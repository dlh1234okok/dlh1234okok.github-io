<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[elasticsearch权威指南学习笔记]]></title>
    <url>%2Fdlh1234okok.github.io%2F2019%2F03%2F07%2Felasticsearch%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[乐观并发控制通过内部版本号内部版本号在每一次修改都会改变并返回改变后的版本号，在修改时指定版本号，修改失败返回409状态码，如果失败可以通过retry_on_conflict参数尝试retry_on_conflict次 通过外部修改版本号外部定义版本号，在修改时带上version=5，则此时版本号被改为5返回，version=10，版本号改为10，此时version=10再次请求，将返回409状态码，new_version&gt;old_version。 修改部分字段脚本语法// 数字可以直接相加 “script” : “ctx._source.views+=1” 1234567// new_tag定义在params中，add函数"script" : &#123; "inline" : "ctx._source.tags.add(params.new_tag)", "params" : &#123; "new_tag" : "search" &#125;&#125; 批量查询_mget每个文档独立检索，通过found字段判断是否找到 在docs中定义索引和类型123456789101112131415161718GET _mget &#123; "docs" : [ &#123; "_index" : "test", "_type" : "ackT", "_id" : 1, "_source" : [ "tags", "views" ] &#125;, &#123; "_index" : "test2", "_type" : "askT", "_id" : 1 &#125; ] &#125; 在url中定义索引及类型1234GET /test/ackT/_mget&#123; "ids" : ["1","2","3"]&#125; 文档分配的分片shard = hash(routing) % number_of_primary_shards routing 默认是文档_id，也可以是一个自定义值，通过hash函数变成数字，除以主分片数量取余，就是文档所在分片的位置（在创建索引的时候就确定分片的数量，如果数量改变了，之前所有路由的值将失效，文档将找不到） 读取文档流程 客户端向node01发送获取请求，根据文档的_id确认所在分片，转发给node02 node02获取文档信息返回给node01 node01将文档信息返回给客户端 处理读取请求时，协调节点每次请求都会轮询所有节点达到负载均衡 删除文档流程 客户端向node01发送删除请求，根据文档_id确认所在分片 假如所在主分片在node03，则会将请求转发给node03， node03处理完成之后将并行请求到其他节点将副本分片删除 如果其他节点完成操作，node03将报告协调节点成功，协调节点返回给客户端 更新文档流程 客户端向node01发送更新请求，根据id转发到node03 node03将修改_source中的json，并且将尝试重新索引主分片的文档，如果此时文档被另外一个进程已经修改，它将重新尝试retry_on_conflict次 如果主分片文档修改成功，它将并行发送给其他副本分片所在的节点，重新建立索引 如果所有副本分片返回成功，node03将发送结果给协调节点，协调节点返回给客户端 在主分片将更改请求转发给副本分片时不会转发更新的请求，而是转发完整文档的新版本 分页通过size和from参数可以制定搜索结果的分页 size：每页显示的数量，默认为10 from：跳过的初试结果的数量，默认为0 如果需要查询第3页，每页显示10条，请求方式就应该是这样 GET /_search?size=10&amp;from=(3-1)*10 对结果的排序成本随分页的深度成指数上升 分词和标准化倒排索引有以下两个文档content内容为 The quick brown fox jumped over the lazy dog Quick brown foxes leap over lazy dogs in summer 我们要建立倒排索引，将content域中内容拆分成单独的词（词条或tokens），创建一个不包含重复词条的列表，并标注哪个词在哪个文档。 Tokens Doc1 Doc2 The ✔ ✖ quick ✔ ✖ brown ✔ ✔ fox ✔ ✖ jumped ✔ ✖ over ✔ ✔ the ✔ ✖ lazy ✔ ✔ dog ✔ ✖ Quick ✖ ✔ foxes ✖ ✔ leap ✖ ✔ … … … 进行全文搜索quick brown时，将匹配 Tokens Doc1 Doc2 quick ✔ ✖ brown ✔ ✔ Total 2 1 两个文档都有匹配，但是第一个文档比第二个文档匹配度高，所以score相对较高。 标准化模式quick 和 Quick 用户可能会认为它们是相同的词 fox 和 foxes 有相同的词根 jumped 和 leap 尽管没有相同的词根，但其意思相近 当我们进行搜索时，为了提升其结果相关性，可以将词条规范为标准化模式 Quick -&gt; quick foxes -&gt; fox jumped 和 leap 可以提取为相近的词jump，此时的倒排索引为 Tokens Doc1 Doc2 quick ✔ ✔ fox ✔ ✔ jump ✔ ✔ … … … 但是 此时我们搜索Quick + foxes时仍然会失败，因为此时我们的分词表中Quick变为了quick，foxes变成了fox，所以我们需要将搜索词也规范为标准化（quick + fox） 全文搜索与精确搜索elasticsearch5.0版本以前通过&quot;&quot;索引的字符串将自动被映射为string类型，默认以全文索引这个域，如果想要设置为精确值，在index中设置为”not_analyzed”，index属性中还有”no”（不索引这个域，搜索不到），”analyzed”以全文索引这个域（默认），例 123456&#123; "tag": &#123; "type": "string", "index": "not_analyzed" &#125;&#125; elasticsearch5.0版本后string类型的映射被去除，取而代之的是text和keyword，从一个变成两个结构更加简单了。 text类型就是原来string类型的analyzed，即全文索引；keyword就是not_analyzed关键字搜索； 而string类型中原来的index属性值改为了true或false（是否索引这个域） 123456789101112131415161718// 关键字索引&#123; "properties": &#123; "tag":&#123; "type": "keyword", "index": true &#125; &#125;&#125;// 全文索引&#123; "properties": &#123; "tag":&#123; "type": "text", "index": true // 是否索引这个域 &#125; &#125;&#125; 查询表达式（Query DSL）1234567891011GET /_search&#123; "query": QUERY_EXPRESSION // 查询表达式&#125;// 例 : 全部匹配GET /_search&#123; "query" : &#123; "match_all":&#123;&#125; &#125;&#125; 查询语句结构1234567891011121314151617&#123; "QUERY_NAME" : &#123; // 字段名 字段值 "ARGUMENT" : "VALUE", "ARGUMENT" : "VALUE", ... &#125;&#125;// 例 ： 查询module字段包含elasticsearch的moduleGET /_search&#123; "query" : &#123; "match" : &#123; "module":"elasticsearch" &#125; &#125;&#125; 合并查询语句添加bool语句组合must（必须）、must_not（必须不）、should（如果匹配将加分_score）匹配，也可以添加不评分的filter过滤，例子： 12345678910111213141516171819202122232425GET /test7*/_search&#123; "query": &#123; "bool": &#123; "must": &#123; "match": &#123; "submodule": "三年计划" &#125; &#125;, "must_not": &#123; "match": &#123; "operator": "更新" &#125; &#125;, "should": &#123; "range": &#123; "timestamp": &#123; "gte":"2019-02-18" &#125; &#125; &#125; &#125; &#125;&#125;// 匹配的submodule必须包含“三年计划”，operator必须不包含“更新”，timestamp大于2019-02-18将增加分数 复合语句可以嵌套复合语句，比如这样 1234567891011121314151617181920212223242526272829303132333435&#123; "query": &#123; "bool": &#123; "must": &#123; "match": &#123; "module": "储备计划" &#125; &#125;, "should": [ &#123; "range": &#123; "timestamp": &#123; "gte": "2019-02-18" &#125; &#125; &#125;, &#123; "bool": &#123; "must": &#123; "match": &#123; "submodule": "年度" &#125; &#125;, "must_not": &#123; "match": &#123; "visitor": "admin5" &#125; &#125; &#125; &#125; ] &#125; &#125;&#125;// 匹配module必须包含“储备计划”字段，timestamp&gt;2019-02-18将加分，submodule包含“年度”的加分，visitor不包含admin5的加分（根据匹配度） 查询和过滤DSL查询语句查询组件可以在两种情况下使用：查询情况和过滤情况 过滤情况：过滤即不查询相关字段信息，不会根据过滤情况评分 查询情况：根据查询字段的匹配程度评分，赋值给_score字段，根据分数进行排序（通常为分数较高的在前） 性能差异​ 过滤查询只需要将数据过滤后查询出来即可，而评分查询不仅需要查询数据还需要根据字段的相关性计算匹配程度所以相比于过滤查询性能较低。所以除了需要进行全文搜索或其他需要影响相关性得分的搜索使用过滤查询代替评分查询较好。 最重要的查询match_all默认的查询，匹配所有文档 match查询​ 根据字段值匹配文档，通常long、boolean、date类型或者是keyword类型的文档将被匹配为精确查找，而text类型的文档是全文查询 multi_match查询可以将一个match查询匹配到多个字段上，例 123456789GET /test7*/_search&#123; "query": &#123; "multi_match": &#123; "query": "储备计划", "fields": ["module","submodule"] &#125; &#125;&#125; range查询通常表示一个区间/范围内的查询 1234567891011GET /test*/_search&#123; "query":&#123; "range": &#123; "@timestamp": &#123; "gte": "2019-02-01", "lte": "2019-03-01" &#125; &#125; &#125;&#125; gt：大于；lt：小于；gte：大于等于；lte：小于等于 term查询通常用于精确查询，比如数字、日期、布尔或是keyword类型的精确查找 12345678910GET /test*/_search&#123; "query": &#123; "term": &#123; "module.keyword": &#123; "value": "储备计划" &#125; &#125; &#125;&#125; terms查询​ 和term查询一样用于精确查询，可以给一个字段匹配多个值，如果该字段匹配其中任何一个就满足条件。 1234567891011GET /test*/_search&#123; "query": &#123; "terms": &#123; "module.keyword": [ "储备计划", "储备谋划" ] &#125; &#125;&#125; exists查询类似于关系型数据库中的NOT NULL，查询指定字段不为空的数据 12345678GET /test*/_search&#123; "query": &#123; "exists": &#123; "field":"module" &#125; &#125;&#125; contant_score查询给予所有数据一个固定的分数，通常用于只有一个filter的查询，例： 12345678910111213GET /test*/_search&#123; "query": &#123; "constant_score": &#123; "filter": &#123; "match": &#123; "module.keyword": "储备计划" &#125; &#125;, "boost": 1.2 &#125; &#125;&#125; 排序sort排序1234567891011121314151617181920GET /test*/_search&#123; "query":&#123; "bool": &#123; "filter": &#123; "term": &#123; "submodule.keyword": "年度计划申报" &#125; &#125; &#125; &#125;, "sort": [ &#123; "@timestamp": &#123; "order": "desc" &#125; &#125; ]&#125;// 查询匹配submodule.keyword的精确值为“年度计划申报”且按时间戳timestamp降序排序 sort排序得到的结果集中_score将不被计算（null），因为它并没有用于排序，计算score会花费巨大的开销 返回“sort”字段将表示timestamp以epoch (January 1, 1970 00:00:00 UTC)以来的毫秒数表示，等价于@timestamp 可以在sort数组中进行多级排序； 也可以使用QueryString进行排序 GET /test7*/_search?sort=@timestamp:desc&amp;sort=_score 多值字段排序一种情形是一个字段有多个值，这些值没有固定的顺序，对于数字或是日期，这时候可以通过取该字段最小值（min）、最大值（max）、平均值（avg）或是和（sum）进行排序，通过mode字段配置 123456"sort": &#123; "@timestamp": &#123; "order": "desc", "mode": "min" &#125; &#125; 相关性算法Elasticsearch的相似度算法被定义为检索词频率/反向文档频率，TF/IDF 检索词频率：检索词在该字段出现的频率越高，相关性越高 反向文档频率：每个检索词在索引中出现的频率越高，相关性越低；检索词出现在多数文档中比出现在少数文档中的权重更低 字段长度准则：字段长度越长，相关性越低 通过添加explain=true参数可以查看我们想要的相关性计算细节 12345678GET /test7*/_search?explain=true&amp;format=yaml&#123; "query": &#123; "match": &#123; "module": "三年" &#125; &#125;&#125; 执行分布式检索查询阶段 客户端发送search请求到协调节点（通常为轮询选择节点达到负载均衡），协调节点准备一个from+size的空优先队列。 协调节点将查询请求转发到索引的每个主分片和副本分片中，每个分片在本地查询并将结果存放在一个大小为from+size的本地有序优先队列中 每个分片将各自优先队列中的文档的ID和排序值返回给协调节点，协调节点将这些值合并到自己的优先队列中后产生一个全局排序后的列表 取回阶段 协调节点辨别哪些需要取回的文档，向相关各分片发送get请求 每个分片加载并丰富文档，将结果返回给协调节点 文档全部取回完毕后，协调节点将结果返回给客户端 搜索选项偏好(Preference)想象一下有两个文档都有相同值的时间戳字段，此时搜索按照timestamp排序，由于搜索请求是在所有相关的主分片和副本分片中轮询的，那就有可能主分片进行搜索时结果是一种顺序，而在副本分片中搜索时结果是另外一种顺序（每次刷新界面结果顺序是不同的）。 此时可以设置Preference参数，比如指定用户的会话id或是一个特定的值来表明一种搜索偏好，让同一用户搜索时使用同一分片。 超时在一些场景中，我们可以设置超时时间，防止elasticsearch搜索时间过长或者因为脚本错误导致的无限制搜索，通过设置timeout字段值来规定搜索时间。 12345678GET /test7*/_search?timeout=1m&#123; "query": &#123; "match": &#123; "module": "三年" &#125; &#125;&#125; 如果搜索超时了，返回的元数据time_out字段将置为true 路由在搜索时通过制定routing的值来限定只搜索哪些分片 1GET /test7*/_search?routing=1]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot集成SpringSecurity-认证]]></title>
    <url>%2Fdlh1234okok.github.io%2F2019%2F01%2F05%2FSpringBoot%E9%9B%86%E6%88%90SpringSecurity-%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[​ SpringSecurity基于Spring环境可以实现我们项目中的权限控制（认证和授权），它主要利用我们Spring中的Aop来实现的，而且在SpringBoot环境下，配置也并没有以前那么复杂，本文主要以一个Demo的形式记录认证的功能。 码前准备数据库表结构​ 在项目中，我们有关用户以及对应的权限相关的表不可或缺，我们这里暂时先创建三张表（用户表、角色表、用户角色表），每个用户有多个权限，每个角色可以给多个用户，这种多对多的关系，我们借助中间表来维护，相关建表语句如下。 123456CREATE TABLE `tb_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键', `user_name` varchar(255) DEFAULT NULL COMMENT '用户名', `user_pwd` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COMMENT='用户表'; 123456CREATE TABLE `tb_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键', `role_name` varchar(255) NOT NULL COMMENT '角色名', `role_desc` varchar(255) DEFAULT NULL COMMENT '角色描述', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COMMENT='角色表'; 12345678910CREATE TABLE `tb_user_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键', `role_id` bigint(20) NOT NULL COMMENT '角色表外键', `user_id` bigint(20) NOT NULL COMMENT '用户表外键', PRIMARY KEY (`id`), KEY `roleId` (`role_id`), KEY `userId` (`user_id`), CONSTRAINT `roleId` FOREIGN KEY (`role_id`) REFERENCES `tb_role` (`id`), CONSTRAINT `userId` FOREIGN KEY (`user_id`) REFERENCES `tb_user` (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COMMENT='用户角色表'; 创建项目我们借助Spring Initializr来快速搭建SpringBoot项目，版本为SpringBoot2.1.1 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 其中数据库连接、持久层、MVC层和View等坐标我就不贴了，自行脑补 配置文件配置在application.properties中配置和SpringSecurity不相关的配置 12345678910111213## datasourcespring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.url=jdbc:mysql://127.0.0.1:3306/security?charsetEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8spring.datasource.username=rootspring.datasource.password=123456## mybatismybatis.mapper-locations=classpath:mappers/*.xmlmybatis.type-aliases-package=com.dlh.springboot_security.entity# thymeleafspring.thymeleaf.prefix=classpath:/templates/spring.thymeleaf.suffix=.html 注意：Mysql-Connector8.0版本后必须要在url后面配上时区serverTimezone。 自定义登录页面其实我们环境中只要有SpringSecurity，它就会自动为我们开启认证，只不过登录页面和认证帐号密码是它提供的 帐号是user，但是我们开发中肯定不会用它的是吧，所以我们需要来定义自己的登录页面还有自己的认证逻辑 准备登录html页面123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;登陆&lt;/h1&gt;&lt;form method="post" action="/user/login"&gt; &lt;div&gt; 用户名：&lt;input type="text" name="username"/&gt; &lt;/div&gt; &lt;div&gt; 密码：&lt;input type="password" name="password"/&gt; &lt;/div&gt; &lt;div&gt; &lt;button type="submit"&gt;立即登陆&lt;/button&gt; &lt;/div&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 创建配置类继承WebSecurityConfigurerAdapter重写Configure(HttpSecurity http)方法 12345678910111213141516171819202122@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123;@Override protected void configure(HttpSecurity http) throws Exception &#123; http.formLogin() // 当需要登录时跳转到的页面 .loginPage("/login") // 登录接口，地址必须和登录提交地址相同 .loginProcessingUrl("/user/login"） .and() // 定义需要拦截的请求和不需要拦截的请求 .authorizeRequests() // 所有权限都可以访问login.html .antMatchers("/login").permitAll() // 任何请求，登陆后可以访问 .anyRequest() .authenticated() .and() // 关闭csrf防护 .csrf().disable(); &#125;｝ 配置自己的认证逻辑​ 我们正常开发中是根据用户名从数据库中查出当前用户的相关信息，然后判断其密码是否一致来进行认证操作，这里SpringSecurity帮我们完成了比较的步骤，我们只需要查数据就可以。 定义自己的认证类，实现UserDetailsService接口重写loadUserByUsername方法 123456789101112131415@Componentpublic class UserService implements UserDetailsService &#123; @Resource private UserDao userDao; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException &#123; Map&lt;String, Object&gt; user = userDao.queryByUserName(s); String userName = (String) user.get("userName"); String userPwd = (String) user.get("userPwd"); String roleName = (String) user.get("roleName"); return new User(userName, userPwd, AuthorityUtils.commaSeparatedStringToAuthorityList(roleName)); &#125;&#125; 加密SpringSecurity5中必须对密码进行加密才可以认证，否则就会出现如下问题： SpringSecurity提供了很多加密方式，可以看PasswordEncoder接口有很多实现 这里我们使用BCrypt方式加密，也就是BCryptPasswordEncoder这个类 在我们的SecurityConfig配置类中重写configure(AuthenticationManagerBuilder auth)方法，将我们自定义认证类传入 1234@Overrideprotected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService(userService).passwordEncoder(new BCryptPasswordEncoder());&#125; 自定义登录成功或失败处理我们前台往往可能会通过ajax发送请求等我们响应JSON数据，或是存一下session，我们总不能直接就给跳转了吧。 登录成功处理继承SimpleUrlAuthenticationSuccessHandler或者它的子类SavedRequestAwareAuthenticationSuccessHandler，子类相比于父类，会将请求数据进行保存，比如我们在他需要请求后直接重定向到之前请求的地址，可以使用子类；重写onAuthenticationSuccess方法 1234567891011121314@Componentpublic class AuthenticationSuccessHandler extends SavedRequestAwareAuthenticationSuccessHandler &#123; @Resource private ObjectMapper objectMapper; @Override public void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws ServletException, IOException &#123; response.setContentType("application/json;charset=UTF-8"); // 将用户记录存到session request.getSession().setAttribute("user", authentication.getPrincipal()); response.getWriter().write(objectMapper.writeValueAsString(authentication)); &#125;&#125; 登录失败处理继承SimpleUrlAuthenticationFailureHandler，重写onAuthenticationFailure方法 123456789101112@Componentpublic class AuthenticationFailedHandler extends SimpleUrlAuthenticationFailureHandler &#123; @Resource private ObjectMapper objectMapper; @Override public void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response, AuthenticationException exception) throws IOException, ServletException &#123; response.setContentType("application/json;charset=UTF-8"); response.getWriter().write(objectMapper.writeValueAsString(exception.getMessage())); &#125;&#125; 来测试一下吧我们现在启动项目，不出意外访问未被允许的地址会被拦截到我们的自定义登录页 进行登录，首先输入错误的密码 这是把我们认证异常的异常信息返回了 进行正确登录 这样前台可以根据authenticated字段或自定义需要返回的内容来进行认证后的相关操作了]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开发中优雅的异常定义]]></title>
    <url>%2Fdlh1234okok.github.io%2F2019%2F01%2F01%2F%E5%BC%80%E5%8F%91%E4%B8%AD%E4%BC%98%E9%9B%85%E7%9A%84%E5%BC%82%E5%B8%B8%E5%AE%9A%E4%B9%89%2F</url>
    <content type="text"><![CDATA[创建异常定义枚举类异常码枚举123456789101112131415161718192021public enum ExceptionCodeEnum &#123; /** * 系统错误异常 */ SYS_ERROR(&quot;SYS_ERROR&quot;, &quot;系统错误&quot;), /** * 未知的系统异常 */ UNKNOWN_ERROR(&quot;UNKNOWN_ERROR&quot;, &quot;未知错误&quot;), /** * 服务调用异常 */ SERVICE_INVOKE_FAIL(&quot;SERVICE_INVOKE_FAIL&quot;, &quot;服务调用异常&quot;), /** * 参数校验异常 */ ILLEGAL_ARGS(&quot;ILLEGAL_ARGS&quot;, &quot;参数校验错误&quot;); 枚举构造函数12345678910// 结果码private String code;// 描述private String desc;ExceptionCodeEnum(String code, String desc) &#123; this.code = code; this.desc = desc;&#125; 一个通过code找枚举的静态方法12345678public static ExceptionCodeEnum getValues(String code) &#123; for (ExceptionCodeEnum ece : values()) &#123; if (StringUtils.equals(ece.getCode(), code)) &#123; return ece; &#125; &#125; return null;&#125; 自定义异常继承RuntimeException1234567891011public class BusinessException extends RuntimeException &#123; /** * 异常码 */ private ExceptionCodeEnum error_code; /** * 异常信息 */ private String error_msg; 重载构造方法1234567891011121314151617181920/** * 带参构造（根据异常枚举） * * @param codeEnum */public BusinessException(ExceptionCodeEnum codeEnum) &#123; super(codeEnum.getDesc()); this.setError_code(codeEnum);&#125;/** * 带参构造（根据异常枚举和异常描述信息） * * @param codeEnum * @param error_msg */public BusinessException(ExceptionCodeEnum codeEnum, String error_msg) &#123; super(StringUtils.isNotBlank(error_msg) ? error_msg : codeEnum.getDesc()); this.setError_code(codeEnum);&#125; 测试12345678910111213141516171819public static void main(String[] args) &#123; String userName = null; int userAge = 0; try &#123; if (null == userName) &#123; throw new BusinessException(ExceptionCodeEnum.ILLEGAL_ARGS); &#125; if (userAge == 0) &#123; throw new BusinessException(ExceptionCodeEnum.ILLEGAL_ARGS, "参数不能为0"); &#125; &#125; catch (BusinessException e) &#123; e.printStackTrace(); System.out.println("异常码：" + e.getError_code()); System.out.println("异常描述：" + e.getMessage()); &#125;&#125; 异常码、异常信息都打出来了，定位问题非常准确]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot集成Quartz时钟框架]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F12%2F24%2FSpringBoot%E9%9B%86%E6%88%90Quartz%E6%97%B6%E9%92%9F%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[添加依赖123456789101112131415161718&lt;!--quartz依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 该依赖里面有spring对schedule的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- quartz 使用了该jar包PlatformTransactionManager类 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;&lt;/dependency&gt; 配置Quartz1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@Configurationpublic class QuartzConfiguration &#123; /** * 配置任务 * * @param quartzTask QuartzTaskService为需要执行的任务类 * @return */ @Bean(name = "Job01") public MethodInvokingJobDetailFactoryBean detailFactoryBean(QuartzTaskService quartzTask) &#123; MethodInvokingJobDetailFactoryBean jobDetail = new MethodInvokingJobDetailFactoryBean(); // 是否并发执行 jobDetail.setConcurrent(false); // 设置任务的名字 jobDetail.setName("Job01"); // 设置任务的分组，在多任务的时候使用 jobDetail.setGroup("JobGroup01"); // 需要执行的对象 jobDetail.setTargetObject(quartzTask); /* * 执行QuartzTaskService类中的需要执行方法 */ jobDetail.setTargetMethod("test"); return jobDetail; &#125; /** * 定时触发器 * * @param Job01 任务01 * @return */ @Bean(name = "jobTrigger") public CronTriggerFactoryBean cronJobTrigger(JobDetail Job01) &#123; CronTriggerFactoryBean tigger = new CronTriggerFactoryBean(); tigger.setJobDetail(Job01); //cron表达式，每1分钟执行一次 tigger.setCronExpression("0 0/1 * * * ?"); tigger.setName("TestTrigger"); return tigger; &#125; /** * 调度工厂 * * @param jobTrigger 触发器 * @return */ @Bean(name = "scheduler") public SchedulerFactoryBean schedulerFactory(Trigger jobTrigger) &#123; SchedulerFactoryBean factoryBean = new SchedulerFactoryBean(); // 用于quartz集群,QuartzScheduler 启动时更新己存在的Job factoryBean.setOverwriteExistingJobs(true); // 延时启动，应用启动1秒后 factoryBean.setStartupDelay(1); // 注册触发器 factoryBean.setTriggers(jobTrigger); return factoryBean; &#125;&#125; 配置任务类123456789@Servicepublic class QuartzTaskService&#123; @Override public void test() &#123; System.out.println("quartz..test.." + new Date()); &#125;&#125; 测试 参考博客：https://www.imooc.com/article/36278 感谢！]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq死信队列和延时任务处理]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F12%2F15%2FRabbitMQ%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%E5%92%8C%E5%BB%B6%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[​ DLX（Dead-Letter-Exchange），称为死信交换机，当消息变为一个死信后，如果这个消息所在的队列中存在x-dead-letter-exchange参数，它就会被发送到对应x-dead-letter-exchange的交换机上，称之为死信交换机，与该交换机绑定的队列就是死信队列。 死信消息 消息被拒绝（Basic.Reject或Basic.Nack）并且设置 requeue 参数的值为 false 消息过期了 队列达到最大的长度 我们可以通过消息过期成为死信消息和死信队列完成延时任务的处理 场景用户在创建订单后如果10s内不进行支付，则自动取消订单 这种延时任务处理有多种方案： 1、定时调度数据库轮询 2、JDK延时队列（DelayQueue） 3、Redis数据库zset 4、RabbitMQ死信队列-&gt;延时队列 我们在这里演示RabbitMQ的解决方案 分析与代码实现通过RabbitMQ的过期消息+死信队列来模拟实现延时队列处理 过期消息-&gt;通过x-message-ttl 参数实现 死信队列交换机-&gt;x-dead-letter-exchange 参数，绑定死信队列到该死信交换机 生产方代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class Producer &#123; // 死信交换机名称 private static final String DLX_EXCHANGE_NAME = "dlx.exchange"; // 死信队列名称 private static final String DLX_QUEUE_NAME = "dlx.queue"; // 交换机名称 private static final String ORDER_EXCHANGE_NAME = "order_exchange"; // 队列名称 private static final String ORDER_QUEUE_NAME = "order_queue"; // 路由规则 private static final String ORDER_ROUTING_KEY = "order.#"; // 死信队列 交换机标识符 private static final String DEAD_LETTER_QUEUE_KEY = "x-dead-letter-exchange"; // 死信队列交换机绑定键标识符 private static final String DEAD_LETTER_ROUTING_KEY = "x-dead-letter-routing-key"; // 队列消息过期时间标识 private static final String MSG_TIMEOUT = "x-message-ttl"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建信道 Channel channel = connection.createChannel(); Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); // 为队列设置死信队列交换机 arguments.put(DEAD_LETTER_QUEUE_KEY, DLX_EXCHANGE_NAME); // 设置队列中消息超时时间 - 10s arguments.put(MSG_TIMEOUT, 10000); // 为死信队列设置路由键，如果没有指定则使用原队列路由键 //arguments.put(DEAD_LETTER_ROUTING_KEY, "dlx.#"); // 创建交换机和队列 channel.exchangeDeclare(ORDER_EXCHANGE_NAME, "topic", true, false, null); channel.queueDeclare(ORDER_QUEUE_NAME, true, false, false, arguments); channel.queueBind(ORDER_QUEUE_NAME, ORDER_EXCHANGE_NAME, ORDER_ROUTING_KEY); // 准备消息 String msg = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()) + "创建订单"; // 创建死信交换机和队列 channel.exchangeDeclare(DLX_EXCHANGE_NAME, "topic", true, false, null); channel.queueDeclare(DLX_QUEUE_NAME, true, false, false, null); channel.queueBind(DLX_QUEUE_NAME, DLX_EXCHANGE_NAME, ORDER_ROUTING_KEY); channel.basicPublish(ORDER_EXCHANGE_NAME, "order.test", MessageProperties.PERSISTENT_TEXT_PLAIN, msg.getBytes(StandardCharsets.UTF_8)); System.out.println("消息发送完成：" + msg); ConnectionUtil.closeResources(connection, channel); &#125;&#125; 接收方代码12345678910111213141516171819202122232425public class Receiver &#123; // 我们需要监听死信队列 private static final String QUEUE_NAME = "dlx.queue"; public static void main(String[] args) throws Exception &#123; // 创建连接 Connection connection = ConnectionUtil.getConnection(); // 创建信道 Channel channel = connection.createChannel(); // 设置客户端最多接收未被ack的消息个数, 只有消息 手动签收 此参数才会生效。 channel.basicQos(1); // 创建消费者 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.err.println("接收到消息：" + new String(body, StandardCharsets.UTF_8)); System.err.println("deliveryTag:" + envelope.getDeliveryTag()); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; // 执行死信队列消费 channel.basicConsume(QUEUE_NAME, consumer); &#125;&#125; 消息大致流转过程]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot集成RabbitMQ]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F12%2F11%2FSpringBoot%E9%9B%86%E6%88%90RabbitMQ%2F</url>
    <content type="text"><![CDATA[Direct模式单机环境引入RabbitMQ依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; application.properties配置相关参数123456# rabbitMq相关配置spring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=dlhspring.rabbitmq.password=123456spring.rabbitmq.virtual-host=/test 配置队列1234567@Configurationpublic class SenderConf &#123; @Bean public Queue queue()&#123; return new Queue("queue"); &#125;&#125; 配置发送方IOC环境下只需要注入AmqpTemplate就可以了 123456789@Componentpublic class Sender01 &#123; @Autowired private AmqpTemplate amqpTemplate; // 指定队列发送 public void send()&#123; amqpTemplate.convertAndSend("queue","hello,spring-boot-rabbitmq"); &#125;&#125; 配置接收方12345678910@Componentpublic class Receiver01 &#123; /** * 配置监听,监听queue队列 */ @RabbitListener(queues = "queue") public void receive(String str)&#123; System.out.println("receive:"+str); &#125;&#125; 测试123456789101112@SpringBootTest@RunWith(SpringJUnit4ClassRunner.class)public class Test01 &#123; @Autowired private Sender01 sender01; @Test public void test01()&#123; sender01.send(); &#125;&#125; 当我们发出消息后，对应队列的监听监听到有消息后就会执行消费 这是最基础的生产消费，接下来我们看一下模拟分布式的topic主题模式的相关配置 Topic主题模式（分布式）首先先配置发送端，我们需要配置队列Queue，然后再配置交换机Exchange，再绑定RoutingKey到交换机上 创建Maven多模块工程模拟分布式应用（服务提供方和服务消费方） 编写消费方相关配置1234567891011121314151617181920212223242526272829303132333435@Configurationpublic class SenderConf &#123; // 声明队列01 @Bean(name = "queue01") public Queue queue01()&#123; return new Queue("queue01"); &#125; // 声明队列02 @Bean(name = "queue02") public Queue queue02()&#123; return new Queue("queue02"); &#125; // 声明交换机 @Bean public TopicExchange exchange()&#123; return new TopicExchange("Spring-Boot-Exchange"); &#125; // 绑定指定队列queue01到交换机上并设置RoutingKey 路由规则 @Bean public Binding bindingExchange01(@Qualifier("queue01") Queue queue01,TopicExchange exchange)&#123; // .* 为匹配.后一个词 return BindingBuilder.bind(queue01).to(exchange).with("queue.*"); &#125; // 这里也一样绑定queue02 @Bean public Binding bindingExchange02(@Qualifier("queue02") Queue queue02,TopicExchange exchange)&#123; // .# 为匹配.后面对个词 return BindingBuilder.bind(queue02).to(exchange).with("queue.#"); &#125;&#125; 然后我们在接收方模块中编写监听以及相应的消费行为 Receiver12345678910111213141516@Componentpublic class ReceiverConf &#123; // 监听queue01 @RabbitListener(queues = "queue01") public void process01(String str) &#123; // 执行消费行为 System.out.println("queue01:" + str); &#125; // 监听queue02 @RabbitListener(queues = "queue02") public void process02(String str) &#123; // 执行消费行为 System.out.println("queue02:" + str); &#125;&#125; 发送消息与消费在我们消费方编写单元测试发送消息 123456789101112@SpringBootTest@RunWith(SpringJUnit4ClassRunner.class)public class Test01 &#123; @Autowired private AmqpTemplate amqpTemplate; @Test public void test01()&#123; amqpTemplate.convertAndSend("Spring-Boot-Exchange","queue.test.test","hello"); &#125;&#125; 然后我们启动接收方，从SpringBoot入口启动，监听到相应队列中的消息就会执行消费 根据我们发送方匹配的RoutingKey交换机将路由到queue02，我们来查看下结果 SpringBoot中RabbitMQ的基本配置就是这样了，在不同的业务场景下都可以套用，比如异步发送短信通知，异步进行日志收集等操作，RabbitMQ还可以做延时任务的处理，比如饿了么购物，下单后未付款将有15分钟的等待时间，超时将自动取消订单，在这种场景下，我们可以使用RabbitMQ的超时队列和死信队列来进行延时任务，期待下次更新。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot集成Druid]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F11%2F29%2FSpringBoot%E9%9B%86%E6%88%90Druid%2F</url>
    <content type="text"><![CDATA[Druid是Java语言中最好的数据库连接池。Druid能够提供强大的监控和扩展功能。其中监控功能可以对我们的sql执行过程进行监控，有利于我们后期的sql调优。 引入druid-spring-boot-starter依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt; …待更新]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hibernate环境搭建]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F11%2F28%2FHibernate%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[​ Hibernate 是一个开放源代码的对象关系映射框架，它对 JDBC 进行了轻量级的对象封装，它将 POJO 与数据库表建立映射关系，是一个全自动的 orm 框架,核心内容是 ORM（Object Relational Mapping 对象关系映射） ,可以根据对象自动的生成数据库相关表的信息，使得开发更加的面向对象。这样我们就可以使用面向对象的思想来操作数据库，而不用关心繁琐的 JDBC。 添加maven坐标依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;4.3.11.Final&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mysql 驱动包 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt;&lt;/dependency&gt; 添加Hibernate配置文件123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC "-//Hibernate/Hibernate Configuration DTD 3.0//EN" "http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;property name="connection.url"&gt;jdbc:mysql://127.0.0.1:3306/hb01&lt;/property&gt; &lt;property name="connection.username"&gt;root&lt;/property&gt; &lt;property name="connection.password"&gt;123456&lt;/property&gt; &lt;!--数据库JDBC驱动类名--&gt; &lt;property name="connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;!--数据库方言--&gt; &lt;property name="dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!--ddl语句自动填表--&gt; &lt;property name="hbm2ddl.auto"&gt;update&lt;/property&gt; &lt;property name="show_sql"&gt;true&lt;/property&gt; &lt;property name="format_sql"&gt;true&lt;/property&gt; &lt;!--连接数据库时使用Unicode编码--&gt; &lt;property name="Connection.useUnicode"&gt;true&lt;/property&gt; &lt;!--设置传输字符集编码格式为utf-8--&gt; &lt;property name="connection.characterEncoding"&gt;UTF-8&lt;/property&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 添加实体类User以及对应的映射文件1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping package="com.dlh.po"&gt; &lt;class name="User" table="user"&gt; &lt;!--主键--&gt; &lt;id name="id" column="id"&gt; &lt;!--native:根据底层数据库能力选择 identity,sequence,或者hilo 中的一个--&gt; &lt;generator class="native"/&gt; &lt;/id&gt; &lt;!--实体类属性--&gt; &lt;property name="userName" column="user_name"/&gt; &lt;property name="userPwd" column="user_pwd"/&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 测试首先执行添加操作，hibernate会帮我们生成相应的表结构，前提是数据库必须存在 1234567891011121314151617181920212223242526272829303132public class TestHibernate &#123; @Test public void test() &#123; Session session = null; try &#123; //1. 加载配置文件 Configuration config = new Configuration(); config.configure("hibernate.cfg.xml"); // 2. 通过注册中心生成 SessionFactory ServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder() .applySettings(config.getProperties()).build(); SessionFactory factory = config.buildSessionFactory(serviceRegistry); // 3. 生成 Session session = factory.openSession(); // 4. 创建User对象 User user = new User(); user.setUserName("test01"); user.setUserPwd("123456"); // 5.执行添加操作 session.save(user); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 关闭 session if (null != session) &#123; session.close(); &#125; &#125; &#125;&#125; 在控制台会打印sql语句，发现执行了一条添加的sql，但是到我们数据库中查看并没有数据添加 原因是默认没有提交事务，此时该记录只存在session中 通过session开启事务，并在添加后执行事务的commit操作修改我们的代码… 1234567891011121314151617181920212223242526272829303132333435public class TestHibernate &#123; @Test public void test() &#123; Session session = null; try &#123; //1. 加载配置文件 Configuration config = new Configuration(); config.configure("hibernate.cfg.xml"); // 2. 通过注册中心生成 SessionFactory ServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder() .applySettings(config.getProperties()).build(); SessionFactory factory = config.buildSessionFactory(serviceRegistry); // 3. 生成 Session session = factory.openSession(); // 开启事务 Transaction transaction = session.beginTransaction(); // 4. 调用 Hibernate 接口操作数据库 User user = new User(); user.setUserName("test01"); user.setUserPwd("123456"); session.save(user); // 执行事务提交操作 transaction.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 关闭 session if (null != session) &#123; session.close(); &#125; &#125; &#125;&#125; 添加成功了！]]></content>
      <categories>
        <category>Hibernate</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Lucene全文检索]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F11%2F12%2FLucene%E4%BA%86%E8%A7%A3%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Lucene是什么​ Lucene 是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。 说到底它是一个信息检索程序库，而不是应用产品。 因此它并不像百度或者 google 那样，拿来就能用，它只是提供了一种工具让你能实现这些产品。 Lucene 能做什么​ 要回答这个问题，先要了解 lucene 的本质。实际上 lucene 的功能很单一，说到底，就是我们给它若干个字符串，然后它为我们提供一个全文搜索服务， 最后告诉我们要搜索的关键词出现在哪里。知道了这个本质， 我们就可以发挥想象做任何符合这个条件的事情了。 比如我们可以把站内新闻都索引了，做个资料库；也可以把一个数据库表的若干个字段索引起来，那就不用再担心因为“%like%”而锁表了…… 深入Lucene为什么 lucene 这么快 倒排索引 压缩算法 二元搜索 倒排序索引​ 它是根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(invertedindex)。 工作方式​ Lucene 提供的服务实际包含两部分：一入一出。所谓入是写入，即将你提供的源（本质是字符串）写入索引或者将其从索引中删除；所谓出是读出，即向用户提供全文搜索服务，让用户可以通过关键词定位源 写入流程 源字符串首先经过 analyzer 处理，包括：分词，分成一个个单词；去除 stopword（可选）。 将源中需要的信息加入 Document 的各个 Field（信息域） 中，并把需要索引的 Field 索引起来，把需要存储的 Field 存储起来。 将索引写入磁盘。 读出流程 用户提供搜索关键词，经过 analyzer 处理。 对处理后的关键词搜索它的索引， 找出对应的 Document。 用户根据需要从找到的 Document 中提取需要的 Field。 Docement​ 用户提供的源是一条条记录，它们可以是文本文件、字符串或者数据库表的一条记录等等。一条记录经过索引之后，就是以一个Document 的形式存储在索引文件中的。用户进行搜索，也是以Document 列表的形式返回。 Field​ 一个 Document 可以包含多个信息域，例如一篇文章可以包含“标题”、“正文”、“最后修改时间”等信息域，这些信息域就是通过 Field在 Document 中存储的。Field 有两个属性可选：存储和索引。通过存储属性你可以控制是否对这个 Field 进行存储；通过索引属性你可以控制是否对该Field 进行索引。这看起来似乎有些废话，事实上对这两个属性的正确组合很重要。 实现原理文本倒排处理 : Lucene 整体使用如图所示： 开始配置Lucene依赖或者项目导入jar包 创建索引12345678910111213141516171819202122232425public void createIndex() throws IOException &#123; // 配置indexWriter IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_4_9, analyzer); // 指定索引写入时为CREATE_OR_APPEND模式 config.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND); // 通过索引目录和配置信息，生成writer IndexWriter writer = new IndexWriter(directory, config); // 遍历读取文件目录dataDir里的所有文件 Collection&lt;File&gt; files = FileUtils.listFiles(new File(dataDir), TrueFileFilter.INSTANCE, TrueFileFilter.INSTANCE); for (File file : files) &#123; // 将一个文件的文件名和文件内容分别生成两个field信息域 Field fileNameField = new StringField("fileName", file.getName(), Field.Store.YES); String context = FileUtils.readFileToString(file); Field contentField = new TextField("content", context, Field.Store.YES); // 创建document，并添加两个信息域 Document document = new Document(); document.add(fileNameField); document.add(contentField); // 通过document通过writer写入到索引目录下 writer.addDocument(document); &#125; writer.close(); &#125; 查询索引1234567891011121314151617181920212223public void search() throws IOException, ParseException &#123; // 创建基础分词器 Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_4_9); IndexReader indexReader = DirectoryReader.open(directory); // 通过indexReader创建一个索引搜索器 IndexSearcher searcher = new IndexSearcher(indexReader); // 创建一个分析器并指定需要搜索的信息域和分词器 QueryParser queryParser = new QueryParser(Version.LUCENE_4_9, "content", analyzer); // 生成一个query Query query = queryParser.parse("java"); // 开始搜索，指定返回结果数量 TopDocs topDocs = searcher.search(query, 10); ScoreDoc[] scoreDocs = topDocs.scoreDocs; System.out.println("命中数：" + topDocs.totalHits); for (ScoreDoc scoreDoc : scoreDocs) &#123; // 取得document的id int idDoc = scoreDoc.doc; // 通过id获取document Document document = searcher.doc(idDoc); System.out.println("分数：" + scoreDoc.score); System.out.println("文件名：" + document.get("fileName")); &#125; &#125; 其他功能分词器​ Lucene 自带的 StandardAnalyzer 分词器，只能对英语进行分词。在对中文进行分词的时候采用了一元分词，即每一个中文作为一个词，如“我是中国人”，则分词结果为“我”，“是”，“中”，“国”，“人”，可以看出分词效果很差。在这里推荐一个比较好用的中文分词器IKAnalyzer。 停用词​ 停用词是指在信息检索中，为节省存储空间和提高搜索效率，在处理自然语言数据（或文本）之前或之后会自动过滤掉某些字或词，这些字或词即被称为 Stop Words（停用词）。 比如中文中“了”，“么”，“呢”，“的”等意义不大且在一篇文章中出现频率又很高的词，又比如英文的”for”,”in”,”it”,”a”,”or”等词。在使用 IKAnalyzer 分词器的时候，可以在 IKAnalyzer.cfg.xml里配置相关信息，如下图： 高亮-Highlighter Field属性详解​ Field 是文档中的域，包括 Field 名和 Field 值两部分，一个文档可以包括多个 Field， Document 只是 Field 的一个承载体， Field值即为要索引的内容，也是要搜索的内容。 是否分词(tokenized) ​ 是：作分词处理，即将 Field 值进行分词，分词的目的是为了索引。比如：商品名称、商品简介等，这些内容用户要输入关键字搜索，由于搜索的内容格式大、内容多需要分词后将语汇单元索引。 ​ 否：不作分词处理，比如：商品 id、订单号、身份证号等 是否索引(indexed) ​ 是：进行索引。将 Field 分词后的词或整个 Field 值进行索引，索引的目的是为了搜索。比如：商品名称、商品简介分词后进行索引，订单号、身份证号不用分词但也要索引，这些将来都要作为查询条件。 ​ 否：不索引。该域的内容无法搜索到，比如：商品 id、文件路径、图片路径等，不用作为查询条件的不用索引。 是否存储(stored) ​ 是：将 Field 值存储在文档中，存储在文档中的 Field 才可以从Document 中获取。比如：商品名称、订单号，凡是将来要从 Document 中获取的 Field都要存储。 ​ 否：不存储 Field 值，不存储的 Field 无法通过 Document 获取，比如：商品简介，内容较大不用存储。如果要向用户展示商品简介可以从系统的关系数据库中获取商品简介。 如果需要商品描述，则根据搜索出的商品 ID 去数据库中查询，然后显示出商品描述信息即可。 Field 常用类型常用 的 Filed 类型，注意 Field 的属性，根据需求选择： 栗子 图书 id： 是否分词：不用分词，因为不会根据商品 id 来搜索商品 是否索引：不索引，因为不需要根据图书 ID 进行搜索 是否存储：要存储，因为查询结果页面需要使用 id 这个值 图书名称： 是否分词：要分词，因为要将图书的名称内容分词索引，根据关键搜索图书名称抽取的词。 是否索引：要索引。 是否存储：要存储 图书价格： 是否分词：要分词， lucene 对数字型的值只要有搜索需求的都要分词和索引，因为 lucene 对数字型的内容要特殊分词处理，本例子可能要根据价格范 围搜索，需要分词和索引。 是否索引：要索引 是否存储：要存储 图书图片地址： 是否分词：不分词 是否索引：不索引 是否存储：要存储 图书描述： 是否分词：要分词 是否索引：要索引 是否存储：因为图书描述内容量大，不在查询结果页面直接显示，不存储。 不存储是来不在 lucene 的索引文件中记录，节省 lucene的索引文件空间， 如果要在详情页面显示描述，思路： 从 lucene中取出图书的 id，根据图书的 id 查询关系数据库中 book 表得到描述信息。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[问题汇总]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F11%2F07%2F%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[IOC是什么,有哪些优点?IOC是Spring框架的核心技术，控制反转和依赖注入 控制反转 应用程序创建对象的过程交给外部容器IOC来创建 未使用Spring框架的IOC之前，创建对象为： UserService userService = new UserService(); 使用控制反转之后： ​ 可以在XML文件中配置bean标签，或者使用扫描机制，配合注解（@Component，@Service，@Repository，@Controller），在Spring上下文启动时就会将这些对象创建完毕。 依赖注入（装配） 依赖注入其实就是给属性赋值，没有使用IOC之前，Controller层如果需要调用Service层，则需要手动赋值 userService = new UserService(); 使用了IOC之后，在‘控制反转’过程中，已经通过XML配置或是扫描注解配置将该对象创建完毕，所以只需要加上@Resource或是@AutoWired注解即可完成对属性的赋值操作 IOC具体实现内部原理 XML解析，反射，单例，工厂设计模式 优点 降低组件之间的耦合，提高程序的灵活性和可维护性，代码的侵入性较低。 缺点 创建对象的步骤变复杂了，并且通过反射创建对象，使得效率相对于手动创建对象低一些 Aop实现方式与应用场景 面向切面编程，Aop实现的关键是Aop在运行时动态创建Aop代理。 Aop代理分为静态代理和动态代理。 静态代理是使用Spring框架提供的命令进行编译，在编译阶段生成Aop代理类，因此也成为编译时增强 动态代理借助JDK动态代理和CGLib动态代理，在程序运行过程中动态创建代理对象 代理对象的方法=被代理对象的方法+增强的处理 核心思想：将应用程序中的业务逻辑和对其支持的通用服务进行分离 在大量方法需要进行同一增强或修改时适合使用Aop 权限控制、日志收集、事务管理、非法资源控制等 SpringMVC工作流程 dispatcherServlet前端控制器捕获用户发送的请求，解析URL获取资源标识URI HandlerMapping处理器映射器根据URI找到对应的处理器对象及其拦截器，返回HandlerExecutionChain 根据Handler对象找到合适的HandlerAdpater处理适配器，将调用拦截器的preHandler()方法 根据HandlerAdpater调用和合适的Handler（Controller） 执行完Controller方法返回ModelAndView对象 HandlerAdpater将ModelAndView对象返回给dispatcherServlet dispatcherServlet将ModelAndView传给ViewReslover视图解析器 Viewreslover解析返回具体的View给dispatcherServlet dispatcherServlet对View进行渲染视图响应给用户 web会话跟踪技术http协议是无状态协议，即协议对于事务没有记忆，为了保持客户端与服务器的一次会话连接 在客户端第一次请求服务器时，server内部会产生一个唯一的sessionId，随着响应携带到客户端，由cookie存储sessionId到浏览器的内存中。 session 存在于服务器，用于保存用户的敏感信息 cookie存在于客户端浏览器，数据量小，用户存放临时的敏感度低的信息 ==、equals和hashCode == 基本数据类型==比较的是值 非基本数据类型==比较的是对象引用的地址 equals equals比较的是对象的地址值 重写之后可以比较对象内容，比如String重写了equals方法，先比较地址，相等直接返回true，不相等再比较内容 重写equals，不重写hashCode equals相等，hashCode不相等（不同对象地址） hashCode相等，equals相等（同一对象地址） 重写hashCode，不重写equals hashCode相等，equals不相等（不同对象地址） equals相等，hashCode相等（同一对象地址） 重写hashCode和equals equals相等，hashCode相等（不同对象地址） 重写equals均采用先比较地址对象地址，再比较对象内容 重写hashCode为Object.hash(参数) MVCMVC是一种编程思想，通过将视图与业务分离，达到降低耦合，提高代码重用，可维护性高等特点。 model-模型，主要是数据存储部分，javabean view-视图，负责用于数据显示，通过模型数据进行展示 controller-控制器，处理与用户之间的交互，用于请求和响应 ORM 对象关系映射 ​ 一般的关系型数据库不是面向对象的，而Java语言是面向对象的。通过对象模型表示的对象映射到基于SQL的关系型 数据库达到操作对象即操作数据库数据的目的。 数据库与javabean对象的关系 表——javabean 字段——属性 记录——javabean对象 ORM框架 Mybatis：半自动ORM框架，基于sql，需要手动创建表结构 Hibernate：完整的ORM框架，全自动，操作对象就是操作表结构 同步和异步的区别同步：发送请求，需要等待返回才能继续发送请求 异步：发送请求，不需要等待返回，随时可以再发送下一个请求 使用异步交互的例子 ​ 在网络环境较差的情况下，同步需要等待服务器响应之后才能继续进行另外的动作，比如加载一个页面，包含文字和图片，同步情况下需要等整个页面响应完成后浏览器才能展示，而异步则可以先将文字加载出来后，局部加载图片。 ​ 比如电商购物，订单提交完成后需要经过仓储系统检查仓储以及调度发货，然后经过配送系统进行配送，这一系列步骤肯定不是同步的，在用户订单支付完成之后，这些操作将异步通信在后台执行。 redis缓存穿透和雪崩问题 缓存穿透 ​ 在一些恶意用户请求的行为，在缓存中查询一个不存在的数据，没有查到将去数据库进行查询，没有查到不写入缓存。这将导致这个不存在的数据每次查找都要去数据库查，造成缓存穿透 解决方法：1、使用互斥锁排队；2、布隆过滤器；3、缓存空对象，将null变为一个值，设置较小的过期时间 缓存雪崩 ​ redis服务器中大量key在同一时间失效，导致大量请求进入数据库导致连接异常 解决方法：1、加锁排队；2、建立备份缓存，缓存A设置超时时间，缓存B不设置超时时间，先读缓存A，缓存A没有查缓存B，查到更新缓存A和缓存B；3、给key值设置超时时间时设置随机的时间，避免同时失效]]></content>
      <categories>
        <category>面试相关</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Shiro-密码散列加密]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F11%2F03%2FShiro-%E5%AF%86%E7%A0%81%E6%95%A3%E5%88%97%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[​ 在数据库中，密码应该避免以明文方式存储，散列算法一般用于生成数据的摘要信息，是一种不可逆的算法，一般适合存储密码之类的数据，常见的散列算法如MD5、SHA等。 ​ Shiro也为我们提供了多种散列算法，这里我们使用的是MD5 测试MD5加密Shiro提供了Hd5Hash这个类，其中通过重载构造器进行不同程度的加密。 一次MD5加密12Md5Hash md5Hash = new Md5Hash(passWord);System.out.println(md5Hash.toString()); 加盐12Md5Hash md5Hash2 = new Md5Hash(passWord,"amy");System.out.println(md5Hash2.toString()); ​ 一些md5解密网站很容易的通过散列值得到密码，即如果直接对密码进行散列相对来说破解更容易，此时我们可以加一些只有系统知道的干扰数据，如用户名或ID（即盐）；这样散列的对象是“密码+用户名”，这样生成的散列值相对来说更难破解。 加盐+散列次数*212Md5Hash md5Hash3 = new Md5Hash(passWord,"amy",2);System.out.println(md5Hash3.toString()); ​ 这时的散列格式或许为MD5(MD5())，将密码+用户名的散列密码再进行散列加密，此时作为存储密码将更加复杂，提高安全性。 在Realm中应用将盐和散列后的值存在数据库中，自动realm从数据库取出盐和加密后的值由shiro完成密码校验。 添加配置文件指定realm和散列加密信息1234567891011[main]#定义凭证匹配器credentialsMatcher=org.apache.shiro.authc.credential.HashedCredentialsMatcher#散列算法credentialsMatcher.hashAlgorithmName=md5#散列次数credentialsMatcher.hashIterations=1#将凭证匹配器设置到realmmyRealm=com.mani.PasswordRealmmyRealm.credentialsMatcher=$credentialsMatchersecurityManager.realms=$myRealm 自定义Realm12345678910111213141516171819protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; //获取用户名 String principal = (String) token.getPrincipal(); // 模拟数据库中的用户名 if(!"zhangsan".equals(principal))&#123; //表示找不到用户,返回空认证信息 return null; &#125; // 模拟数据库中的密码 String password = "2a238413f0931a219bf70721c8e741d8"; // 盐,在数据库中存储的 String salt = "zhangsan"; /** * 返回认证信息由父类AuthenticatingRealm进行认证 * 返回认证信息的时候需要把盐也一并的传过去 */ SimpleAuthenticationInfo simpleAuthenticationInfo = new SimpleAuthenticationInfo(principal, password, ByteSource.Util.bytes(salt),getName()); return simpleAuthenticationInfo;&#125; 进行认证测试 1234567891011121314151617181920@Testpublic void testAuthenticate() &#123; Subject subject = SecurityUtils.getSubject(); // 判断当前用户未认证 if (!subject.isAuthenticated()) &#123; // token中的参数相当于用户登录传入的账户和密码 UsernamePasswordToken token = new UsernamePasswordToken("zhangsan", "root"); try &#123; // 登录 subject.login(token); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; // 输出认证信息：true或false System.out.println(subject.isAuthenticated()); // 登出 subject.logout(); System.out.println(subject.isAuthenticated()); &#125;&#125; 结果： AuthenticatingRealm会将我们传入的密码进行加盐散列加密后与模拟数据库中的密码进行匹配…]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Shiro框架-开始]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F11%2F03%2FShiro%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[简介​ Apache Shiro是一个强大易用的Java安全框架，提供了认证、授权、加密和会话管理功能，相比于Spring Security，Shiro的功能可能并没有那么强大，但是使用相对于更加轻便。 ​ Shiro可以非常容易的开发出足够好的应用，其不仅可以用在JavaSE环境，也可以用在JavaEE环境。Shiro可以帮助我们完成：认证、授权、加密、会话管理、与Web集成、缓存等。 Authentication：身份认证/登录，验证用户是不是拥有相应的身份； Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是如Web环境的； Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储； Web Support：Web支持，可以非常容易的集成到Web环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率； Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。 核心概念Subject​ subject在这里其基本意思是“当前操作用户”，但是在安全领域中，subject即可以是人，也可以是第三方进程，网络爬虫，机器人…在Shiro集成的环境中在代码的任何地方可以轻松的获取Shiro Subject。 1Subject subject = SecurityUtils.getSubject(); ​ 一旦获得Subject，你就可以立即获得你希望用Shiro为当前用户做的90%的事情，如登录、登出、访问会话、执行授权检查等。 SecurityManager​ Subject的“幕后”推手是SecurityManager。Subject代表了当前用户的安全操作，SecurityManager则管理所有用户的安全操作。它是Shiro框架的核心，充当“保护伞”，引用了多个内部嵌套安全组件，它们形成了对象图。但是，一旦SecurityManager及其内部对象图配置好，它就会退居幕后。 Realm​ Realm充当了Shiro与应用安全数据间的“桥梁”或者“连接器”。也就是说，当切实与像用户帐户这类安全相关数据进行交互，执行认证（登录）和授权（访问控制）时，Shiro会从应用配置的Realm中查找很多内容。 ​ 从这个意义上讲，Realm实质上是一个安全相关的DAO：它封装了数据源的连接细节，并在需要时将相关数据提供给Shiro。当配置Shiro时，你必须至少指定一个Realm，用于认证和（或）授权。配置多个Realm是可以的，但是至少需要一个。 ​ Realm 可以理解为读取用户信息、角色及权限的 DAO，就是说SecurityManager要验证用户身份与权限，那么它需要从Realm获取相应的信息进行比较以确定用户身份是否合法；可以把Realm看成DataSource，即安全数据源。 第一个Shiro应用配置依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; 添加shiro-realm.ini配置文件1234#指定自定义realm的位置（在后面）myRealm= com.mani.MyRealm#指定securityManager的realm实现securityManager.realms=$myRealm 创建SecurityManagerFactory12// 加载配置文件，创建工厂Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory("classpath:shiro.ini"); 这里以面向接口的方式来接收工厂对象 通过工厂获取securityManager对象1securityManager = factory.getInstance(); 绑定securityManager12// 设置到运行环境中SecurityUtils.setSecurityManager(securityManager); 创建Subject实例1Subject subject = SecurityUtils.getSubject(); 至此我们Shiro的核心Subject，SecurityManager和Realm都已经拥有了，这里我自定义一个Realm 模拟用户登录认证操作12345678910111213141516171819public void testAuthenticate() &#123; Subject subject = SecurityUtils.getSubject(); // 判断当前用户未认证 if (!subject.isAuthenticated()) &#123; // token中的参数相当于用户登录传入的账户和密码 UsernamePasswordToken token = new UsernamePasswordToken("zhangsan", "666"); try &#123; // 登录 subject.login(token); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; // 输出认证信息：true或false System.out.println(subject.isAuthenticated()); // 登出 subject.logout(); System.out.println(subject.isAuthenticated()); &#125;&#125; 自定义Realm123456789101112131415161718192021222324252627public class MyRealm extends AuthorizingRealm &#123; @Override public String getName() &#123; return "MyRealm"; &#125; @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; return null; &#125; @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; // 获取传入的用户名 String name = (String) token.getPrincipal(); // 模拟数据库，真的用户名 String trueName = "zhangsan"; if (!trueName.equals(name))&#123; return null; &#125; // 数据库中的密码 String passWord = "666"; // info对象表示realm登录比对信息 SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(name,passWord,getName()); return info; &#125;&#125; 结果： 认证解析​ 在登录login方法处打上一个断点，进入方法-&gt; ​ Subject subject = securityManager.login(this, token); ​ 发现调用了SecurityManager的login方法，并将subject和token传入，再进入这个方法-&gt; ​ 进行认证操作-&gt; ​ securityManger将认证操作托管给了一个认证器-&gt; ​ 在这里才真正开始认证-&gt; ​ 从字面上的看出在这里它要获取AuthenticationInfo对象-&gt; ​ 不出意外跳到了我们的自定义realm中，将AuthenticationInfo返回-&gt;&gt;&gt; ​ 基本上这一次认证就完成了]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hadoop-HDFS]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F11%2F01%2FHadoop-HDFS%2F</url>
    <content type="text"><![CDATA[Hadoop 是分布式的系统架构，是 Apache 基金会顶级金牌项目 Hadoop组成分布式存储系统 HDFS （ Hadoop Distributed File System ） 分布式存储系统 提供了 高可靠性、高扩展性和高吞吐率的数据存储服务 分布式计算框架 MapReduce 分布式计算框架（计算向数据移动） 具有 易于编程、高容错性和高扩展性等优点。 分布式资源管理框架 YARN（ Yet Another ResourceManagement） 负责集群资源的管理和调度 分布式文件存储系统HDFS​ 分布式存储系统HDFS，主要解决大数据的存储问题。 HDFS架构图 HDFS 数据存储单元（block）文件被切分成固定大小的数据块 block 默认数据块大小为 128MB (hadoop2.x)，可自定义配置 若文件大小不到 128MB ，则单独存成一个 block 一个文件存储方式 按大小被切分成若干个 block ，存储到不同节点上 默认情况下每个 block 都有 3 个副本 Block 大小和副本数通过 Client 端上传文件时设置，文件上传成功后副本数可以变更， Block Size 不可变更 hdfs 存储模型：字节 文件线性切割成块（Block） :偏移量 offset （byte） Block 分散存储在集群节点中 单一文件 Block 大小一致，文件与文件可以不一致 Block 可以设置副本数，副本分散在不同节点中，副本数不要超过节点数量 文件上传可以设置 Block 大小和副本数 已上传的文件 Block 副本数可以调整，大小不变 只支持一次写入多次读取，同一时刻只有一个写入者 可以 append 追加数据 NameNode （简称NN）NameNode 主要功能 接受客户端的读/写服务 收集 DataNode 汇报的 Block 列表信息 基于内存存储 ： 不会和磁盘发生交换 只存在内存中 持久化 NameNode 保存 metadata 信息 文件 owership(归属)和 permissions(权限) 文件大小，时间 （Block 列表： Block 偏移量），位置信息 Block 保存在哪个 DataNode 信息（由 DataNode 启动时上报,不保存在磁盘） NameNode 持久化 NameNode 的 metadate 信息在启动后会加载到内存 metadata 存储到磁盘文件名为”fsimage” Block 的位置信息不会保存到 fsimage edits 记录对 metadata 的操作日志 fsimage 保存了最新的元数据检查点,类似快照。 editslog 保存自最新检查点后的元信息变化， 从最新检查点后， hadoop 将对每个文件的操作都保存在edits 中。 客户端修改文件时候，先写到 editlog，成功后才更新内存中的metadata 信息。 Metadata = fsimage + editslog DataNode（DN） 本地磁盘目录存储数据（Block），文件形式 同时存储 Block 的元数据信息文件 启动 DN 进程的时候会向 NameNode 汇报 block 信息 通过向 NN 发送心跳保持与其联系（3 秒一次），如果 NN 10分钟没有收到 DN 的心跳，则认为其已经lost，并 copy 其上的 block 到其它 DN SecondaryNameNode（SNN）​ 它的主要工作是帮助 NN 合并 edits log 文件，减少 NN 启动时间,它不是 NN 的备份（但可以做备份)。 SNN 执行合并时间和机制 根据配置文件设置的时间间隔 fs.checkpoint.period 默认 3600 秒。 根据配置文件设置 edits log 大小 fs.checkpoint.size规定 edits 文件的最大值默认是 64MB SecondaryNameNode SNN 合并流程 ​ 首先是 NN 中的 Fsimage 和 edits 文件通过网络拷贝，到达SNN 服务器中，拷贝的同时，用户的实时在操作数据，那么 NN中就会从新生成一个 edits 来记录用户的操作，而另一边的 SＮＮ将拷贝过来的 edits 和 fsimage 进行合并，合并之后就替换NN 中的 fsimage。之后 NN 根据 fsimage 进行操作（当然每隔一段时间就进行替换合并，循环）。当然新的 edits 与合并之后传输过来的 fsimage 会在下一次时间内又进行合并。 Block 的副本放置策略 第一个副本：放置在上传文件的 DN；如果是集群外提交，则随机挑选一台磁盘不太满， CPU 不太忙的节点。 第二个副本：放置在于第一个副本不同的机架的节点上。 第三个副本：与第二个副本相同机架的不同节点。 更多副本：随机节点 HDFS 读写流程 HDFS 写流程Client： 切分文件 Block 按 Block 线性和 NN 获取 DN 列表（副本数） 验证 DN 列表后以更小的单位(packet)流式传输数据 ​ 各节点，两两通信确定可用 Block 传输结束后： ​ DN 向 NN 汇报 Block 信息 ​ DN 向 Client 汇报完成 ​ Client 向 NN 汇报完成 获取下一个 Block 存放的 DN 列表 …………….. 最终 Client 汇报完成 NN 会在写流程更新文件状态 读文件过程 Client： 和 NN 获取一部分 Block 副本位置列表 线性和 DN 获取 Block，最终合并为一个文件 在 Block 副本列表中按距离择优选取 HDFS 的优缺点优点 高容错性 数据自动保存多个副本 副本丢失后，自动恢复 适合批处理 移动计算而非数据 数据位置暴露给计算框架（Block 偏移量） 适合大数据处理 GB 、 TB 、甚至 PB 级数据 百万规模以上的文件数量 10K+ 节点 可构建在廉价机器上 通过多副本提高可靠性 提供了容错和恢复机制 缺点 低延迟高数据吞吐访问问题比如支持秒级别反应，不支持毫秒级延迟与高吞吐率问题（吞吐量大但有限制于其延迟） 小文件存取占用 NameNode 大量内存寻道时间超过读取时间 并发写入、文件随机修改一个文件只能有一个写者仅支持 append Hadoop伪分布式搭建 jdk 安装，配置环境变量 vi /etc/profile 12export JAVA_HOME=/opt/dlh/jdk1.7.0_75PATH=$PATH:$JAVA_HOME/bin ssh 免密钥（本机） 12ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsacat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys 上传 hadoop.tar.gz 到服务器 解压部署包 到/opt/dlh 目录下 vi /etc/profile 12export HADOOP_PREFIX=/opt/dlh/hadoop-2.6.5PATH=$PATH:$JAVA_HOME/bin:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin /opt/dlh/hadoop-2.6.5/etc/hadoop 目录 hadoop-env.sh 1JAVA_HOME=/opt/dlh/jdk1.7.0_75 core-site.xml 12345678&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://192.168.32.222:9000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/var/dlh/hadoop/local&lt;/value&gt;&lt;/property&gt; hdfs-site.xml 12345678&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;192.168.32.222:50090&lt;/value&gt;&lt;/property&gt; vi slaves（datanode 节点）192.168.32.222 格式化 hdfs namenode -format 启动 start-dfs.sh 查看服务进程启动了么？ jpsSecondaryNameNodeNameNodeDataNodeJps 访问 192.168.32.222:50070确保防火墙关闭（service iptables stop） hdfs dfs -mkdir /user hdfs dfs -ls /user hdfs dfs 命令： 12345hdfs dfs -put fileName[本地文件名] PATH【hdfs 的文件路径】hdfs dfs -du [-s][-h]URI[URI ...] 显示文件(夹)大小.hdfs dfs -mkdir[-p] &lt;paths&gt; 创建hdfs dfs -rm -r /myhadoop1.0 删除hdfs dfs -cp [-f][-p|-p[topax]]URI[URI...]&lt;dest&gt;复制文件(夹)，可以覆盖，可以保留原有权限信息 产生 100000 条数据测试：for i in seq 100000;do echo “hello hadoop$i” &gt;&gt; test.txt;done]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F10%2F30%2FNginx%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[什么是 Nginx？ ​ Nginx 是一款轻量级的 Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。由俄罗斯的程序设计师Igor Sysoev 所开发，其特点是占有内存少， 并发能力强， nginx 的并发能力确实在同类型的网页服务器中表现非常好。 ​ 2004 年 10 月 4 日 第一个公开版本 0.1.0 发布。其将源代码以类 BSD 许可证的形式发布。 ​ 官方测试 nginx 能够支撑 5 万并发链接，并且 CPU、内存等资源消耗却非常低，运行非常稳定 。 Nginx 和 apache 的优缺点 nginx 相对于 apache 的优点： ​ 轻量级，同样起 web 服务，比 apache 占用更少的内存及资源高并发，nginx 处理请求是异步非阻塞（如前端 ajax） 的，而 apache 则是阻塞型的，在高并发下 nginx 能保持低资源低消耗高性能高度模块化的设计，编写模块相对简单还有，它社区活跃，各种高性能模块出品迅速（十几年时间发展） apache 相对于 nginx 的优点： ​ Rewrite 重写 ，比 nginx 的 rewrite 强大模块超多，基本想到的都可以找到少 bug ， nginx 的 bug 相对较多。（出身好起步高） Nginx 配置简洁, Apache 复杂 安装Nginx安装依赖依赖 gcc openssl-devel pcre-devel zlib-devel安装： yum -y install gcc openssl-devel pcre-devel zlib-devel 解压文件解压： tar -zxvf nginx-1.8.1.tar.gz configure 配置进入解压后的源码目录，然后执行 configure 命令进行配置./configure –prefix=/usr/soft/nginx (设置编译后的文件目录) 编译并安装make &amp;&amp; make install 安装好后，会在/usr/soft 下生成 nginx 目录(这是我编译前指定的)，这个目录就是 nginx 的软件了。 nginx 命令启动命令 ： nginx_home/sbin/nginx 启动后，访问虚拟机的 80 端口，可查看到以下界面 Nginx 默认监听 80 端口，当出现以上信息，说明安装启动成功 一旦 nginx 启动，就可以通过调用带有-s 参数的可执行文件来控制它。使用语法： nginx -s 信号 信号可以是下列之一：​ stop - 快速关机​ quit - 优雅的关机​ reload - 重新加载配置文件​ reopen - 重新打开日志文件例如，要停止 nginx 进程并等待工作进程完成当前请求的服务，可以执行以下命令： nginx -s quit Nginx 配置nginx 默认配置详解12345678910111213141516171819202122232425262728293031323334#进程数，建议设置和 CPU 个数一样或 2 倍worker_processes 2;#日志级别error_log logs/error.log warning;(默认 error 级别)nginx 启动后的 pid 存放位置#pid logs/nginx.pid;events &#123; #配置每个进程的连接数，总的连接数= worker_processes * worker_connections #根据物理内存大小来配置，默认 1024 worker_connections 10240;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; #连接超时时间，单位秒 keepalive_timeout 65; server &#123; listen 80; server_name localhost #默认请求 location / &#123; root html; #定义服务器的默认网站根目录位置 index index.php index.html index.htm; #定义首页索引文件的名称 &#125; #定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 负载均衡配置：nginx 支持以下负载均衡机制（或方法）： 循环 - 对应用程序服务器的请求以循环方式分发， 最少连接数 - 将下一个请求分配给活动连接数最少的服务器 ip-hash - 哈希函数用于确定下一个请求（基于客户端的 IP地址）应该选择哪个服务器。 默认负载平衡配置使用 nginx 进行负载平衡的最简单配置可能如下所示： 1234567891011121314http &#123; upstream frame&#123; server srv1.example.com; server srv2.example.com; server srv3.example.com; &#125; server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://frame; &#125; &#125;&#125; ​ 在上面的示例中，在 srv1-srv3 上运行相同应用程序的 3 个实例。如果没有专门配置负载均衡方法，则默认为循环法。所有请求都被 代理到服务器组 ss，并且 nginx 应用 HTTP 负载平衡来分发请求。 加权负载平衡 通过使用服务器权重，还可以进一步影响nginx负载均衡算法，谁的权重越大，分发到的请求就越多。12345upstream frame &#123; server srv1.example.com weight=3; server srv2.example.com; server srv3.example.com;&#125; 最少连接负载平衡在连接负载最少的情况下， nginx 会尽量避免将过多的请求分发给繁忙的应用程序服务器，而是将新请求分发给不太繁忙的服务器，避免服务器过载。123456upstream frame &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; 会话持久性上述的循环或最少连接数的负载平衡方法，每个后续客户端的请求都可能被分发到不同的服务器。不能保证相同的客户端总是定向到相同的服务器。如果需要将客户端绑定到特定的应用程序服务器 - 换句话说，就是始终选择相同的服务器而言， 就要使客户端的会话“粘滞”或“持久” 。 ip-hash 负载平衡机制就是有这种特性。 使用 ip-hash，客户端的 IP 地址将用作散列键，以确定应该为客户端的请求选择服务器组中的哪台服务器。 此方法可确保来自同一客户端的请求将始终定向到同一台服务器，除非此服务器不可用。123456upstream frame&#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; Nginx访问控制Nginx 还可以对 IP 的访问进行控制， allow 代表允许， deny 代表禁止12345678location / &#123; deny 192.168.78.1; allow 192.168.78.0/24; allow 10.1.1.0/16; allow 192.168.1.0/32; deny all; proxy_pass http://frame;&#125; 从上到下的顺序，匹配到了便跳出。如上的例子先禁止了 192.168.78.1，接下来允许了 3 个网段，其中包含了一个 ipv6，最后未匹配的 IP 全部禁止访问 虚拟主机何为虚拟主机​ 虚拟主机是指在网络服务器上分出一定的磁盘空间，用户可以租用此部分空间，以供用户放置站点及应用组件，提供必要的数据存放和传输功能。 ​ 说白了虚拟主机就是把一台物理服务器划分成多个“虚拟”的服务器，各个虚拟主机之间完全独立，在外界看来，每一台虚拟主机和一台单独的主机的表现完全相同。所以这种被虚拟化的逻辑主机被形象地称为“虚拟主机”。 优点： ​ 由于多台虚拟主机共享一台真实主机的资源，每个虚拟主机用户承受的硬件费用、网络维护费用、通信线路的费用均大幅度降低。许多企业建立网站都采用这种方法，这样不仅大大节省了购买机器和租用专线的费用， 网站服务器服务器管理简单，诸如软件配置、防病毒、防攻击等安全措施都由专业服务商提供，大大简化了服务器管理的复杂性；同时也不必为使用和维护服务器的技术问题担心，更不必聘用专门的管理人员。 类别： 1、基于域名的虚拟主机，通过域名来区分虚拟主机 2、基于端口的虚拟主机，通过端口来区分虚拟主机 3、基于 ip 的虚拟主机， 很少用 基于域名的虚拟主机1234567891011121314151617181920212223242526http &#123; upstream frame1&#123; server srv1.example.com; server srv2.example.com; &#125; upstream frame2&#123; server srv3.example.com; server srv4.example.com; &#125; server &#123; listen 80; //访问 xt1.com 的时候，会把请求导到 frame1 的服务器组里 server_name xt1.com; location / &#123; proxy_pass http://frame1; &#125; &#125; server &#123; listen 80; //访问 xt2.com 的时候，会把请求导到 frame2 的服务器组里 server_name xt2.com; location / &#123; proxy_pass http://frame2; &#125; &#125;&#125; 注意： 基于域名的虚拟机主机 在模拟应用场景时，需要在 windows 系统的 hosts文件里配置域名映射。 （C:\Windows\System32\drivers\etc\hosts） 基于端口的虚拟主机1234567891011121314151617181920212223242526http &#123; upstream frame1&#123; server srv1.example.com; server srv2.example.com; &#125; upstream frame2&#123; server srv3.example.com; server srv4.example.com; &#125; server &#123; //当访问 nginx 的 80 端口时，将请求导给 frame1 组 listen 80; server_name localhost; location / &#123; proxy_pass http://frame1; &#125; &#125; server &#123; //当访问 nginx 的 81 端口时，将请求导给 frame2 组 listen 81; server_name localhost; location / &#123; proxy_pass http://frame2; &#125; &#125;&#125; 正向代理和反向代理正向代理​ 举个栗子： 我是一个用户，我访问不了某网站，但是我能访问一个代理服务器，这个代理服务器呢,他能访问那个我不能访问的网站，于是我先连上代理服务器,告诉他我需要那个无法访问网站的内容，代理服务器去取回来,然后返回给我。 像我们经常通过 vpn 访问国外的网站，此时就是正向代理。 客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的 IP 地址，还有代理程序的端口。 反向代理​ 反向代理（Reverse Proxy） 方式是指以代理服务器来接受 internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器 ​ 反向代理隐藏了真实的服务端，当我们请求 www.baidu.com 的时候，就像拨打 10086 一样，背后可能有成千上万台服务器为我们服务，但具体是哪一台，你不知道，也不需要知道，你只需要知道反向代理服务器是谁就好了， www.baidu.com 就是我们的反向代理服务器，反向代理服务器会帮我们把请求转发到真实的服务器那里去。 Nginx 就是性能非常好的反向代理服务器，用来做负载均衡。 Nginx 的 session 的一致性问题​ http 协议是无状态的，即你连续访问某个网页 100 次和访问 1次对服务器来说是没有区别对待的，因为它记不住你。那么，在一些场合，确实需要服务器记住当前用户怎么办？比如用户登录邮箱后，接下来要收邮件、写邮件，总不能每次操作都让用户输入用户名和密码吧，为了解决这个问题， session 的方案就被提了出来，事实上它并不是什么新技术，而且也不能脱离 http 协议以及任何现有的 web 技术session 的常见实现形式是会话cookie（session cookie），即未设置过期时间的 cookie，这个 cookie 的默认生命周期为浏览器会话期间，只要关闭浏览器窗口， cookie 就消失了。 Session 共享​ 首先我们应该明白，为什么要实现共享，如果你的网站是存放在一个机器上，那么是不存在这个问题的，因为会话数据就在这台机器，但是如果你使用了负载均衡把请求分发到不同的机器呢？这个时候会话 id 在客户端是没有问题的，但是如果用户的两次请求到了两台不同的机器，而它的 session 数据可能存在其中一台机器，这个时候就会出现取不到 session 数据的情况，于是 session 的共享就成了一个问题 。 Session 一致性解决方案 session 复制 tomcat 本身带有复制 session 的功能。 共享 session 需要专门管理 session 的软件， memcached 缓存服务，可以和 tomcat 整合，帮助 tomcat共享管理 session。 安装 memcached 安装 memcached 内存数据库 yum – y install memcached 可以用 telnet localhost 11211 web 服务器连接 memcached 的 jar 包拷贝到 tomcat 的 lib 配置 tomcat 的 conf 目录下的 context.xml 123456789&lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"memcachedNodes="n1:192.168.17.9:11211"sticky="true"lockingMode="auto"sessionBackupAsync="false"requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"sessionBackupTimeout="1000"transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory" /&gt; ​ 配置 memcachedNodes 属性，配置 memcached 数据库的 ip 和端口，默认 11211，多个的话用逗号隔开。​ 目的是让 tomcat 服务器从 memcached 缓存里面拿 session 或者是放 session 修改 index.jsp，取 sessionid 看一看 12345678&lt;%@ page language="java" contentType="text/html;charset=UTF-8" pageEncoding="UTF-8"%&gt; &lt;html lang="en"&gt; SessionID:&lt;%=session.getId()%&gt; &lt;/br&gt; SessionIP:&lt;%=request.getServerName()%&gt; &lt;/br&gt; &lt;h1&gt;tomcat1&lt;/h1&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring-Session+Redis实现Session共享]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F10%2F28%2FSpring-Session%E5%AE%9E%E7%8E%B0Session%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[场景1、通常我们在百度登陆后，百度贴吧、百度文库这些子系统也会自动登录，此时用户信息是如何在多个子系统中实现共享？ 2、一个大型的互联网项目肯定不会只有一台服务器，通常是以集群的方式存在，多台服务器同时跑相同的服务。假设采用Nginx分发轮询策略，当第一台服务器用户登录后，轮询到别的服务器，别的服务器上没有该用户的Session，如何保证当前会话保持。 其中一个方案就是将当前用户的Session存入缓存（Redis、memcached等 ）中 实现Session共享添加依赖123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!-- spring mvc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- web开发要有servlet --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--spring-session--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;version&gt;1.3.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt;&lt;/dependency&gt;&lt;!--redis--&gt;&lt;dependency&gt; &lt;groupId&gt;biz.paluch.redis&lt;/groupId&gt; &lt;artifactId&gt;lettuce&lt;/artifactId&gt; &lt;version&gt;3.5.0.Final&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.3.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- jackson --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.8.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt; &lt;version&gt;1.9.12&lt;/version&gt;&lt;/dependency&gt; 在web.xml中添加session过滤器123456789&lt;!--session过滤器--&gt;&lt;filter&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 添加Redis的配置1234567891011@EnableRedisHttpSessionpublic class Config &#123; @Bean public LettuceConnectionFactory connectionFactory() &#123; LettuceConnectionFactory lettuceConnectionFactory = new LettuceConnectionFactory(); lettuceConnectionFactory.setHostName("192.168.4.189"); lettuceConnectionFactory.setPassword("123456"); lettuceConnectionFactory.setPort(6379); return lettuceConnectionFactory; &#125;&#125; 此时spring-session会将拦截到的session存到redis中统一管理session，达到session共享 编写Controller层代码进行测试123456789101112131415@RestControllerpublic class TestController &#123; @GetMapping("set") public String set(HttpSession session) &#123; session.setAttribute("abc", "hello"); return "hello"; &#125; @GetMapping("get") public String get(HttpSession session) &#123; String val = (String) session.getAttribute("abc"); return val; &#125;&#125; 我们将程序跑在两个不同端口的tomcat服务器来进行测试 首先跑8080端口进行set设置作用域 我们查看redis服务器中的key值 此时已经将session存到缓存中了 然后我们启用8081端口，get获取session，如果拿到了即达到了session共享]]></content>
      <categories>
        <category>项目经验</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JDK8-Lambda]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F07%2F27%2FJDK8-Lambda%2F</url>
    <content type="text"><![CDATA[​ Lambda 表达式是一个匿名函数， 我们可以把 Lambda 表达式理解为是一段可以传递的代码（将代码像数据一样进行传递）。 可以写出更简洁、 更灵活的代码。 作为一种更紧凑的代码风格， 使得 Java 语言表达能力得到了提升。Java8 中引入了一个新的操作符”-&gt;”该操作符称为箭头操作符或 Lambda 操作符， 箭头操作符将 Lambda表达式拆分为两部分：​ 左侧： Lambda 表达式的参数列表。 对应接口中抽象方法的参数列表。​ 右侧： Lambda 表达式中所需要执行的功能， 即 Lambda 体。 对应接口中抽象方法的实现 。 基础语法无参数无返回值12345678910111213141516@Testpublic void test01() &#123; // 以前的写法 Runnable r1 = new Runnable() &#123; @Override public void run() &#123; System.out.println("线程1在奔跑"); &#125; &#125;; r1.run(); System.out.println("-----------------"); // 无参数，无返回值 // 括号相当于new Runnable()；-&gt; 相当于run方法；后面是方法体 Runnable r2 = () -&gt; System.out.println("线程2在奔跑"); r2.run();&#125; 这里的lambda表达式中，括号相当于new Runnable()；-&gt; 相当于run方法；后面是方法体 有一个参数，无返回值12345678910/** * 有一个参数，无返回值 */@Testpublic void test02() &#123; Consumer&lt;String&gt; consumer = (s) -&gt; System.out.println(s); consumer.accept("hello");&#125;// 只有一个参数时，括号可以不写，方法体中只有一行语句时，花括号可以不写Consumer&lt;String&gt; consumer = s -&gt; System.out.println(s); 有两个参数，方法体中有多条语句1234567891011/** * 有两个参数，方法体中有多条语句 */@Testpublic void test03() &#123; Comparator&lt;Integer&gt; comparator = (x, y) -&gt; &#123; System.out.println("hello"); return Integer.compare(x, y); &#125;; System.out.println(comparator.compare(4, 3));&#125; Lambda表达式需要“函数式接口”的支持​ 接口中只有一个抽象方法的接口，称为函数式接口，其中静态方法和默认方法不算。 ​ 内置的函数式接口都有注解@FunctionalInterface修饰，可以使用该注解检查是否是函数式接口。 自定义函数式接口1234567891011121314151617181920212223242526272829/** * 自定义函数式接口 * （只有一个抽象方法的接口，可以使用注解@FunctionalInterface修饰检查） */@Testpublic void test05() &#123; // 使用lamad表达式之前的形式 Integer res = operation(200, new MyFunction&lt;Integer&gt;() &#123; @Override public Integer getValue(Integer o) &#123; return o * o; &#125; &#125;); System.out.println(res); // 使用lamad表达式之后的形式 Integer result = operation(100, x -&gt; x * x); System.out.println(result);&#125;private Integer operation(Integer num, MyFunction&lt;Integer&gt; mf) &#123; return mf.getValue(num);&#125;@FunctionalInterfacepublic interface MyFunction&lt;T&gt; &#123; public T getValue(T o);&#125; 四大内置核心函数式接口消费性接口：需要给它一个参数 1234567891011121314151617/** * Consumer&lt;T&gt;消费型接口 * void accept(T t); */@Testpublic void test06() &#123; Consumer&lt;Integer&gt; consumer = new Consumer&lt;Integer&gt;() &#123; @Override public void accept(Integer integer) &#123; System.out.println(integer); &#125; &#125;; consumer.accept(3); Consumer&lt;Integer&gt; consumer1 = (x) -&gt; System.out.println(x &lt; 2); consumer1.accept(6);&#125; 供给型接口：自己给你数据 1234567891011121314151617181920212223242526272829/** * Supplier&lt;T&gt;供给型接口 * T get(); */@Testpublic void test07() &#123; Supplier&lt;Integer&gt; supplier = new Supplier&lt;Integer&gt;() &#123; @Override public Integer get() &#123; return (int) (Math.random() * 100); &#125; &#125;; System.out.println(supplier.get()); Supplier&lt;Double&gt; sup = () -&gt; (Double) (Math.random() * 100); System.out.println(sup.get());&#125;// 向集合中添加十个随机数并遍历 @Test public void test08() &#123; Supplier&lt;Integer&gt; supplier = () -&gt; (int) (Math.random() * 10); List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; list.add(supplier.get()); &#125; for (Integer integer : list)&#123; System.out.print(integer+" "); &#125; &#125; 函数型接口：给它一个数据，返回一个数据，泛型中的类型要和传入返回的类型一致 12345678910/** * Function&lt;T,R&gt;函数型接口 * R apply(T t); */@Testpublic void test09()&#123; String str = "123456"; Function&lt;String,Integer&gt; function = (s) -&gt; Integer.valueOf(s); System.out.println(function.apply(str));&#125; 断言型接口：和其他断言一样，返回判断结果boolean类型 123456789/** * Predicate&lt;T&gt;断言型接口 * boolean test(T t) */@Testpublic void test10()&#123; Predicate&lt;String&gt; predicate = (s)-&gt; s.contains("a"); System.out.println(predicate.test("test"));&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[登录限制页面回退实现]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F07%2F19%2F%E7%99%BB%E5%BD%95%E9%99%90%E5%88%B6%E9%A1%B5%E9%9D%A2%E5%9B%9E%E9%80%80%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[场景​ 在某些页面的跳转中需要验证登录才可以继续进行，比如实名认证页面，用户必须登录，没有登录就会被拦截器拦截，此时当用户登录后跳转的直接就是实名认证页面。 实现思路 ​ 在拦截器执行拦截跳转到登录页面之前，获取请求的路径，将路径存入session作用域中 ​ 在登录操作的Controller方法中获取该session，判断session是否为空，不为空则直接跳转该路径视图 代码通过Aop切面+自定义注解做未登录拦截 12345678910111213141516171819202122232425262728293031323334353637383940@Component@Aspectpublic class LoginInterceptor &#123; @Resource private HttpServletRequest request; @Pointcut("@annotation(com.dlh.xmjf.web.aop_adaptor.annotation.RequireLogin)") public void cut() &#123;&#125; @Around("cut()") public Object around(ProceedingJoinPoint pjp) throws Throwable &#123; Object result = null; // 通过作用域拿到userModel对象，只有登录之后才会存在，从而判断是否登录 UserModel userModel = (UserModel) request.getSession().getAttribute(XmjfConstant.LOGIN_SESSION_KEY); if (null == userModel) &#123; // 拿到方法签名 MethodSignature methodSignature = (MethodSignature) pjp.getSignature(); Method method = methodSignature.getMethod(); // 获取RequestMapping等映射注解，因为可能三种注解混合使用了 RequestMapping requestMapping = method.getAnnotation(RequestMapping.class); GetMapping getMapping = method.getAnnotation(GetMapping.class); PostMapping postMapping = method.getAnnotation(PostMapping.class); String requestPath = ""; if (null != requestMapping) &#123; requestPath += requestMapping.value()[0]; &#125; if (null != getMapping) &#123; requestPath += getMapping.value()[0]; &#125; if (null != postMapping) &#123; requestPath += postMapping.value()[0]; &#125; request.getSession().setAttribute(XmjfConstant.LOGIN_BEFORE_SESSION, requestPath); throw new LoginException("未登录"); &#125; result = pjp.proceed(); return result; &#125;&#125; Controller层的登录代码 1234567891011121314@PostMapping("user/login")@ResponseBodypublic ResultInfo login(String phone, String password, HttpServletRequest request) &#123; UserModel userModel = userService.login(phone, password); request.getSession().setAttribute(XmjfConstant.LOGIN_SESSION_KEY, userModel); String beforeView = (String) request.getSession().getAttribute(XmjfConstant.LOGIN_BEFORE_SESSION); if (null != beforeView) &#123; // 因为是前台是ajax请求，所以返回一个beforeView，通过判断是否存在从而是否跳转相应页面 // success是resultInfo对象 return success(200, beforeView); &#125; else &#123; return success(); &#125;&#125;]]></content>
      <categories>
        <category>项目经验</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Aop+自定义注解+Redis实现缓存]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F06%2F08%2FAop-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3-Redis%E5%AE%9E%E7%8E%B0%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[​ 相比于从数据库中查询，从缓存中读取数据无疑更加快速，当用户发送相同的请求时使用缓存，既可以减少数据库的压力，又可以加快查询速度。 首先先讲一下在Java代码中加入redis缓存的步骤 准备一个key，key不可重复，常与参数相结合，这样可以通过判断用户是发送的请求参数是否改变。 通过key从缓存中查询数据，有缓存则直接将缓存数据返回。 redis服务器中没有缓存，则从数据库中查询，再将结果以该key为键存入缓存，返回。 我们往往在很多地方需要使用到缓存，每次都要写上这些步骤无益于我们的代码复用。 ​ 所以我在这里引入了Aop面向切面编程，通过拦截自定义注解（在需要添加缓存的方法上添加），拦截后查询或添加缓存。 准备自定义注解12345678910111213@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface RequireCache &#123; // 用于存放形参名，数组，有多个形参则需要存多个 String[] value() default ""; // 用户存放key的开头 String name() default ""; // 如果参数为javabean，则需要传递，必须要有默认值否则必须写入 Class[] type() default Integer.class;&#125; 准备切面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/*@Component@Aspect*/public class RequireCacheHandler &#123; @Resource private RedisTemplate&lt;String, Object&gt; redisTemplate; @Pointcut("@annotation(com.dlh.xmjf.server.aop_adaptor.annotation.RequireCache)") public void cut() &#123; &#125; @Around("cut()") public Object around(ProceedingJoinPoint pjp) throws Throwable &#123; Object result = null; // 通过pjp拿到方法签名 MethodSignature methodSignature = (MethodSignature) pjp.getSignature(); Signature signature = pjp.getSignature(); // 拿到方法 Method method = methodSignature.getMethod(); // 获得目标对象的方法（因为该service实现了接口，动态代理会代理到接口上，接口并没有注解） Method realMethod = pjp.getTarget().getClass().getDeclaredMethod(signature.getName(), method.getParameterTypes()); // 拿到注解 RequireCache requireCache = realMethod.getAnnotation(RequireCache.class); // 拿到注解中的value和name和class类型 String[] value = requireCache.value(); String name = requireCache.name(); Class[] types = requireCache.type(); // 拿到参数值 Object[] args = pjp.getArgs(); // 定义StringBuffer用于存放key StringBuffer key = new StringBuffer(); // 先将缓存开头名存入 key.append(name); if (value.length &gt; 0 &amp;&amp; args.length &gt; 0 &amp;&amp; value.length == args.length) &#123; for (String paramName : value) &#123; for (Object arg : args) &#123; String str = "::" + paramName + "::"; key.append(str); // 排除Integer和String类型等等..的参数,则为javabean对象 if (!(arg instanceof Integer) &amp;&amp; !(arg instanceof String)) &#123; for (Class type : types) &#123; // 通过反射调用get方法拿到值 Field[] fields = type.getDeclaredFields(); for (int i = 0; i &lt; fields.length; i++) &#123; Field field = fields[i]; field.setAccessible(true); String fieldName = field.getName(); // 排除序列化Id字段 if (!fieldName.equals("serialVersionUID")) &#123; String methodName = "get" + fieldName.substring(0, 1).toUpperCase() + fieldName.substring(1); Method declaredMethod = type.getDeclaredMethod(methodName); Object typeResult = declaredMethod.invoke(type.newInstance()); String str2 = ""; if (null != typeResult) &#123; str2 = "::" + typeResult + "::"; &#125; // 将字段名和值一一对应 key.append(fieldName); key.append(str2); &#125; field.setAccessible(false); &#125; &#125; &#125; else &#123; key.append(arg); &#125; &#125; &#125; &#125; // 拿到缓存中的内容 Object obj = redisTemplate.opsForValue().get(key.toString()); // 有缓存则直接返回 if (null != obj) &#123; return obj; &#125; result = pjp.proceed(); // 返回通知，存入缓存 redisTemplate.opsForValue().set(key.toString(), result); return result; &#125;&#125; ​ 经过测试，发现javabean对象反射取值并不顺利，前台传入的值取不到，默认值可以拿到。如果是Integer和String类型的参数则正常。这里我只将代码贴出保存下来，感觉思路是正确的，可能反射调用出现了问题。仅供参考。 以后完善之后，我会将调试一并发出。]]></content>
      <categories>
        <category>项目经验</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F05%2F29%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux目录结构 bin 存放二进制可执行文件(ls,cat,mkdir等) boot 存放用于系统引导时使用的各种文件 dev 用于存放设备文件 etc 存放系统配置文件 home 存放所有用户文件的根目录 lib 存放跟文件系统中的程序运行所需要的共享库及内核模块 mnt 系统管理员安装临时文件系统的安装点 opt 额外安装的可选应用程序包所放置的位置 proc 虚拟文件系统，存放当前内存的映射 root 超级用户目录 sbin 存放二进制可执行文件，只有root才能访问 tmp 用于存放各种临时文件 usr 用于存放系统应用程序，比较重要的目录/usr/local 本地管理员软件安装目录 var 用于存放运行时需要改变数据的文件 目录操作切换目录：cd + 目录路径 查看当前目录完整路径： pwd 返回父目录： cd .. 新建目录： mkdir+目录名 查看当前目录下拥有的子目录和文件： ls 查看当前目录下拥有的子目录和文件的详情信息：ls -l 或 ll 拷贝目录： cp source dest -r（递归） 删除目录： rmdir directory（只能删除空目录） 删除非空目录或文件： rm -rf dir 移动文件或目录：mv + 目录/文件名字 + 其他路径 更改文件或目录的名字：mv + 旧目录名字 + 新目录名字 文件操作创建一个空文件： touch 文件名 复制文件： cp 文件名 复制的文件名 复制目录： 复制文件，加个-r 参数，代表遍历复制 删除文件： rm 文件名（加 –f参数，直接删除，无需确认） 删除目录： 删除文件加上-r参数，遍历删除 查看目录：ls/ll ls -l == ll 查看目录下所有东西（包括隐藏文件）： ls -al （ll -a） 查看文件内容：cat filename（一次显示文件所有内容），当文件较大时，可以使用more 或 less ​ more filename 该命令一次显示一屏文本，满屏后停下来，并且在屏幕的底部出现一个提示信息，给出至今己显示的该文件的百分比。 按Space键，显示文本的下一屏内容。 按Enier键，只显示文本的下一行内容。 按B键，显示上一屏内容。 按Q键，退出。 ​ less命令 与 more命令 非常类似 less filename: h 显示帮助界面 Q 退出less 命令 u 向后滚动半页 d 向前翻半页 空格键 滚动一页 b 向后翻一页 回车键 滚动一行 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 上下键，向上一行，向下一行 从头打印文件内容： head -10 filename 打印文件1到10行 从尾部打印文件内容： tail -10 filename 打印文件最后10行 注意：tail 还经常可以拿来查看文件的内容变化 加-f参数，tail –f filename 查找文件或目录： find pathname –name filename（可以按正则表达式来查找） 文本编辑编辑模式 vi filename :打开或新建文件，并将光标置于第一行首 vi +n filename ：打开文件，并将光标置于第n行首 vi + filename ：打开文件，并将光标置于最后一行首 vi +/pattern filename：打开文件，并将光标置于第一个与 pattern匹配的串处 命令行模式 w保存 q退出 q!：不保存文件并退出vi 在VI的命令模式下输入“:set nu”，就有行号了。 在VI的命令模式下输入“:set nonu”，取消行号。 一般模式 yy 复制光标所在行(常用) nyy 复制光标所在行的向下n行，例如， 20yy则是复制20行(常用) p,P p为复制的数据粘贴在光标下一行， P则为粘贴在光标上一行(常用) G:光标移至第最后一行 nG：光标移动至第N行行首 n+：光标下移n行 n-：光标上移n行 H ：光标移至屏幕顶行 M ：光标移至屏幕中间行 L ：光标移至屏幕最后行 dd：删除 行 x或X：删除一个字符，x删除光标后的，而X删除光标前的 u 恢复前一个动作(常用) 删除第N行到第M行 : N,Md 文件传输将本地文件复制到远程机器 scp local_file remote_username@remote_ip:remote_folder 将本地目录复制到远程机器 scp -r local_folder remote_username@remote_ip:remote_folder 例：scp -r user root@192.168.32.100:/opt/ 网络指令查看网络配置信息：ifconfig 测试与目标主机的连通性：ping remote_ip 显示各种网络相关信息 命令：netstat -a (all)显示所有选项，默认不显示LISTEN相关 -t (tcp)仅显示tcp相关选项 -u (udp)仅显示udp相关选项 -n 拒绝显示别名，能显示数字的全部转化成数字。 -l 仅列出有在 Listen (监听) 的服務状态 -p 显示建立相关链接的程序名 -r 显示路由信息，路由表 -e 显示扩展信息，例如uid等 -s 按各个协议进行统计 -c 每隔一个固定时间，执行该netstat命令。 系统配置修改主机名 ​ vim /etc/sysconfig/network 重启机器后才能生效 ​ DNS配置 ​ hosts文件的作用相当于DNS，提供IP地址hostname的对应,可在这个文件里添加映射。域名解析 ​ vi /etc/hosts DNS服务器地址文件：/etc/resolv.conf 环境变量Linux系统的环境变量是在/etc/profile文件里配置。 ​ 首先考虑一个问题，问什么我们先前敲的yum, service,date,useradd等等，可以直接使用，系统怎么知道这些命令对应的程序是放在哪里的呢？ ​ 这是由于无论是windows系统还是linux系统，都有一个叫做path的系统环境变量，当我们在敲命令时，系统会到path对应的目录下寻找，找到的话就会执行，找不到就会报没有这个命令。如下图： 我们可以查看一下，系统一共在哪些目录里寻找命令对应的程序。 命令：echo $path ​ 服务操作列出所有服务：chkconfig 各数字代表的系统初始化级别含义： ​ 0：停机状态 1：单用户模式，root账户进行操作 2：多用户，不能使用net file system，一般很少用 3：完全多用户，一部分启动，一部分不启动，命令行界面 4：未使用、未定义的保留模式 5：图形化，3级别中启动的进程都启动，并且会启动一部分图形界面进程。 6：停止所有进程，卸载文件系统，重新启动(reboot) 这些级别中1、2、4很少用，相对而言0、3、5、6用的会较多。3级别和5级别除了桌面相关的进程外没有什么区别。为了减少资源占用，推荐都用3级别 注意 ：linux默认级别为3，不要把initdefault 设置为0 和 6 服务操作service 服务名 start/stop/status/restart 关闭防火墙 ：service iptables start/stop/status 服务初执行等级更改： chkconfig –level 2345 name off|on ​ 若不加级别，默认是2345级别 ​ 命令：chkconfig name on|off 进程操作查看所有进程： ps -aux ​ -a 列出所有 ​ -u 列出用户 ​ -x 详细列出，如cpu、内存等 ​ - e ​ -f 命令： ps - ef | grep ssh 查看所有进程里CMD是ssh 的进程信息 杀死进程： kill pid -9：强制杀死 ps 命令先查出对应程序的PID或PPID ，然后杀死掉进程 其他常用命令wget用法:wget [option] 网址 -O 指定下载保存的路径 tar ​ -z gzip进行解压或压缩，带.gz需要加，压缩出来.gz也需要加 ​ -x 解压 ​ -c 压缩 ​ -f 目标文件，压缩文件新命名或解压文件名 ​ -v 解压缩过程信息打印 解压命令：tar -zvxf xxxx.tar.gz 压缩命令：tar -zcf 压缩包命名 压缩目标]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring整合RabbitMQ]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F05%2F28%2FSpring%E6%95%B4%E5%90%88RabbitMQ%2F</url>
    <content type="text"><![CDATA[添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;version&gt;1.6.5.RELEASE&lt;/version&gt;&lt;/dependency&gt; 添加RabbitMQ配置文件properties文件存放连接信息12345host=127.0.0.1name=dlhpassword=123456port=5672virtual-host=/test 配置RabbitMQ1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:rabbit="http://www.springframework.org/schema/rabbit" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd"&gt; &lt;!--配置spring扫描--&gt; &lt;context:component-scan base-package="com.dlh"/&gt; &lt;!--引入配置文件--&gt; &lt;context:property-placeholder location="config.properties"/&gt; &lt;!--连接工厂--&gt; &lt;rabbit:connection-factory id="connectionFactory" host="$&#123;host&#125;" username="$&#123;name&#125;" port="$&#123;port&#125;" virtual-host="$&#123;virtual-host&#125;" password="$&#123;password&#125;"/&gt; &lt;rabbit:admin connection-factory="connectionFactory"/&gt; &lt;!--配置交换机--&gt; &lt;rabbit:topic-exchange name="MyExchange"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern="test.*" queue="q01"/&gt; &lt;rabbit:binding pattern="test.#" queue="q02"/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:topic-exchange&gt; &lt;!--配置队列--&gt; &lt;rabbit:queue name="q01" durable="true"/&gt; &lt;rabbit:queue name="q02" durable="true"/&gt; &lt;!--配置监听--&gt; &lt;rabbit:listener-container connection-factory="connectionFactory"&gt; &lt;rabbit:listener ref="consumer" method="consumer01" queue-names="q01"/&gt; &lt;rabbit:listener ref="consumer" method="consumer02" queue-names="q02"/&gt; &lt;/rabbit:listener-container&gt; &lt;!--配置模板类--&gt; &lt;rabbit:template id="rabbitTemplate" connection-factory="connectionFactory" exchange="MyExchange" /&gt;&lt;/beans&gt; 定义两个消费者consumer01和consumer02123456789@Componentpublic class Consumer &#123; public void consumer01(Object obj) &#123; System.out.println("消费者01：" + obj); &#125; public void consumer02(Object obj) &#123; System.out.println("消费者02：" + obj); &#125;&#125; 编写单元测试12345678910111213@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:rabbitmq.xml")public class Test01 &#123; @Resource private AmqpTemplate amqpTemplate; @Test public void test()&#123; amqpTemplate.convertAndSend("MyExchange","test.test.1","hello"); &#125;&#125; 按照我们的交换机配置的Routing Key规则和我们输入的routing key结果为]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq消息路由规则-direct]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F05%2F26%2FRabbitMq%E6%B6%88%E6%81%AF%E8%B7%AF%E7%94%B1%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[​ 我们可以针对不同的消息，在对消息进行消费时，通过exchange types以及Routing key设置规则，便可以将不同消息路由到不同的队列然后交给不同消费者进行消费。 从图中可以看出： 生产者产生消息投给交换机 交换机投送消息时的Exchange Types 为direct类型 消息通过定义的Routing Key 被路由到指定的队列进行后续消费 Sender123456789101112131415161718public class Sender &#123; private static final String EXCHANGE_NAME = "direct"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); // 发布消息 channel.basicPublish(EXCHANGE_NAME, "wrong", null, "hello".getBytes(StandardCharsets.UTF_8)); // 关闭资源 ConnectionUtil.closeResources(connection, channel); &#125;&#125; Receiver12345678910111213141516171819202122232425262728public class Receiver01 &#123; private static final String EXCHANGE_NAME = "direct"; private static final String QUEUE_NAME = "info_wrong"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "wrong"); // 获取消费者 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("info_wrong-&gt;" + msg); &#125; &#125;; // 消费 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 12345678910111213141516171819202122232425262728public class Receiver02 &#123; private static final String EXCHANGE_NAME = "direct"; private static final String QUEUE_NAME = "error"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "error"); // 获取消费者对象 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("error-&gt;" + msg); &#125; &#125;; // 消费 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 测试 根据发送时指定的routing key，只有匹配的Receiver01消费者才能接收到消息]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq消息发布与订阅-fanout]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F05%2F26%2FRabbitMq%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85%2F</url>
    <content type="text"><![CDATA[​ 对于微信公众号，相信每个人都订阅过， 当公众号发送新的消息后，对于订阅过该公众号的所有用户均可以收到消息，这个场景大家都能明白，同样对于RabbitMq 消息的处理也支持这种消息处理， 当生产者把消息投送出去后，不同的消费者均可以对该消息进行消费，而不是消息被一个消费者消费后就立即从队列中删除，对于这种消息处理，我们通常称之为消息的发布与订阅模式，凡是消费者订阅了该消息，均能够收到对应消息进行处理，比较常见的如用户注册操作。模型图如下: 从图中看到: 消息产生后不是直接投送到队列中，而是将消息先投送给 Exchange 交换机，然后消息经过 Exchange 交换机投递到相关队列 多个消费者消费的不再是同一个队列，而是每个消费者消费属于自己的队列。 publish/subscribefanoutSender(将消息发送到交换机)123456789101112131415161718192021public class Sender &#123; private static final String EXCHANGE_NAME = "fanout"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); for (int i = 0; i &lt; 50; i++) &#123; String msg = "消息-&gt;" + i; channel.basicPublish(EXCHANGE_NAME, "", null, msg.getBytes(StandardCharsets.UTF_8)); &#125; // 关闭资源 ConnectionUtil.closeResources(connection, channel); &#125;&#125; Receiver（从交换机中分发为两个队列）1234567891011121314151617181920212223242526272829303132public class Receiver01 &#123; private static final String EXCHANGE_NAME = "fanout"; private static final String QUEUE_NAME = "queue01"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ""); // 获取consumer Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("queue01-" + msg); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; // 消费 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 1234567891011121314151617181920212223242526public class Receiver02 &#123; private static final String EXCHANGE_NAME = "fanout"; private static final String QUEUE_NAME = "queue02"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ""); // 获取消费者 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("queue02-" + msg); &#125; &#125;; // 消费 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 测试 两个消费者都能收到同样的消息]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq-Topic主题模式]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F05%2F26%2FRabbitMq-Topic%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在对于商品的添加、更新、删除等操作时我们可以使用Topic主题模式通过指定的匹配模式将消息路由匹配到相匹配的队列中进行后续处理。 .* ：匹配一个 .# ：匹配多个 sender1234567891011121314151617public class Sender &#123; private static final String EXCHANGE_NAME = "topic"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); // 发布消息 channel.basicPublish(EXCHANGE_NAME, "lazy.orange.test", null, "hello".getBytes(StandardCharsets.UTF_8)); // 关闭连接 ConnectionUtil.closeResources(connection, channel); &#125;&#125; Receiver12345678910111213141516171819202122232425262728public class Receiver01 &#123; private static final String EXCHANGE_NAME = "topic"; private static final String QUEUE_NAME = "topicQueue01"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "*.orange.*"); // 获取消费者 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("消费者01-&gt;" + msg); &#125; &#125;; // 消费 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 12345678910111213141516171819202122232425262728public class Receiver02 &#123; private static final String EXCHANGE_NAME = "topic"; private static final String QUEUE_NAME = "topicQueue02"; public static void main(String[] args) throws Exception &#123; // 获取连接 Connection connection = ConnectionUtil.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "lazy.#"); // 获取消费者 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("消费者02-&gt;" + msg); &#125; &#125;; // 消费 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 测试发送消息时指定的Routing Key为lazy.orange.test，所以两个队列都能匹配，结果： 我们修改一下Routing Key 为lazy.test.test，此时队列1肯定是接收不到的]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq初体验]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F05%2F25%2FRabbitMq%E5%AE%89%E8%A3%85%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[消息队列（Message queue）是一种进程间通信或同一进程的不同线程间的通信方式， 软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列互交。消息会保存在队列中，直到接收者取回它 。 安装RabbitMQ需要安装Erlang，首先安装Erlang，然后再安装RabbitMQ服务器 环境测试 检查RabbitMQ安装后依赖的文件版本信息列表 切换到安装后的sbin目录，执行命令提示符输入命令rabbitmqctl.bat status 查看RabbitMQ支持的插件列表 rabbitmq-plugins.bat list 启用管理控制台插件 rabbitmq-plugins.bat enable rabbitmq_management 浏览器访问127.0.0.1:15672 默认账号:用户名:guest 密码:guest Windows环境下问题的官方解决：http://www.rabbitmq.com/windows-quirks.html 浏览器客户端添加用户 添加虚拟主机 Java客户端引入RabbitMQ依赖12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.2.0&lt;/version&gt;&lt;/dependency&gt; 从最简单的队列开始发送方（发送到消息队列）123456789101112131415161718192021222324252627282930313233public class Sender &#123; // 定义一个常量作为队列名 private static final String QUEUE_NAME = "hello"; public static void main(String[] args) throws Exception &#123; // 获得连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置主机 factory.setHost("127.0.0.1"); // 设置端口 factory.setPort(5672); // 设置虚拟主机 factory.setVirtualHost("/test"); // 设置用户名 factory.setUsername("dlh"); // 设置密码 factory.setPassword("123456"); // 获得连接 Connection connection = factory.newConnection(); // 获得连接通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 声明消息内容 String msg = "hello RabbitMq"; // 发布消息 channel.basicPublish("", QUEUE_NAME, null, msg.getBytes()); // 关闭资源 channel.close(); connection.close(); &#125;&#125; 将消息发布后可以在浏览器客户端中看到我们刚刚创建的队列 我们已经把消息发送到队列中了，但是我们的消息好像丢失了，我们需要先启动消费方再启动发送方，否则容易丢失 接收方（从消息队列中接收处理并返回回执）12345678910111213141516171819202122232425262728293031public class Receiver &#123; private static final String QUEUE_NAME = "hello"; public static void main(String[] args) throws Exception &#123; // 获得连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置参数 factory.setHost("127.0.0.1"); factory.setPort(5672); factory.setUsername("dlh"); factory.setPassword("123456"); factory.setVirtualHost("/test"); // 创建连接 Connection connection = factory.newConnection(); // 创建连接通道 Channel channel = connection.createChannel(); // 指定队列 参数 1、队列的名字 2、是否为耐久队列 3、是否为独占队列 4、队列中的属性 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 创建消费者对象 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("队列中的消息：" + msg); &#125; &#125;; // 执行消费 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 消息的发送方和接收方已经定义好了，这是最简单的消息发送和接收 测试先启动接收方，再启动发送方，结果 工作队列 在上面的例子中消息消费者只有一个，当消息量非常大时，单个消费者处理消息就会变得很慢，同时给节点页带来很大压力，导致消息堆积越来越多。 对于这种情况， Rabbitmq 提供了工作队列模式，通过工作队列提供做个消费者，对 mq 产生的消息进行消费，提高 mq 消息的吞吐率，降低消息的处理时间。 轮询分发默认为轮询分发，定义两个或多个消费方 12345678910111213141516171819202122232425262728293031public class Sender &#123; private static final String QUEUE_NAME = "hello_rr"; public static void main(String[] args) throws Exception &#123; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置参数 factory.setVirtualHost("/test"); factory.setPassword("123456"); factory.setUsername("dlh"); factory.setPort(5672); factory.setHost("127.0.0.1"); // 创建连接 Connection connection = factory.newConnection(); // 通过连接创建连接通道 Channel channel = connection.createChannel(); // 定义队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); for (int i = 0; i &lt; 20; i++) &#123; // 准备消息 String msg = "hello_rabbitMq" + i; // 发布消息 channel.basicPublish("", QUEUE_NAME, null, msg.getBytes()); &#125; // 关闭资源 channel.close(); connection.close(); &#125;&#125; 这里消费方循环发送20次 已经发送到消息队列中了，定义两个消费方 123456789101112131415161718192021222324252627282930313233343536public class Receiver01 &#123; private static final String QUEUE_NAME = "hello_rr"; public static void main(String[] args) throws Exception &#123; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置属性 factory.setHost("127.0.0.1"); factory.setPort(5672); factory.setUsername("dlh"); factory.setPassword("123456"); factory.setVirtualHost("/test"); // 创建连接 Connection connection = factory.newConnection(); // 创建连接通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 创建消费者对象 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("接收01——" + msg); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334public class Receiver02 &#123; private static final String QUEUE_NAME = "hello_rr"; public static void main(String[] args) throws Exception &#123; // 获取连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置属性 factory.setVirtualHost("/test"); factory.setPassword("123456"); factory.setUsername("dlh"); factory.setPort(5672); factory.setHost("127.0.0.1"); // 创建连接 Connection connection = factory.newConnection(); // 创建通道 Channel channel = connection.createChannel(); // 获取consumer对象 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("接收02——" + msg); try &#123; Thread.sleep(2000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;; channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 消费方使用Thread.sleep模拟消息处理时间 轮询就是队列每次轮流分发给消费方，所以两个消费方收到的消息数量几乎一样 ​ 轮询的缺点就是每个人都轮到一次，而不同机器的性能或消息复杂度处理时间不同，有的消费者闲置，有的消费者高负荷，导致资源上的损耗。 在看看上面的配置 1channel.basicConsume(QUEUE_NAME, true, consumer); ​ 第二个参数设置为true时（autoAck=true），只要消费方接收消息，服务器就默认消息处理完成，而且服务器是一股脑把消息分发给消费方，此时当其中一个消费方宕机，原本该属于它的数据将丢失。 公平分发 在上面的轮询分发中我们发现，服务器只会盲目地将消息轮流发给消费方，消费方的处理效率不同导致资源损耗。这里我们设置服务器最大消息数（channel.basicQos(1)），并设置只有将消息处理回执返回才会发送下一条消息。 修改我们消费方的配置 1234567891011121314151617181920212223242526272829303132333435363738394041public class Receiver_fair01 &#123; private static final String QUEUE_NAME = "hello_fair"; public static void main(String[] args) throws Exception &#123; // 获得连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置属性 factory.setVirtualHost("/test"); factory.setPassword("123456"); factory.setPort(5672); factory.setHost("127.0.0.1"); factory.setUsername("dlh"); // 创建连接 Connection connection = factory.newConnection(); // 获取通道 Channel channel = connection.createChannel(); // 设置服务器最大消息数 channel.basicQos(1); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 获取consumer Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, StandardCharsets.UTF_8); System.out.println("接收者01——" + msg); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 手动回执 channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125;; channel.basicConsume(QUEUE_NAME, false, consumer); &#125;&#125; 处理结果 我们发现消费方的处理速率和消息处理量是成正比，处理速率低收到的消息少，处理速率高收到的消息就多。]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SSM整合Dubbo]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F04%2F09%2FSSM%E6%95%B4%E5%90%88Dubbo%2F</url>
    <content type="text"><![CDATA[SSM环境整合Dubbo其实就是将我们以前的单体应用程序改造成分布式应用程序。 创建Maven多模块工程ssm_dubbo_par 父工程 ssm_dubbo_api 服务定义模块 ssm_dubbo_server 服务提供模块 ssm_dubbo_web 服务消费模块 多模块工程目录结构为 接下来写一个demo，通过用户id查询用户 服务定义模块 ​ 建议将服务接口、服务模型、服务异常等均放在 API 包中，因为服务模型和异常也是 API 的一部分，这样做也符合分包原则：重用发布等价原则(REP)，共同重用原则(CRP)。 创建POJO类12345678@Getter@Setterpublic class User implements Serializable &#123; private static final long serialVersionUID = -431851354165903552L; private Integer userId; private String userName; private String userPwd;&#125; 因为要通过网络传输，所以将它实现序列化接口 创建服务接口123public interface IUserService &#123; public User queryUserByUserId(Integer userId);&#125; 服务提供模块引入对API模块的依赖，引入Spring、Mybatis等的各种依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384 &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;!-- c3p0 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加mybatis与Spring整合的核心包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql 驱动包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 日志打印相关的jar --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring mvc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- web servlet --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; 添加jetty插件以及对java目录下资源文件读取的支持 12345678910111213141516171819202122232425262728&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.tld&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt;&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;maven-jetty-plugin&lt;/artifactId&gt; &lt;version&gt;6.1.25&lt;/version&gt; &lt;configuration&gt; &lt;scanIntervalSeconds&gt;10&lt;/scanIntervalSeconds&gt; &lt;!-- 上下文路径:访问的项目名 --&gt; &lt;contextPath&gt;/ssm-dubbo&lt;/contextPath&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 添加Spring配置文件1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;context:component-scan base-package="com.dlh.server.service"&gt; &lt;/context:component-scan&gt; &lt;!--读取jdbc.properties配置文件--&gt; &lt;context:property-placeholder location="classpath:jdbc.properties" /&gt; &lt;!-- 配置数据源 --&gt; &lt;!-- 配置c3p0 数据源 --&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;property name="driverClass" value="$&#123;jdbc.driver&#125;"&gt;&lt;/property&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url&#125;"&gt;&lt;/property&gt; &lt;property name="user" value="$&#123;jdbc.username&#125;"&gt;&lt;/property&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置 sqlSessionFactory --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;property name="mapperLocations" value="classpath:com/dlh/server/mappers/*.xml" /&gt; &lt;/bean&gt; &lt;!-- 配置扫描器 --&gt; &lt;bean id="mapperScanner" class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 扫描com.dlh.dao这个包以及它的子包下的所有映射接口类 --&gt; &lt;property name="basePackage" value="com.dlh.server.dao" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory" /&gt; &lt;/bean&gt; &lt;!--dubbo服务提供方配置--&gt; &lt;dubbo:application name="ssm_dubbo_server"/&gt; &lt;dubbo:service interface="com.dlh.api.service.IUserService" ref="userServiceImpl"/&gt; &lt;dubbo:registry address="zookeeper://127.0.0.1:2181"/&gt; &lt;dubbo:protocol name="dubbo" port="20880"/&gt;&lt;/beans&gt; 编写dao层代码12345678&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.dlh.server.dao.UserDao"&gt; &lt;select id="queryUserByUserId" resultType="com.dlh.api.po.User" parameterType="int"&gt; SELECT id AS userId,user_name AS userName,user_pwd AS userPwd FROM t_user WHERE id = #&#123;userId&#125; &lt;/select&gt;&lt;/mapper&gt; 1234@Repositorypublic interface UserDao &#123; public User queryUserByUserId(Integer userId);&#125; 实现服务接口12345678910@Servicepublic class UserServiceImpl implements IUserService &#123; @Resource private UserDao userDao; @Override public User queryUserByUserId(@Param("userId") Integer userId) &#123; return userDao.queryUserByUserId(userId); &#125;&#125; 在web.xml中配置应用程序的入口123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app id="WebApp_ID" version="3.0" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 启用spring容器环境上下文监听 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt;&lt;/web-app&gt; 服务消费模块配置springMVC配置文件123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation=" http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;!-- 扫描com.dlh.crm.controller 下包 --&gt; &lt;context:component-scan base-package="com.dlh.web.controller"/&gt; &lt;!-- mvc 注解驱动 并添加json 支持 --&gt; &lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;!-- 返回信息为字符串时 处理 --&gt; &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"/&gt; &lt;!-- 将对象转换为json 对象 --&gt; &lt;bean class="org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"/&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;!-- 静态资源文件的处理放行 配置方式 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--dubbo消费方配置--&gt; &lt;dubbo:application name="ssm_dubbo_web"/&gt; &lt;dubbo:registry address="zookeeper://127.0.0.1:2181"/&gt; &lt;dubbo:reference interface="com.dlh.api.service.IUserService" id="userService"/&gt;&lt;/beans&gt; 配置Controller层123456789@RestControllerpublic class UserController &#123; @Resource private IUserService userService; @GetMapping("/user/&#123;userId&#125;") public User queryUserByUserId(@PathVariable Integer userId) &#123; return userService.queryUserByUserId(userId); &#125;&#125; 配置jetty插件1234567891011121314&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;maven-jetty-plugin&lt;/artifactId&gt; &lt;version&gt;6.1.25&lt;/version&gt; &lt;configuration&gt; &lt;scanIntervalSeconds&gt;10&lt;/scanIntervalSeconds&gt; &lt;!-- 上下文路径:访问的项目名 --&gt; &lt;contextPath&gt;/ssm-web&lt;/contextPath&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 开始Maven执行多模块安装1clean compile install -Dmaven.test.skip=true 启动zookeeper服务 启动服务端jetty（server）1jetty:run -Djetty.port=9091 没有报错则基本启动完成 启动消费方jetty（web）1jetty:run -Djetty.port=9092 访问调用Controller层]]></content>
      <categories>
        <category>分布式应用</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Dubbo配置zookeeper注册中心]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F04%2F07%2FDubbo%E9%85%8D%E7%BD%AEzookeeper%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[windows 下Zookeeper 配置与启动（单机模式）下载并解压http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz 准备zoo.cfg文件/zookeeper-3.4.13/conf目录下将zoo_sample.cfg文件拷贝复制一份为zoo.cfg 添加数据存储目录dataDir和日志存储目录dataLogDir 启动服务器bin/zkServer.cmd 客户端连接bin/zkCli.cmd 节点查看命令：ls / Dubbo 应用配置1&lt;dubbo:registry address="zookeeper://127.0.0.1:2181"&gt;&lt;/dubbo:registry&gt; 添加坐标 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.3.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt;&lt;/dependency&gt; Linux下Zookeeper 配置与启动下载zookeeper 解压缩 准备zoo.conf配置文件进入到conf目录下 配置zoo.cfg文件添加数据和日志存放目录 启动服务进入bin目录下 1./zkServer.sh start 启动客户端1./zkCli.sh Dubbo注册中心配置1&lt;dubbo:registry address="zookeeper://192.168.32.223:2181" /&gt; 地址填写虚拟机ip地址 测试运行zookeeper服务端，将服务发布 运行zookeeper客户端，ls /命令查询根节点下所有节点 在进入到dubbo节点下可以看到我们发布的服务接口 进入发布的服务，可以看到我们服务提供方和消费方相关信息]]></content>
      <categories>
        <category>分布式应用</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Dubbo-RPC-开始]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F04%2F06%2FDubbo%2F</url>
    <content type="text"><![CDATA[RPC基本概念RPC 协议(Remote Procedure Call Protocol)​ 远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 协议假定某些传输协议的存在，如 TCP 或 UDP，为通信程序之间携带信息数据。在 OSI 网络通信模型中，RPC 跨越了传输层和应用层。RPC 使得开发包括网络分布式程序在内的应用程序更加容易。 ​ RPC 采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。 RPC与 HTTP、TCP、UDP、Socket 的区别 TCP/UDP：都是传输协议，主要区别是 tcp 协议连接需要 3 次握手，断开需要四次挥手，是通过流来传输的，就是确定连接后，一直发送信息，传完后断开。udp 不需要进行连接，直接把信息封装成多个报文，直接发送。所以 udp 的速度更快写，但是不保证数据的完整性。 Http：超文本传输协议是一种应用层协议，建立在TCP 协议之上。 Socket：是在应用程序层面上对 TCP/IP 协议的封装和应用。其实是一个调用接口，方便程序员使用 TCP/IP 协议栈而已。程序员通过 socket 来使用 tcp/ip 协议。但是 socket 并不是一定要使用 tcp/ip 协议，Socket 编程接口在设计的时候，就希望也能适应其他的网络协议。小结：我们把网络传输类比于一条公路，那 TCP/UDP 就是货车，HTTP 就是货物，而 socket就是发动机。 RPC 是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。所以RPC 的实现可以通过不同的协议去实现比如可以使 http、RMI 等。 Dubbo​ Dubbo 是由阿里巴巴开源的一个高性能、基于 Java 开源的远程调用框架。正如在许多RPC 系统中一样，dubbo 是基于定义服务的概念，指定可以通过参数和返回类型远程调用的方法。在服务器端，服务器实现这个接口，并运行一个 dubbo 服务器来处理客户端调用。在客户端，客户机有一个存根，它提供与服务器相同的方法。 架构流程图 start 初始化(ioc 容器) ​ 在ioc 容器启动时 对服务实现类实例化 register 服务注册操作 ​ 将服务提供方提供的服务信息写入到注册中心 ​ ip port 服务列表信息(userService:queryUserByUserId,queryUsersByparams…,accountService,…) subscrible 服务订阅操作 ​ 消费者启动时订阅注册中心提供的服务列表信息 ​ userService,accountService notify 消息通知 服务变更时 注册中心推送变更消息到消费者 invoke 远程调用 ​ 根据订阅的服务信息 发起远程调用(同步操作 会有阻塞情况发生) count 监控中心 监控程序运行状况 快速入门系统要求jdk1.6 以上和 maven3.0 以上，采用 maven 分模块构建 api 模块，provider模块以及 consumer 模块 导入Dubbo坐标12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.6&lt;/version&gt;&lt;/dependency&gt; 定义服务接口（api）​ 由于服务的生产者和消费者都会依赖这个接口，因此强烈建议把这个接口定义在一个独立的模块，然后由生产者模块和消费者模块各自依赖即可。 123public interface IUserService &#123; public User queryUserById(Integer id);&#125; 服务实现（provider）123456789101112@Servicepublic class UserServiceImpl implements IUserService &#123; private Map&lt;Integer, User&gt; map = new HashMap&lt;Integer, User&gt;(); // 初始化时给map集合填充数据，充当数据库查询 public UserServiceImpl() &#123; map.put(1, new User(1, "zs", "123")); &#125; @Override public User queryUserById(Integer id) &#123; return map.get(id); &#125;&#125; 配置生产者（provider）12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="com.dlh.service"/&gt; &lt;!--dubbo环境配置--&gt; &lt;!--应用名称--&gt; &lt;dubbo:application name="dubbo_provider"/&gt; &lt;!--注册中心配置--&gt; &lt;!--&lt;dubbo:registry address="multicast://232.5.6.7:1221"/&gt;--&gt; &lt;!--公布的服务使用的协议与端口号--&gt; &lt;dubbo:protocol name="dubbo" port="20880"/&gt; &lt;!--配置公布的服务--&gt; &lt;dubbo:service interface="com.dlh.service.IUserService" ref="userServiceImpl"/&gt;&lt;/beans&gt; 启动服务提供程序（provider）12345678public class Publish &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("provider.xml"); context.start(); System.out.println("发布成功。。。"); System.in.read();// 任意键停止 &#125;&#125; 配置服务的消费端（consumer）12345678&lt;context:component-scan base-package="com.dlh.controller"/&gt;&lt;!--应用名称--&gt;&lt;dubbo:application name="dubbo_consumer"/&gt;&lt;!--注册中心配置--&gt;&lt;!--&lt;dubbo:registry address="multicast://232.5.6.7:1221"/&gt;--&gt;&lt;dubbo:registry address="zookeeper://224.5.6.7:1234?backup=224.5.6.8:1234,224.5.6.9:1234" /&gt;&lt;!--配置订阅的服务列表--&gt;&lt;dubbo:reference id="userService" interface="com.dlh.service.IUserService"/&gt; 模拟消费端Controller层（consumer）12345678@Controllerpublic class UserController &#123; @Resource private IUserService userService; public User queryUserById(Integer id) &#123; return userService.queryUserById(id); &#125;&#125; 测试消费（consumer）1234567public class Test &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("consumer.xml"); UserController userController = (UserController) context.getBean("userController"); System.out.println(userController.queryUserById(1)); &#125;&#125;]]></content>
      <categories>
        <category>分布式应用</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式应用-RMI简单实现]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F04%2F04%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%BA%94%E7%94%A8-rmi%2F</url>
    <content type="text"><![CDATA[单体应用​ 一个单体应用程序，通俗来说就是应用程序的全部功能被一起打包作为单个单元或应用程序。 这个单元可以是JAR、WAR、EAR，或其他一些归档格式，但其全部集成在一个单一的单元。 例如在线购物网站通常会包括客户、产品、目录、结帐等功能。 另一个例子是如下的movieplex。这样的应用程序通常由节目预订、添加/删除的电影、票房收入、电影起租点和其他功能组成。在单体应用程序的情况下，所有这些功能的实现和打包在一起作为一个应用程序。（来自百科） 特点 dao service controller ui页面 全部体现到一个war文件中 功能升级复杂 扩展功能相对麻烦 不能按需扩展 代码重复性较大 service服务代码重复性较大 部署简单 技术迭代 复杂度变高 后期维护复杂(涉及技术复杂度较高) 分布式应用分布式应用程序是指：应用程序分布在不同计算机上，通过网络来共同完成一项任务。通常为服务器/客户端模式。 建立分布式应用主要设计以下几种技术： 客户机/服务器体系结构； 远程过程调用（RPC）； 分布式计算环境（DCE）； 分布式组件对象模型（DCOM）； 通用对象请求代理体系结构（COBRA）； 企业 Intranet Applet； Java 分布式对象模型。 RMI:远程方法调用简单实现 第一步：定义一个借口，必须继承remote 123public interface IRmiService extends Remote &#123; public String say() throws RemoteException;&#125; 第二步：编写一个实现类即服务端，继承 UnicastRemoteObject 实现 IRmiService 接口 12345678910public class RmiService extends UnicastRemoteObject implements IRmiService &#123; public RmiService() throws RemoteException &#123; super(); &#125; public String say() throws RemoteException &#123; String content = "Woo! So beautiful butterfly!"; System.out.println("RMI Server say: " + content); return content; &#125; &#125; 第三步：发布服务 1234567891011121314151617181920public class RmiPublish &#123; public RmiPublish() &#123; try &#123; IRmiService rmiService = new RmiService(); // 发布的接口 LocateRegistry.createRegistry(8888); // 绑定地址 Naming.bind("rmi://localhost:8888/rmiService", rmiService); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; catch (AlreadyBoundException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; new RmiPublish(); &#125;&#125; 第四步：客户端调用 123456789101112131415public class RmiClient &#123; public static void main(String[] args) &#123; try &#123; IRmiService rmiService = (IRmiService) Naming.lookup("rmi://localhost:8888/rmiService"); String content = rmiService.say(); System.out.println("RMI Client Got Say Content: " + content); &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; catch (NotBoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>分布式应用</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[webSocket]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F03%2F12%2FwebSocket%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[一、webSocket是什么 ​ webSocket是html5推出的一种新协议，和HTTP协议基本没有关系，但是为了兼容现有浏览器的握手规范，需要通过HTTP协议完成一部分握手，也可以说是HTTP协议的补充，两者之间有交集，但不是全部，可以用以下这张图理解HTTP和webSocket的关系 二、为什么需要webSocket ​ HTTP协议是无状态（协议对事务处理没有记忆能力），无连接（一次请求即断开连接），单向的应用层协议（只能由客户端请求服务器，服务器无法主动向客户端发送消息）。 ​ 在这种单向请求的特点在服务器状态持续发生变化时客户端想要获知就很麻烦，（可以使用Ajax的轮询或者长轮询实现），但是轮询效率低并且十分耗费资源（因为要持续不断的打开连接） ​ 在这种情况下，webSocket应运而生了，webSocket只需要建立一次连接就可以保持连接，进行持久通信，而且客户端和服务端都可以通过连接发送数据到另一方。 ​ 在需要实时通信的需求下使用webSocket最好不过了 对于webSocket的介绍就到这里，贴一篇关于webSocket原理的文章参考 https://www.cnblogs.com/fuqiang88/p/5956363.html 三、通过Java实现webSocket通信的简易聊天室 js代码（客户端） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;主页&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;input type="text" id="userMsg"/&gt;&lt;button onclick="send()"&gt;发送消息&lt;/button&gt;&lt;/br&gt;&lt;button onclick="closeWebSocket()"&gt;关闭连接&lt;/button&gt;&lt;button onclick="clearMsg()"&gt;清屏&lt;/button&gt;&lt;div id="msg"&gt;&lt;/div&gt;&lt;div id="per"&gt;&lt;/div&gt;&lt;/body&gt;&lt;script type="text/javascript" src="statics/jquery-3.3.1.min.js"&gt;&lt;/script&gt;&lt;%String nick = request.getParameter("nick");%&gt;&lt;script type="text/javascript"&gt; // 页面加载完毕没有登录则跳转到登录页面 $(function () &#123; var nick = &lt;%=nick%&gt;; if (nick==null)&#123; window.location.href="login.jsp"; &#125; &#125;); var webSocket = null; // 判断浏览器是否支持webSocket if ("WebSocket" in window)&#123; webSocket = new WebSocket("ws://192.168.1.139:8080/chat"); &#125;else&#123; alert("浏览器不支持webSocket") &#125; // 连接发生错误的回调方法 webSocket.onerror = function () &#123; setMsg("发生错误") &#125;; // 建立连接后要做的事情 webSocket.onopen = function () &#123; addUser(); &#125;; // 服务器发送过来的消息 webSocket.onmessage = function (event) &#123; setMsg(event.data); &#125;; // 关闭连接 webSocket.onclose = function () &#123; subUser(); &#125;; // 当浏览器关闭时关闭连接，防止后台报错 window.onbeforeunload = function () &#123; closeWebSocket(); &#125;; // 将信息显示在页面 function setMsg(msg)&#123; $('#msg').append(msg+"&lt;/br&gt;"); &#125; function addUser() &#123; webSocket.send('&lt;%=nick%&gt;'+"加入聊天室"); &#125; function subUser() &#123; webSocket.send('&lt;%=nick%&gt;'+"离开聊天室"); &#125; // 关闭webSocket连接 function closeWebSocket() &#123; webSocket.close(); window.location.href="login.jsp"; &#125; // 发送消息 function send() &#123; var userMsg= $('#userMsg').val(); webSocket.send('&lt;%=nick%&gt;'+"说："+userMsg); $('#userMsg').val(""); &#125; function clearMsg() &#123; $('#msg').empty(); &#125;&lt;/script&gt;&lt;/html&gt; java代码（服务端） ​ 在编写代码之前需要引入javaee标准 123456&lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-api&lt;/artifactId&gt; &lt;version&gt;7.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package com.dlh.websocket;import javax.websocket.*;import javax.websocket.server.ServerEndpoint;import java.io.IOException;import java.util.concurrent.CopyOnWriteArraySet;// 建立一个webSocket的端点，要和js代码中对应@ServerEndpoint("/chat")public class ChatServer &#123; // 与客户端之间连接的会话，通过session向和客户端发送消息 private Session session; // concurrent包线程安全的set，用来存放chatServer对象 private static CopyOnWriteArraySet&lt;ChatServer&gt; set = new CopyOnWriteArraySet&lt;&gt;(); // 用来计算当前在线人数 private Integer onlineNum = 0; /** * 建立连接后要做的事情 */ @OnOpen public void onOpen(Session session)&#123; this.session = session; set.add(this); //将当前登录对象放入集合 System.out.println("webSocket连接已经建立.."); addOnline(); &#125; /** * 从客户端收到的消息 */ @OnMessage public void onMessage(String msg,Session session)&#123; this.session = session; try &#123; for (ChatServer chats:set)&#123; chats.session.getBasicRemote().sendText(msg); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 断开连接 */ @OnClose public void onClose(Session session)&#123; set.remove(this); System.out.println("断开连接..."); subOnline(); &#125; /** * 发生异常调用 */ @OnError public void onError(Throwable e)&#123; System.out.println("发生异常..."); e.printStackTrace(); &#125; public synchronized void addOnline()&#123; onlineNum++; &#125; public synchronized void subOnline()&#123; onlineNum--; &#125; // 获取在线人数 public synchronized Integer getOnline()&#123; return onlineNum; &#125;&#125;]]></content>
      <categories>
        <category>webSocket</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Crm-权限管理模块]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F02%2F22%2FCrm%E9%A1%B9%E7%9B%AE%E6%9D%83%E9%99%90%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[​ 在这个项目中权限管理模块分为用户信息管理、角色管理、资源管理三个方面对不同用户的权限进行管理。 ​ 由于每个用户可以有多个角色，每个角色有多个模块权限，处理这些多对多的关系，建立了两张中间表，其中用户和角色之间的中间表，角色和权限的中间表，所以这里权限管理总共有五张表： ​ 用户表：t_user 、 角色表：t_role 、 用户和角色的关系中间表：t_user_role ​ 模块表：t_module 、角色和模块的关系中间表：t_permission 用户信息管理 ​ 这里主要管理用户和用户的角色分配，通过中间表t_user_role中的userId和roleId对另外两张表关联 ​ 其中需要将多行数据显示到一行，使用了mysql的group_concat语法 角色管理 ​ 最主要的是关联权限，这里用了zTree插件建立了一棵权限树 ​ ​ 通过t_permission中间表中的roleId和moduleId连接t_role和t_module两张表之间的关系 ​ 资源管理 ​ 通过t_permission表和t_module表中的权限码关联 ​ 这个项目中权限码的设定是进行权限管理的关键 权限管理如何进行管理 ​ 前台管理：freemake-所见即有权限 ​ 思路： ​ 1、登录时根据用户id查询两张中间表中角色id相同的权限码（该用户拥有的权限码），并将结果存到session作用域中 ​ 2、前台模版引擎判断作用域中权限码是否存在和对应权限码显示 1234567891011121314&lt;#if permissions??&gt; &lt;!--判断作用域存在的话才展示以下信息--&gt; &lt;#if permissions?seq_contains("10")&gt; &lt;!--判断作用域中包含才展示以下信息--&gt; &lt;div title="营销管理" data-options="selected:true,iconCls:'icon-yxgl'" style="padding: 10px"&gt; &lt;#if permissions?seq_contains("1010")&gt; &lt;a href="javascript:openTab('营销机会管理','saleChance/index/1','icon-yxjhgl')" class="easyui-linkbutton" data-options="plain:true,iconCls:'icon-yxjhgl'" style="width: 150px"&gt;营销机会管理&lt;/a&gt; &lt;/#if&gt; &lt;#if permissions?seq_contains("1020")&gt; &lt;a href="javascript:openTab('客户开发计划','saleChance/index/2','icon-khkfjh')" class="easyui-linkbutton" data-options="plain:true,iconCls:'icon-khkfjh'" style="width: 150px"&gt;客户开发计划&lt;/a&gt; &lt;/#if&gt; &lt;/div&gt; &lt;/#if&gt; &lt;/#if&gt; ​ ​ 后台管理：通过spring-aop+自定义注解进行统一管理 ​ 思路： ​ 1、自定义注解 ​ 2、配置切面，对标记有该注解的注解中的值和session作用域中的内容进行比较判断，对不包含访问该资源所需权限码的行为进行拦截。 1234567891011121314151617181920212223242526272829@Component@Aspectpublic class PermissionAdaptor &#123; @Pointcut("@annotation(com.dlh.crm.annotation.RequestPermission)") public void cut() &#123; &#125; @Around("cut()") public Object around(ProceedingJoinPoint pjp) throws Throwable &#123; // 得到方法签名 MethodSignature signature = (MethodSignature) pjp.getSignature(); // 通过方法签名拿到方法 Method method = signature.getMethod(); // 通过方法拿到注解 RequestPermission requestPermission = method.getAnnotation(RequestPermission.class); // 拿到注解中的value String aclValue = requestPermission.aclValue(); // 通过spring线程的上下文获取request对象（也可以直接注入httpsession，我只是做测试） ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = requestAttributes.getRequest(); // 通过request对象拿到session中的内容 List&lt;String&gt; permission = (List&lt;String&gt;) request.getSession().getAttribute(CrmConstant.USER_PERMISSIONS); // 判断集合中是否包含ACLValue拦截 AssertUtil.isTrue(CollectionUtils.isEmpty(permission) || !permission.contains(aclValue), "没有权限"); return pjp.proceed(); &#125;&#125;]]></content>
      <categories>
        <category>项目经验</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用poi读取Excel和写出Excel]]></title>
    <url>%2Fdlh1234okok.github.io%2F2018%2F01%2F04%2F%E4%BD%BF%E7%94%A8poi%E8%AF%BB%E5%8F%96Excel%E5%92%8C%E5%86%99%E5%87%BAExcel%2F</url>
    <content type="text"><![CDATA[本次使用到的jar包 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt; &lt;/dependency&gt; &nbsp; 1、从数据库读取数据写出到Excel 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package com.sync;import com.sync.po.Account;import org.apache.poi.hssf.usermodel.*;import javax.swing.filechooser.FileSystemView;import java.io.*;import java.util.List;/** * 简单的查询数据库将结果存到Excel */public class CreateExcel01 &#123; // 数据库查询 public static List&lt;Account&gt; query() &#123; String sql = "select * from tb_account"; List&lt;Account&gt; list = BaseDao.findRows(sql, null, Account.class); return list; &#125; // 创建Excel public static void createExcel()&#123; try &#123; // 获取桌面路径 FileSystemView fsv = FileSystemView.getFileSystemView(); String desktop = fsv.getHomeDirectory().getPath(); String filePath = desktop + "/template.xls"; File file = new File(filePath); OutputStream outputStream = new FileOutputStream(file); HSSFWorkbook workbook = new HSSFWorkbook(); // 创建一个工作表 HSSFSheet sheet = workbook.createSheet("Sheet1"); // 创建首行/头（第0行开始） HSSFRow head = sheet.createRow(0); String[] header = new String[]&#123;"账户id","账户名称","账户类型","账户金额","账户备注","创建时间","用户id","修改时间"&#125;; for (int i=0;i&lt;header.length;i++)&#123; // 设置首行信息 head.createCell(i).setCellValue(header[i]); &#125; head.setHeightInPoints(20); // 设置行的高度 // 从数据查询返回的集合 List&lt;Account&gt; accounts=query(); // 日期格式化 HSSFCellStyle cellStyle2 = workbook.createCellStyle(); HSSFCreationHelper creationHelper = workbook.getCreationHelper(); // 设置日期格式 cellStyle2.setDataFormat(creationHelper.createDataFormat().getFormat("yyyy-MM-dd")); sheet.setColumnWidth(3, 15 * 256); sheet.setColumnWidth(5, 20 * 256); sheet.setColumnWidth(7, 20 * 256);// 设置列的宽度 // 保留两位小数 HSSFCellStyle cellStyle3 = workbook.createCellStyle(); cellStyle3.setDataFormat(HSSFDataFormat.getBuiltinFormat("0.00")); for(int i=0;i&lt;accounts.size();i++) &#123; // 创建行（从第一行开始） HSSFRow row1 = sheet.createRow(i + 1); // id row1.createCell(0).setCellValue(accounts.get(i).getId()); // 账户名称 row1.createCell(1).setCellValue(accounts.get(i).getAccountName()); // 账户类型 row1.createCell(2).setCellValue(accounts.get(i).getAccountType()); // 账户金额（添加样式，保留两位小数） HSSFCell money = row1.createCell(3); money.setCellStyle(cellStyle3); money.setCellValue(accounts.get(i).getMoney()); // 账户备注 row1.createCell(4).setCellValue(accounts.get(i).getRemark()); // 创建时间（格式化时间） HSSFCell date1 = row1.createCell(5); date1.setCellStyle(cellStyle2); date1.setCellValue(accounts.get(i).getCreateTime()); // 用户id row1.createCell(6).setCellValue(accounts.get(i).getUid()); // 更新时间 HSSFCell date2 = row1.createCell(7); date2.setCellStyle(cellStyle2); date2.setCellValue(accounts.get(i).getUpdateTime()); &#125; workbook.setActiveSheet(0); workbook.write(outputStream); outputStream.close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; &#125;&#125;class test&#123; public static void main(String[] args)&#123; CreateExcel01.createExcel(); &#125;&#125; 2、从Excel读取写入到数据库 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127package com.sync;import org.apache.commons.lang3.time.DateFormatUtils;import org.apache.poi.hssf.usermodel.HSSFCell;import org.apache.poi.hssf.usermodel.HSSFDataFormat;import org.apache.poi.hssf.usermodel.HSSFDateUtil;import org.apache.poi.hssf.usermodel.HSSFWorkbook;import org.apache.poi.ss.formula.functions.Rows;import org.apache.poi.ss.usermodel.*;import org.apache.poi.xssf.usermodel.XSSFWorkbook;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Date;import java.util.Iterator;import java.util.List;public class ReadExcelToDB &#123; public List&lt;List&lt;Object&gt;&gt; importExcel(File file) &#123; List&lt;List&lt;Object&gt;&gt; dataList = null; try &#123; dataList = new ArrayList&lt;List&lt;Object&gt;&gt;(); // Excel对象 Workbook workbook = null; // 获取文件名 String fileName = file.getName().toLowerCase(); // 判断后缀 if (fileName.endsWith("xls")) &#123; workbook = new HSSFWorkbook(new FileInputStream(file)); &#125; else if (fileName.endsWith("xlsx")) &#123; workbook = new XSSFWorkbook(new FileInputStream(file)); &#125; else &#123; throw new RuntimeException("该文件不是Excel文件"); &#125; // 获取Excel中的第一个表格 Sheet sheet = workbook.getSheet("Sheet1"); // 得到表格中的数据的行数，最后一行 int rows = sheet.getLastRowNum(); if (rows == 0) &#123; throw new RuntimeException("表格中没有数据"); &#125; Row row = null; //行对象 Iterator&lt;Cell&gt; cols = null; // 列对象的迭代器 List&lt;Object&gt; list = null; for (int i = 1; i &lt;= rows; i++) &#123; row = sheet.getRow(i); // 获取第i行 if (row != null) &#123; cols = row.cellIterator(); // 获取该行的迭代器 list = new ArrayList&lt;Object&gt;(); while (cols.hasNext()) &#123; // 循环获取每一列数据存到list中 list.add(getCellObj(cols.next())); &#125; // 将这行数据存到集合dataList中 dataList.add(list); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return dataList; &#125; private Object getCellObj(Cell cell) &#123; if (cell == null) &#123; return ""; &#125; Object cellObj; switch (cell.getCellType()) &#123; case HSSFCell.CELL_TYPE_STRING: //字符串 cellObj = cell.getStringCellValue(); break; case HSSFCell.CELL_TYPE_NUMERIC: //数字 // poi把日期类型也归为数字类型 if (HSSFDateUtil.isCellDateFormatted(cell))&#123; // 获取日期对象并格式化 Date date=cell.getDateCellValue(); cellObj= DateFormatUtils.format(date,"yyyy-MM-dd"); &#125; else&#123; /*CellStyle cellStyle=cell.getCellStyle(); cellStyle.setDataFormat(HSSFDataFormat.getBuiltinFormat("0"));*/ cellObj = cell.getNumericCellValue(); &#125; break; case HSSFCell.CELL_TYPE_BOOLEAN: //boolean cellObj = cell.getBooleanCellValue(); break; case HSSFCell.CELL_TYPE_FORMULA: //公式 cellObj = cell.getCellFormula(); break; case HSSFCell.CELL_TYPE_BLANK: //空 cellObj = ""; break; case HSSFCell.CELL_TYPE_ERROR: //错误 cellObj = ""; break; default: cellObj=""; break; &#125; return cellObj; &#125;&#125;class Test &#123; public static void main(String[] args) &#123; File file = new File("C:\\Users\\Administrator\\Desktop\\no1.xls"); ReadExcelToDB readExcelToDB = new ReadExcelToDB(); List&lt;List&lt;Object&gt;&gt; lists=readExcelToDB.importExcel(file); for (List&lt;Object&gt; ObjList:lists)&#123; for (Object object:ObjList)&#123; System.out.println(object); &#125; System.out.println("____________"); &#125; &#125;&#125; 读取的结果是： &nbsp; 调用数据库插入就可以往插入到数据库了]]></content>
      <categories>
        <category>poi</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring-Data-Redis操作redis服务器]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F10%2F27%2FSpring-Data-Redis%E6%93%8D%E4%BD%9Credis%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[进行spring操作前，需要将redis配置中的所有127.0.0.1改为本机ip 加入坐标依赖1234567891011121314151617181920212223&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-test&lt;/artifactId&gt;&lt;version&gt;4.3.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.data&lt;/groupId&gt;&lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt;&lt;version&gt;1.8.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;redis.clients&lt;/groupId&gt;&lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt; 添加application.xml配置文件1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 连接池配置 --&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;!-- 最大连接数 --&gt; &lt;property name="maxTotal" value="1024"/&gt; &lt;!-- 最大 空闲连接数 --&gt; &lt;property name="maxIdle" value="200"/&gt; &lt;!-- 获取连接时最大等待毫秒数 --&gt; &lt;property name="maxWaitMillis" value="10000"/&gt; &lt;!-- 在获取连接时检查有效性 --&gt; &lt;property name="testOnBorrow" value="true"/&gt; &lt;/bean&gt; &lt;!-- 客户端连接工厂 --&gt; &lt;bean id="jedisConnFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory" p:use-pool="true" p:host-name="192.168.1.38" p:port="6380" p:password="123456"&gt; &lt;!-- 连接池引用 --&gt; &lt;constructor-arg name="poolConfig" ref="jedisPoolConfig"/&gt; &lt;/bean&gt; &lt;!-- redisTemplate 配置 --&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate" p:connection-factory-ref="jedisConnFactory"&gt; &lt;!-- 配置序列化操作 --&gt; &lt;property name="keySerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;/property&gt; &lt;property name="valueSerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 单元测试1234567891011121314151617181920public class TestSpringDataRedis &#123; @Resource RedisTemplate&lt;String,Object&gt; redisTemplate; @Test public void test01() &#123; ValueOperations valueOperations = redisTemplate.opsForValue(); valueOperations.set("redis02", "hello redis"); &#125; // 过期秒数实现 @Test public void test02() &#123; BoundValueOperations&lt;String, Object&gt; Operations = redisTemplate.boundValueOps("18236741290:12 3456"); Operations.append("123456"); System.out.println("验证码:" + Operations.get()); // 设置过期时间 60 秒后过期 Operations.expire(60, TimeUnit.SECONDS); &#125;&#125; Spring环境下读写分离配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 连接池配置 --&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;!-- 最大连接数 --&gt; &lt;property name="maxTotal" value="1024"/&gt; &lt;!-- 最大 空闲连接数 --&gt; &lt;property name="maxIdle" value="200"/&gt; &lt;!-- 获取连接时最大等待毫秒数 --&gt; &lt;property name="maxWaitMillis" value="10000"/&gt; &lt;!-- 在获取连接时检查有效性 --&gt; &lt;property name="testOnBorrow" value="true"/&gt; &lt;/bean&gt; &lt;bean id="redisSentinelConfiguration" class="org.springframework.data.redis.connection.RedisSentinelConfiguration"&gt; &lt;property name="master"&gt; &lt;bean class="org.springframework.data.redis.connection.RedisNode"&gt; &lt;property name="name" value="mymaster"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="sentinels"&gt; &lt;set&gt; &lt;bean class="org.springframework.data.redis.connection.RedisNode"&gt; &lt;constructor-arg name="host" value="192.168.1.38"/&gt; &lt;constructor-arg name="port" value="6380"/&gt; &lt;/bean&gt; &lt;bean class="org.springframework.data.redis.connection.RedisNode"&gt; &lt;constructor-arg name="host" value="192.168.1.38"/&gt; &lt;constructor-arg name="port" value="6379"/&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 客户端连接工厂 --&gt; &lt;bean id="jedisConnFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;!-- 连接池引用 --&gt; &lt;constructor-arg name="poolConfig" ref="jedisPoolConfig"/&gt; &lt;constructor-arg name="sentinelConfig" ref="redisSentinelConfiguration"/&gt; &lt;property name="password" value="123456"/&gt; &lt;/bean&gt; &lt;!-- redisTemplate 配置 --&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate" p:connection-factory-ref="jedisConnFactory"&gt; &lt;!-- 配置序列化操作 --&gt; &lt;property name="keySerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;/property&gt; &lt;property name="valueSerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.JdkSerializationRedisSerializer"/&gt; &lt;/property&gt; &lt;property name="hashKeySerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;/property&gt; &lt;property name="hashValueSerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.JdkSerializationRedisSerializer"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="redisUtils" class="com.shsxt.utils.RedisUtils"&gt; &lt;constructor-arg name="redisTemplate" ref="redisTemplate"/&gt; &lt;/bean&gt;&lt;/beans&gt;]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis-JAVA客户端]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F10%2F27%2FRedis%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[​ 在前面我们添加的服务器访问密码和bind的设置就是为了连接客户端准备的。 添加依赖123456789101112131415&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;redis.clients&lt;/groupId&gt;&lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;version&gt;2.9.0&lt;/version&gt;&lt;type&gt;jar&lt;/type&gt;&lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;&lt;/dependencies&gt; 通过junit简单测试1234567891011@Testpublic void test01() &#123; // 创建redis客户端连接对象 Jedis jedis = new Jedis("192.168.1.38", 6380); // 设置认证密码 jedis.auth("123456"); // 批量添加string类型数据 jedis.mset("name", "zs", "age", "20", "address", "shanghai"); // 获取缓存数据并输出 System.out.println(jedis.get("name"));&#125; 通过redis连接池获取连接对象并操作服务器123456789@Testpublic void test02() &#123; // 初始化redis客户端连接池 JedisPool jedisPool = new JedisPool(new JedisPoolConfig(), "192.168.1.38", 6380, 10000, "123456"); // 从连接池获取连接 Jedis jedis = jedisPool.getResource(); jedis.set("name","ls"); System.out.println(jedis.get("name"));&#125; 封装RedisUtil对外提供连接对象获取方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class RedisUtils &#123; // redis服务器ip private static String IP = "192.168.1.38"; // redis端口号 private static int PORT = 6380; // redis服务器访问密码 private static String AUTH = "123456"; /** * 可用连接实例的最大数目，默认值为8 * 如果赋值为-1，则表示不限制；如果pool已经分配了maxActive个jedis实例， * 则此时pool的状态为exhausted(耗尽) */ private static int MAX_ACTIVE = 1024; // 控制一个pool最多有多少个状态为idle(空闲)的jedis实例，默认值为8 private static int MAX_IDLE = 200; /** * 等待可用连接的最大时间，单位毫秒，默认值为-1（永不超时）,如果超过等待时间 * 则直接抛出JedisConnectionException */ private static int MAX_WAIT = 10000; private static int TIMEOUT = 10000; /** * 在borrow一个jedis实例时，是否提前进行validate操作；如果为true， * 则得到的jedis实例均是可用的 */ private static boolean TEST_ON_BORROW = true; private static JedisPool jedisPool = null; /** * 初始化redis连接池 */ static &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(MAX_ACTIVE); config.setMaxIdle(MAX_IDLE); config.setMaxWaitMillis(MAX_WAIT); config.setTestOnBorrow(TEST_ON_BORROW); jedisPool = new JedisPool(config, IP, PORT, TIMEOUT, AUTH); &#125; public RedisUtils(RedisTemplate redisTemplate) &#123; &#125; /** * 获取Jedis实例 */ public synchronized static Jedis getJedis() &#123; if (null != jedisPool) &#123; Jedis resource = jedisPool.getResource(); return resource; &#125; else &#123; return null; &#125; &#125; /** * 释放jedis资源 */ public static void returnResource(final Jedis jedis) &#123; if (null != jedis) jedisPool.close(); &#125;&#125; Jedis客户端操作redis服务器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class TestJeditPool &#123; private Jedis jedis; @Before public void init() &#123; jedis = RedisUtils.getJedis(); &#125; /** * string操作 */ @Test public void test01() &#123; jedis.set("one", "hello"); jedis.append("one", "world"); System.out.println(jedis.get("one")); System.out.println("---------------"); jedis.mset("name", "zs", "age", "20", "id", "123456"); List&lt;String&gt; list = jedis.mget("name", "age", "id"); if (null != list &amp;&amp; list.size() &gt; 0) &#123; for (String str : list) System.out.println(str + " "); &#125; System.out.println("---------------"); jedis.incr("age"); System.out.println(jedis.get("age")); jedis.incrBy("age", 10); System.out.println(jedis.get("age")); RedisUtils.returnResource(jedis); &#125; /** * hash操作 */ @Test public void test02() &#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put("id", "1"); map.put("name", "zs"); map.put("age", "20"); jedis.hmset("user", map); System.out.println(jedis.hmget("user", "id", "name", "age")); jedis.hdel("user", "age"); System.out.println(jedis.hexists("user", "age")); Set&lt;String&gt; keys = jedis.hkeys("user"); for (String str : keys) System.out.println(str + "-" + jedis.hget("user", str)); &#125; /** * list操作 */ @Test public void test03() &#123; jedis.lpush("test", "h1"); jedis.lpush("test", "h2"); jedis.lpush("test", "h3"); System.out.println(jedis.lrange("test", 0, -1)); System.out.println(jedis.lpop("test")); System.out.println(jedis.lrange("test", 0, -1)); jedis.lrem("test", 0, "h1"); jedis.lrem("test", 1, "h2"); jedis.lrem("test", 2, "h3"); &#125; /** * set操作 */ @Test public void test04() &#123; jedis.sadd("users", "zs"); jedis.sadd("users", "ls"); jedis.sadd("users", "ww"); System.out.println(jedis.smembers("users")); System.out.println(jedis.sismember("users", "zss")); System.out.println(jedis.srandmember("users")); System.out.println(jedis.spop("users")); System.out.println(jedis.scard("users")); RedisUtils.returnResource(jedis); &#125; /** * sort set */ @Test public void test05() &#123; jedis.zadd("stu", 100, "zs"); jedis.zadd("stu", 30, "ls"); jedis.zadd("stu", 60, "ww"); System.out.println(jedis.zrange("stu", 0, -1)); System.out.println(jedis.zrevrange("stu", 0, -1)); System.out.println(jedis.zrangeByScore("stu", 50, 60)); RedisUtils.returnResource(jedis); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F10%2F27%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[对于 Redis,其提供了不同级别的持久化操作:​ 1、RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照​ 2、AOF 持久化记录服务器执行的所有写操作命令， 并在服务器启动时， 通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存， 新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite）， 使得 AOF文件的体积不会超出保存数据集状态所需的实际大小。 ​ 3、Redis 还可以同时使用 AOF 持久化和 RDB 持久化。在这种情况下， 当 Redis 重启时,它会优先使用 AOF 文件来还原数据集,因为 AOF 文件保存的数据集通常比 RDB文件所保存的数据集更完整。​ 4、持久化功能当然也可以进行关闭操作， 让数据仅在服务器运行时存在 RDB 持久化操作（快照 SnapShot 方式）​ 在默认情况下， Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。当然， 这里可以通过修改redis.conf 配置文件来对数据存储条件进行定义， 规定在“ N 秒内数据集至少有 M 个改动”这一条件被满足时,自动保存一次数据集。 也可以通过调用 save 或 bgsave ,手动让 Redis 进行数据集保存操作 Save |Bgsave 手动方式保存数据通过 save 操作 ， 当前 io 操作被阻塞， 当 save 保存执行完毕才会进行后续 io 操作 save 操作执行成功后可以看到 dump.rdb 文件(在 root/usr/redis-4.0.9-master/src 目录下) 快照运行方式当 Redis 需要保存 dump.rdb 文件时， 服务器执行以下操作： Redis 调用 fork() ， 同时拥有父进程和子进程。 子进程将数据集写入到一个临时 RDB 文件中。 当子进程完成对新 RDB 文件的写入时， Redis 用新 RDB 文件替换原来的 RDB 文件， 并删除 旧的 RDB 文件。 RDB 优缺点 优点: RDB 是一个非常紧凑（compact） 的文件， 它保存了 Redis 在某个时间点上的数据集。 该文件适合用于进行备份 。 比如说， 可以在最近的 24 小时内， 每小时备份一次 RDB 文件， 并且在每个月的每一天， 也备份一个 RDB 文件。 这样的话， 即使遇上问题， 也可以随时将数据集还原到不同的版本。 RDB 非常适用于灾难恢复（disaster recovery） ： 它只有一个文件， 并且内容都非常紧凑，可以（在加密后） 将它传送到别的数据中心 RDB 可以最大化 Redis 的性能： 父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程， 然后这个子进程就会处理接下来的所有保存工作， 父进程无须执行任何磁盘 I/O 操作。 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快 缺点: 如果想要做到数据实时备份级别， 此时使用 rdb 快照进行备份可能会出现数据无法备份完整情况，比如在数据备份完毕下次备份操作发起前， 服务器由于某种原因意外宕机， 此时采用 rdb 就无法对当前情况做的实时响应处理 RDB 需要经常 fork 子进程来保存数据集到硬盘上,当数据集比较大的时候,fork 的过程是非常耗时的,可能会导致Redis在一些毫秒级内不能响应客户端的请求.如果数据集巨大并且CPU性能不是很好的情况下,这种情况会持续 1 秒,AOF 也需要 fork,但是你可以调节重写日志文件的频率来提高数据集的耐久度. AOF 只追加操作的文件​ RDB 需要经常 fork 子进程来保存数据集到硬盘上,当数据集比较大的时候,fork 的过程是非常耗时的,可能会导致 Redis 在一些毫秒级内不能响应客户端的请求.如果数据集巨大并且 CPU 性能不是很好的情况下,这种情况会持续 1 秒,AOF 也需要 fork,但是你可以调节重写日志文件的频率来提高数据集的耐久度. appendonly yes ​ 从现在开始， 每当 Redis 执行一个改变数据集的命令时（比如 SET） ， 这个命令就会被追加到 AOF 文件的末尾。 这样的话， 当 Redis 重新启时， 程序就可以通过重新执行AOF 文件中的命令来达到重建数据集的目的。 日志重写 ​ 因为 AOF 的运作方式是不断地将命令追加到文件的末尾， 所以随着写入命令的不断增加，AOF 文件的体积也会变得越来越大。 举个例子， 如果你对一个计数器调用了 100 次INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录（entry） 。 然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。 ​ 为了处理这种情况， Redis 支持一种有趣的特性： 可以在不打断服务客户端的情况下， 对AOF 文件进行重建（rebuild） 。 执行 BGREWRITEAOF 命令， Redis 将生成一个新的AOF 文件， 这个文件包含重建当前数据集所需的最少命令。 Redis 2.2 需要自己手动执行 BGREWRITEAOF 命令； Redis 2.4 则可以自动触发 AOF 重写。 参考:http://www.redis.cn/topics/persistence.html AOF重写文件配置 1234567891011121314151617181920# 是否开启 AOF， 默认关闭（no）appendonly yes# 指定 AOF 文件名appendfilename appendonly.aof# Redis 支持三种不同的刷写模式：# appendfsync always #每次收到写命令就立即强制写入磁盘， 是最有保证的完全的持久化， 但速度也是最慢的， 一般不推荐使用。appendfsync everysec #每秒钟强制写入磁盘一次， 在性能和持久化方面做了很好的折中， 是受推荐的方式。# appendfsync no #完全依赖 OS 的写入， 一般为 30 秒左右一次， 性能最好但是持久化最没有保证， 不被推荐。#在日志重写时， 不进行命令追加操作， 而只是将其放在缓冲区里， 避免与命令的追加造成DISK IO 上的冲突。#设置为 yes 表示 rewrite 期间对新写操作不 fsync,暂时存在内存中,等 rewrite 完成后再写入， 默认为nono-appendfsync-on-rewrite no#当前 AOF 文件大小是上次日志重写得到 AOF 文件大小的二倍时， 自动启动新的日志重写过程。auto-aof-rewrite-percentage 100#当前 AOF 文件启动新的日志重写过程的最小值， 避免刚刚启动 Reids 时由于文件尺寸较小导致频繁的重写。auto-aof-rewrite-min-size 64mb]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵机制(主备切换)]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F10%2F27%2FRedis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[​ 访问网站时为了提高响应速度，从内存中获取热点数据比从数据库中获取要快很多，Redis是一个很好的Cache工具，大型网站的热点数据往往巨大，此时一台Redis服务器内存无法满足，需要集合多台Redis，但只有一台主机，其他都是从服务器，实现读写分离。 ​ 但是，万一主机宕机或中断了怎么办。 ​ Redis哨兵机制，对服务器进行监视，当主机‘挂’了的时候，它会从其他服务器中重新拥立一个新的主机，赋予可执行功能。当‘挂’掉的主机再重新启动后，就不再是主机了。 准备这里是单台服务器不同端口模拟3台服务器（1主2从） 节点准备127.0.0.1 6379（master-主节点） 127.0.0.1 6380（slave-从节点1） 127.0.0.1 6381（slave-从节点2） 主节点redis.conf配置设置端口 ， daemonize,密码， 连接主节点密码， requirepass 禁用 bind 等 基本配置 从节点redis.conf配置从节点配置和主节点基本类似，相比多一个配置 sentinel.conf哨兵文件配置 ​ 所有哨兵起先监视主机端口 ​ 为了方便快速看到效果，设置哨兵执行时效 测试开启所有三个服务和所有哨兵 将主服务kill掉 结果发现端口号为6381的从服务成功成为主服务 再次启动原本为主服务的6379 只能乖乖当6381的奴隶了吧~ 这里的一切均为本机127.0.0.1测试，如果需要连接局域网，可以改为本机ip地址]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis搭建主从复用-读写分离]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F10%2F27%2FRedis%E6%90%AD%E5%BB%BA%E4%B8%BB%E4%BB%8E%E5%A4%8D%E7%94%A8-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[​ Redis 支持主从复用。 数据可以从主服务器向任意数量的从服务器上同步， 同步使用的是发布/订阅机制。 Mater Slave 的模式， 从 Slave 向 Master 发起 SYNC 命令。可以是 1 Master 多 Slave， 可以分层， Slave 下可以再接 Slave， 可扩展成树状结构。因为没有两台电脑， 所以只能在一台机器上搭建两个 Redis 服务端。这里使用单机来模拟 redis 主从服务器 ， 实现读写分离配置 。 ​ 由于之前redis5.0版本配置文件有些不同，选择了降低版本使用了4.0.9版本 准备将编译后的redis主文件夹复制两份，一份为master（主），一份slave（从），复制的命令为 1cp -rf redis-4.0.9 redis-4.0.9-slave ​ 我们主要操作master和slave 修改主服务器配置进入master目录，vim 编辑 redis.conf文件 修改完成后：wq保存并退出 修改从服务器配置 添加设置作为谁的从服务器 启动服务器先启动主服务master，到src目录下 1./redis-server ../redis.conf &amp; ---以配置文件启动 ‘&amp;’---在后台运行 然后启动从服务slave 启动客户端1./redis-cli 从服务器需要以指定端口启动 1./redis-cli -p 6380 启动后输入info replication查看当前服务器状态 主服务器 从服务器 ​ 看到这些信息基本配置好了，接下来进行测试 测试主服务器 可读可写 ，我们添加一条数据，测试从服务器是否能读到 从服务器只有可读权限，关注它能否读取到主服务刚才写入的数据 测试发现无法写入，可以读取主服务写入的数据 ，成功。 下一章是配置哨兵机制~]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis-五种数据类型]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F10%2F26%2Fredis-2%2F</url>
    <content type="text"><![CDATA[key 相关指令​ exists key 检测指定 key 是否存在， 返回 1 表示存在， 0 不存在​ del key1 key2 …… keyN 删除给定 key,返回删除 key 的数目， 0 表示给定 key 都不存在​ type key 返回给定 key 值的类型。 返回 none 表示 key 不存在,string 字符类型， list 链表类型 set 无序集合类型……​ keys pattern 返回匹配指定模式的所有 key​ randomkey 返回从当前数据库中随机选择的一个 key,如果当前数据库是空的， 返回空串​ rename oldkey newkey 重命名一个 key,如果 newkey 存在， 将会被覆盖， 返回1 表示成功，0 失败。 可能是 oldkey 不存在或者和 newkey 相同。​ renamenx oldkey newkey 同上， 但是如果 newkey 存在返回失败。​ expire key seconds 为 key 指定过期时间， 单位是秒。 返回 1 成功， 0 表示key 已经设置超过过期时间或者不存在。​ ttl key 返回设置过过期时间 key 的剩余过期秒数。 -1 表示 key 不存在或者未设置过期时间。​ select db-index 通过索引选择数据库， 默认连接的数据库是 0,默认数据库数是16 个。 返回 1表示成功， 0 失败。​ move key db-index 将 key 从当前数据库移动到指定数据库。 返回 1 表示成功。0 表示 key不存在或者已经在指定数据库中。 五种基本数据类型redis 提供五种数据类型： string,hash,list,set 及sorted set String 类型string 是最基本的类型， 而且 string 类型是二进制安全的。 意思是 redis 的string 可以包含任何数据。 比如 jpg 图片或者序列化的对象。 从内部实现来看其实string 可以看作 byte 组， 最大上限是 1G 字节。 1G=1024MB string 类型数据操作指令简介​ set key value 设置 key 对应 string 类型的值， 返回 1 表示成功， 0 失败。​ setnx key value 如果 key 不存在， 设置 key 对应 string 类型的值。 如果key 已经存在， 返回 0。​ get key 获取 key 对应的 string 值,如果 key 不存在返回 nil​ getset key value 先获取 key 的值，再设置 key 的值。如果 key 不存在返回 nil。​ mget key1 key2 ……keyN 一次获取多个 key 的值， 如果对应 key 不存在，则对应返回 nil。​ mset key1 value1 ……keyN valueN 一次设置多个 key 的值， 成功返回 1表示所有的值都设置了， 失败返回0 表示没有任何值被设置。​ msetnx key1 value1 ……keyN valueN 一次设置多个 key 的值， 但是不会覆盖已经存在的 key ​ incr key 对 key 的值做++操作， 并返回新的值。 注意 incr 一个不是 int 的value 会返回错误， incr 一个不存在的 key， 则设置 key 值为 1。​ decr key 对 key 的值做–操作， decr 一个不存在 key， 则设置 key 值为-1。**​ incrby key integer 对 key 加上指定值 ， key 不存在时候会设置 key， 并认为原来的 value 是 0。​ decrby** key integer 对 key 减去指定值。 decrby 完全是为了可读性， 我们完全可以通过 incrby 一个负值来实现同样效果， 反之一样 应用场景​ String 是最常用的一种数据类型， 普通的 key/value 存储都可以归为此类， value 其实不仅是 String,也可以是数字： 比如想知道什么时候封锁一个 IP 地址(访问超过几次)。INCRBY 命令让这些变得很容易， 通过原子递增保持计数。 Hash 类型Hash 类型数据操作指令​ hset key field value 设置 hash field 为指定值， 如果 key 不存在， 则创建​ hget key field 获取指定的 hash field。​ hmget key filed1….fieldN 获取全部指定的 hash filed。​ hmset key filed1 value1 ……filedN valueN 同时设置hash的多个 field。​ hincrby key field integer 将指定的 hash filed 加上指定值。 成功返回 hash filed 变更后的值。​ hexists key field 检测指定 field 是否存在。​ hdel key field 删除指定的 hash field。​ hlen key 返回指定 hash 的 field 数量​ hkeys key 返回 hash 的所有 field。​ hvals key 返回 hash 的所有 value。​ hgetall key 返回 hash 的所有 filed 和 value。 应用场景​ 我们简单举个实例来描述下 Hash 的应用场景， 比如我们要存储一个用户信息对象数据， 包含以下信息：用户 ID， 为查找的 key，存储的 value 用户对象包含姓名 name， 年龄 age， 生日 birthday 等信息，如果用普通的 key/value 结构来存储， 主要有以下 2 种存储方式：​ 第一种方式将用户ID作为查找key,把其他信息封装成一个对象以序列化的方式存储，如： set u001 “李三,18,20010101” 这种方式的缺点是， 增加了序列化/反序列化的开销， 并且在需要修改其中一项信息时， 需要把整个对象取回， 并且修改操作需要对并发进行保护， 引入 CAS 等复杂问题。​ 第二种方法是这个用户信息对象有多少成员就存成多少个 key-value 对儿， 用用户 ID+对应属性的名称作为唯一标识来取得对应属性的值，如： mset user:001:name “李三” user:001:age 18 user:001:birthday “20010101”虽然省去了序列化开销和并发问题， 但是用户 ID 为重复存储， 如果存在大量这样的数据， 内存浪费还是非常可观的。那么 Redis 提供的 Hash 很好的解决了这个问题， Redis 的 Hash 实际是内部存储的Value 为一个 HashMap，并提供了直接存取这个 Map 成员的接口，如： hmset user:001 name “李三” age 18 birthday “20010101” 也就是说， Key 仍然是用户 ID,value 是一个 Map， 这个 Map 的 key 是成员的属性名， value 是属性值，这样对数据的修改和存取都可以直接通过其内部 Map 的 Key(Redis 里称内部 Map 的 key 为 field), 也就是通过key(用户 ID) + field(属性标签) 操作对应属性数据了， 既不需要重复存储数据， 也不会带来序列化和并发修改控制的问题。 很好的解决了问题。这里同时需要注意， Redis 提供了接口(hgetall)可以直接取到全部的属性数据,但是如果内部 Map 的成员很多， 那么涉及到遍历整个内部 Map 的操作， 由于 Redis 单线程模型的缘故， 这个遍历操作可能会比较耗时， 而另其它客户端的请求完全不响应， 这点需要格外注意。 实现方式：​ 上面已经说到 Redis Hash 对应 Value 内部实际就是一个 HashMap， 实际这里会有2 种不同实现， 这个 Hash的成员比较少时 Redis 为了节省内存会采用类似一维数组的方式来紧凑存储， 而不会采用真正的 HashMap 结构， 对应的 value redisObject 的encoding 为 zipmap,当成员数量增大时会自动转成真正的 HashMap。 List 类型List 类型数据操作指令简介​ lpush key string 在 key 对应 list 的头部添加字符串元素， 返回 1 表示成功， 0表示 key 存在且不是 list 类型。​ rpush key string 在 key 对应 list 的尾部添加字符串元素。​ llen key 返回 key 对应 list 的长度， 如果 key 不存在返回 0， 如果 key 对应类型不是 list 返回错误。​ lrange key start end 返回指定区间内的元素， 下标从 0 开始， 负值表示从后面计算， -1 表示倒数第一个元素 ， key 不存在返回空列表。​ ltrim key start end 截取 list 指定区间内元素， 成功返回 1， key 不存在返回错误。​ lset key indexvalue 设置 list 中指定下标的元素值， 成功返回 1， key 或者下标不存在返回错误。​ lrem key count value 从 List 的头部 （ count 正数） 或尾部 （ count 负数）删除一定数量 （ count） 匹配 value 的元素， 返回删除的元素数量。 count 为 0时候删除全部。​ lpop key 从 list 的头部删除并返回删除元素。 如果 key 对应 list 不存在或者是空返回 nil， 如果 key 对应值不是 list 返回错误。​ rpop key 从 list 的尾部删除并返回删除元素。​ blpop key1 ……keyN timeout 从左到右扫描， 返回对第一个非空 list 进行lpop 操作并返回， 比如 blpop list1 list2 list3 0 ,如果 list 不存在list2,list3 都是非空则对 list2 做 lpop 并返回从 list2 中删除的元素。 如果所有的 list 都是空或不存在， 则会阻塞 timeout 秒， timeout 为 0 表示一直阻塞。当阻塞时， 如果有 client 对 key1…keyN 中的任意 key 进行 push 操作， 则第一在这个 key 上被阻塞的 client 会立即返回。 如果超时发生， 则返回 nil。 有点像unix 的 select 或者 poll。 ​ brpop 同 blpop， 一个是从头部删除一个是从尾部删除 应用场景​ Redis list 的应用场景非常多， 也是 Redis 最重要的数据结构之一。​ 我们可以轻松地实现最新消息排行等功能。​ Lists 的另一个应用就是队列， 可以利用 Lists 的 PUSH 操作， 将任务存在 List 中，然后工作线程再用 POP 操作将任务取出进行执行。 实现方式：​ Redis list 的实现为一个双向链表， 即可以支持反向查找和遍历， 更方便操作， 不过带来了部分额外的内存开销， Redis 内部的很多实现， 包括发送缓冲队列等也都是用的这个数据结构。 Set 类型​ 是无序集合， 最大可以包含(2 的 32 次方-1)个元素。 set 的是通过 hashtable 实现的， 所以添加， 删除， 查找的复杂度都是 O(1)。 hash table 会随着添加或者删除自动的调整大小。 需要注意的是调整 hashtable 大小时候需要同步（获取写锁）会阻塞其他读写操作。 可能不久后就会改用跳表（ skip list） 来实现。 跳表已经在 sortedsets 中使用了。 关于 set 集合类型除了基本的添加删除操作， 其它有用的操作还包含集合的取并集(union)， 交集(intersection)， 差集(difference)。通过这些操作可以很容易的实现 SNS 中的好友推荐和 blog 的 tag 功能 set 类型数据操作指令简介​ sadd key member 添加一个 string 元素到 key 对应 set 集合中， 成功返回 1,如果元素以及在集合中则返回 0， key 对应的 set 不存在则返回错误。​ srem key member 从 key 对应 set 中移除指定元素， 成功返回 1， 如果 member在集合中不存在或者 key 不存在返回 0， 如果 key 对应的不是 set 类型的值返回错误。​ spop key 删除并返回 key 对应 set 中随机的一个元素,如果 set 是空或者 key不存在返回 nil。​ srandmember key 同 spop， 随机取 set 中的一个元素， 但是不删除元素。​ smove srckey dstkey member 从 srckey 对应 set 中移除 member 并添加到dstkey 对应 set 中， 整个操作是原子的。 成功返回 1,如果 member 在 srckey 中不存在返回 0， 如果 key 不是 set 类型返回错误。​ Scard key 返回 set 的元素个数， 如果 set 是空或者 key 不存在返回 0。​ sismember key member 判断 member 是否在 set 中， 存在返回 1， 0 表示不存在或者 key 不存在。​ sinter key1 key2 …… keyN 返回所有给定 key 的交集。​ sinterstore dstkey key1 ……. keyN 返回所有给定 key 的交集， 并保存交集存到 dstkey 下。​ sunion key1 key2 …… keyN 返回所有给定 key 的并集。​ sunionstore dstkey key1 ……keyN 返回所有给定 key 的并集， 并保存并集到 dstkey 下。​ sdiff key1 key2 ……keyN 返回所有给定 key 的差集。​ sdiffstore dstkey key1 ……keyN 返回所有给定 key 的差集， 并保存差集到 dstkey 下。​ smembers key 返回 key 对应 set 的所有元素， 结果是无序的。 应用场景​ Redis set 对外提供的功能与 list 类似是一个列表的功能， 特殊之处在于 set 是可以自动排重的， 当你需要存储一个列表数据， 又不希望出现重复数据时， set 是一个很好的选择， 并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口， 这个也是 list所不能提供的。​ 比如在微博应用中， 每个人的好友存在一个集合（set） 中， 这样求两个人的共同好友的操作， 可能就只需要用求交集命令即可。 （新浪微博关注共同好友） ​ Redis 还为集合提供了求交集、 并集、 差集等操作。实现方式：​ set 的内部实现是一个 value 永远为 null 的 HashMap， 实际就是通过计算 hash的方式来快速排重的， 这也是 set 能提供判断一个成员是否在集合内的原因。 Sorted Set 类型​ Sorted Set 是有序集合， 它在 set 的基础上增加了一个顺序属性， 这一属性在添加修改元素的时候可以指定， 每次指定后， 会自动重新按新的值调整顺序。 可以理解了有两列的 mysql 表， 一列存 value， 一列存顺序。 操作中 key 理解为sorted set 的名字， 最多包含 2&gt;32-1 个元素 。 Sorted Set 类型数据操作指令简介​ zadd key score member 添加元素到集合， 元素在集合中存在则更新对应 score。​ zrem key member 删除指定元素， 1 表示成功， 如果元素不存在返回 0。​ zincrby key incrmember 增加对应 member 的 score 值， 然后移动元素并保持 skip list 保持有序。 返回更新后的 score 值。​ zrank key member 返回指定元素在集合中的排名（下标）， 集合中元素是按 score从小到大排序的。​ zrevrankkey member 同上,但是集合中元素是按 score 从大到小排序。​ zrange key start end 类似 lrange 操作从集合中去指定区间的元素。 返回的是有序结果​ zrevrange key start end 同上， 返回结果是按 score 逆序的。​ zrangebyscore key min max 返回集合中 score 在给定区间的元素。​ zcount key min max 返回集合中 score 在给定区间的数量。​ zcard key 返回集合中元素个数。​ zscore key element 返回给定元素对应的 score 应用场景​ 以某个条件为权重， 比如按顶的次数排序.ZREVRANGE 命令可以用来按照得分来获取前 100 名的用户， ZRANK 可以用来获取用户排名， 非常直接而且操作容易。​ Redis sorted set 的使用场景与 set 类似， 区别是 set 不是自动有序的， 而 sorted set 可以通过用户额外提供一个优先级(score)的参数来为成员排序， 并且是插入有序的，即自动排序。​ 比如:twitter 的 public timeline 可以以发表时间作为 score 来存储， 这样获取时就是自动按时间排好序的。​ 比如:全班同学成绩的 SortedSets， value 可以是同学的学号， 而 score 就可以是其考试得分， 这样数据插入集合的， 就已经进行了天然的排序。​ 比如网易云音乐排行榜实现；​ 另外还可以用 Sorted Sets 来做带权重的队列， 比如普通消息的 score 为 1， 重要消息的 score 为 2， 然后工作线程可以选择按 score 的倒序来获取工作任务。 让重要的任务优先执行。需要精准设定过期时间的应用​ 比如你可以把上面说到的 sorted set 的 score 值设置成过期时间的时间戳， 那么就可以简单地通过过期时间排序， 定时清除过期数据了， 不仅是清除 Redis 中的过期数据，你完全可以把 Redis 里这个过期时间当成是对数据库中数据的索引， 用 Redis 来找出哪些数据需要过期删除， 然后再精准地从数据库中删除相应的记录。]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis简介和安装]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F10%2F25%2Fredis-1%2F</url>
    <content type="text"><![CDATA[介绍​ Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。 ——http://www.redis.cn/ 小结： Redis 是把数据存放在内存当中， 所以它的运行速度会非常快 Redis 具有多种数据存储结构 Redis 具有持久化的功能 Redis 上的数据可以设置过期 Redis 支持集群， 而且可以自动切换 跨平台 支持多种语言客户端 Redis 用途： ​ 缓存（StackOverFlow）， 数据库(微博)， 消息中间件（队列， 微博） Redis安装环境：centerOS 6.7 虚拟机 redis版本：5.0 1、通过xshell建立连接，使用wget命令下载对应的节点资源 wget http://download.redis.io/releases/redis-5.0.0.tar.gz ​ 或者去官网下载，使用xftp导入 2、安装gcc环境 ​ yum install gcc 3、解压redis压缩文件 ​ tar zxf redis-5.0.0.tar.gz 4、进入解压后的文件夹 ​ make -编译 ​ 完成~ 启动redis服务进入src目录 ./redis-server &amp; 在后面加上&amp;在启动服务后可以继续别的操作，否则以当前窗口启动无法进行其他操作。 出现以上界面表示服务启动成功 启动客户端 ./redis-cli 启动成功就可以在里面愉快地敲命令了！]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot文件上传]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F05%2F08%2FSpringBoot%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[Pom文件依赖12345678910&lt;!--freemarker--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--web mvc--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 在application.properties中设置最大文件上传大小 12## 文件上传配置最大上传文件大小spring.servlet.multipart.max-file-size=10MB 编写Controller层代码1234567891011121314151617181920212223242526272829303132333435@Controllerpublic class UploadController &#123; @RequestMapping("uploadFile") public ModelAndView uploadFile(HttpServletRequest request) &#123; // 设置结果视图 ModelAndView mv = new ModelAndView("result"); // 获取MultipartHttpServletRequest对象 MultipartHttpServletRequest multipartHttpServletRequest = (MultipartHttpServletRequest) request; // 获取上传的文件 MultipartFile mf = multipartHttpServletRequest.getFile("file"); try &#123; if (null != mf &amp;&amp; !mf.isEmpty()) &#123; // 获取文件上传的路径，可以用第三方存储服务器代替 String path = request.getSession().getServletContext().getRealPath("/WEB-INF/upload"); // 获取文件名 String fileName = mf.getOriginalFilename(); File file = new File(path, fileName); // 判断父目录是否存在 if (!file.getParentFile().exists()) &#123; // 不存在则新建 file.getParentFile().mkdir(); &#125; // 上传操作 mf.transferTo(file); // 将结果存到作用域中 mv.addObject("msg", "文件上传成功!"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); mv.addObject("msg", "文件上传失败!"); &#125; return mv; &#125;&#125; 添加result视图页面1结果：$&#123;msg !''&#125;&lt;!--防止msg为空报错--&gt; 测试因为SpringBoot没有WEB-INF目录，所以需要将应用打包成war包到外部容器中运行 放到tomcat/webapps目录下，执行startup.bat 使用postman测试]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot配置]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F05%2F07%2FSpringBoot%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[​ 如果说Maven整合了Jar文件管理，SpringBoot就相当于整合了框架、中间件或一些第三方插件，它使用“约定大于配置”，即默认帮我们配好了大部分配置，借助SpringBoot我们可以快速创建web应用。这里不从头开始体现，只说明一些核心的常用的配置。 不得不说@SpringBootApplication@SpringBootApplication注解是SpringBoot的核心注解，它是一个组合注解，其注解定义源码为： 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; SpringBootApplication注解组合了@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan注解 @SpringBootConfiguration123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Configurationpublic @interface SpringBootConfiguration &#123;&#125; ​ 它组合了@Configuration注解，对于 SpringBoot 应用， @SpringBootConfiguration 注解属于 Boot 项目的配置注解也是属于一个组合注解， Spring Boot 项目中推荐使用@SpringBootConfiguration 注解,因为其包含了@Configuration 注解。 @EnableAutoConfiguration1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; ​ @EnableAutoConfiguration组合了@AutoConfigurationPackage、@Import注解，使用该注解，代表 Spring Boot 应用在启动后默认启用自动配置 @ComponentScan12345@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Documented@Repeatable(ComponentScans.class)public @interface ComponentScan &#123; 组件扫描注解，如果没有配置，默认扫描@SpringBootApplication所在类的同级目录以及它的子目录 Profile配置 Profile 是 Spring 用来针对不同环境对不同配置提供支持的全局 Profile 配置使用application-{profile}.properties，比如 application-dev.properties ,application-test.properties通过在 application.properties 中设置 spring.profiles.active=test|dev|prod 来动态切换不同环境 我们定义不同的三种配置环境test、dev、prod 然后将环境切换定义在application.properties文件中 1spring.profiles.active=dev 日志配置12345678# 日志打印信息级别 debuglogging.pattern.level=debug# 控制台日志输出格式logging.pattern.console=%d [%t] %-5p [%c] -%m%n# 指定文件输出路径logging.file=c:/java/test.log Jar包和War包的部署jar包相对来说比较简单，因为内置tomcat容器，我们甚至可以直接运行jar文件 maven配置命令：clean compile package jar包运行命令：java jar + jar包路径+名字 war包部署： 1、设置pom文件工程打包类型 2、添加tomcat依赖并设置不运行 123456&lt;!--设置内嵌tomcat不运行--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3、在启动类中添加入口给外部Tomcat，继承SpringBootServletInitializer，重写configure方法 123456789101112@SpringBootApplicationpublic class Springboot01Application extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; SpringApplication.run(Springboot01Application.class, args); &#125; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(Springboot01Application.class); &#125;&#125; war包打包命令：clean compile package jar包和war包打包完成在编译后的target目录 将war包放入tomcat的webapp目录下，运行startup.bat]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring4.X+基于注解的配置]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F05%2F06%2FSpring4-X-%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Spring 框架从 4.x 版本开始推荐使用注解形式来对 java 应用程序进行开发与配置,并且可以完全替代原始的 XML+注解形式的开发。 注解解释@Configuration：作用与类上，将当前类声明为一个配置类，相当于一个XML配置文件 @ComponentScan：自动扫描指定包下有@Repository，@Service，@Controller，@Component的类进行实例化 @Bean：作用于方法上，相当于XML文件中的，声明当前方法返回值为一个bean @Value：配合@PropertySource可以获取properties文件中的内容 接下来我们通过代码来证明这些注解使用的正确 使用引入Spring4.X版本的依赖 然后写一个测试用的UserDao和UserService 123456@Repositorypublic class UserDao &#123; public void test() &#123; System.out.println("UserDao.test..."); &#125;&#125; 12345678910@Servicepublic class UserService &#123; @Resource private UserDao userDao; public void test() &#123; System.out.println("UserService.test..."); userDao.test(); &#125;&#125; 此时我们没有配置任何的XML配置文件 再创建一个类，在其类上标注@Configuration和@ComponentScan并指明扫描范围 12345@Configuration@ComponentScan("com.dlh")public class IocConfig &#123; &#125; 此时标注有@Repository和@Service的两个类创建对象的过程交给Spring的IoC容器来管理，其对象默认为单例 加载我们Spring上下文并且调用对应的bean对象即可看到结果，注意：这里是以Annotation配置的方式 1234567public class Starter &#123; public static void main(String[] args)&#123; ApplicationContext context = new AnnotationConfigApplicationContext(IocConfig.class); UserService userService = (UserService) context.getBean("userService"); userService.test(); &#125;&#125; 我们再来看看@Bean和@Value两个注解，我们做一个数据库连接池的配置 准备好jdbc.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://127.0.0.1:3306/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8jdbc.username=rootjdbc.password=123456 然后在IocConfig类上添加@PropertySource并指明文件路径，可以同时配置多个文件 在字段上标注@Value并以El-Spring表达式取值 123456789101112131415161718192021222324@Configuration@ComponentScan("com.dlh")@PropertySource("classpath:jdbc.properties")public class IocConfig &#123; @Value("$&#123;jdbc.username&#125;") private String userName; @Value("$&#123;jdbc.password&#125;") private String password; @Value("$&#123;jdbc.driver&#125;") private String driver; @Value("$&#123;jdbc.url&#125;") private String url; @Bean public ComboPooledDataSource dataSource() throws PropertyVetoException &#123; ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(userName); dataSource.setPassword(password); dataSource.setJdbcUrl(url); dataSource.setDriverClass(driver); return dataSource; &#125;&#125; 这样的配置等同于以前XML这样的配置 123456&lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;property name="driverClass" value="$&#123;jdbc.driver&#125;"/&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="user" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt;&lt;/bean&gt; 我们在IocConfig类重写toString方法打印一下里面的属性即可看到赋值是否成功]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-异常处理]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F04%2F12%2FSpringMVC%E5%AD%A6%E4%B9%A0-8%2F</url>
    <content type="text"><![CDATA[SpringMVC处理全局异常1、使用SpringMVC提供的简单异常处理器SimpleMappingExceptionResolver 2、实现Spring的异常处理接口HandlerExceptionResolver定义自己的异常处理器 3、使用@ExceptionHandler 注解实现异常处理 全局异常处理方式一配置SimpleMappingExceptionResolver对象（配置servlet-context配置文件） 123456789&lt;bean class="org.springframework.web.servlet.handler.SimpleMappingExceptionResolver"&gt; &lt;property name="defaultErrorView" value="error"&gt;&lt;/property&gt; &lt;property name="exceptionAttribute" value="ex"&gt;&lt;/property&gt; &lt;property name="exceptionMappings"&gt; &lt;props&gt; &lt;prop key="com.dlh.exception.ParamException"&gt;param&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt; ​ 优点：集成简单，有良好的扩展性，对已有代码没有入侵性等 ​ 缺点：该方法仅能获取到异常信息，若在出现异常时，对需要获取除异常以外的数据的情况不适用。 全局异常处理方式二定义自己的异常处理器，实现HandlerExceptionResolver接口 12345678910111213141516171819202122232425@Component // 在需要使用时只需要加上这个注解交给spring管理即可public class MyExceptionHandler implements HandlerExceptionResolver &#123; @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; System.out.println("============================="); System.out.println("======MyExceptionHandler====="); System.out.println("============================="); ModelAndView mv = new ModelAndView(); // 当发生参数异常时 instanceof--判断左边对象是否是右边类的实例 if (ex instanceof ParamException)&#123; // 将异常转为参数异常 ParamException paramException = (ParamException) ex; // 设置视图页面 mv.setViewName("param"); // 设置模型数据 mv.addObject("ex",ex); return mv; &#125; mv.setViewName("error"); mv.addObject("ex",ex); return mv; &#125;&#125; ​ 相比于配置SimpleMappingExceptionResolver对象方式，实现接口的方式能在异常处理时获取出现异常的对象，能提供更详细的异常处理信息 全局异常处理方式三定义异常处理器，使用@ExceptionHandler注解，页面处理器继承异常处理器 1234567891011public class ExceptionController &#123; @ExceptionHandler public String ex(HttpServletRequest request, Exception e)&#123; request.setAttribute("ex",e); if (e instanceof ParamException)&#123; return "param"; &#125; return "error"; &#125;&#125; 123456789101112@Controller@RequestMapping("index")public class IndexController extends ExceptionController&#123; /*参数异常*/ @RequestMapping("test01") public String test01() &#123; if (true)&#123; throw new ParamException("参数异常"); &#125; return "index"; &#125;&#125; ​ 该方法需要修改已有代码，且受限于java单继承的局限性，在获取异常时不能获取除异常之外的数据 未捕获异常的处理​ 对于Unchecked Exception而言，由于代码不强制捕获，往往被忽略，如果运行期产生了Unchecked Exception，而代码中又没有进行相应的捕获和处理，则我们可能不得不面对尴尬的404、500……等服务器内部错误提示页面。​ 我们需要一个全面而有效的异常处理机制。目前大多数服务器也都支持在Web.xml中通过(Websphere/Weblogic)或者(Tomcat)节点配置特定异常情况的显示页面。修改 web.xml 文件，增加以下内容： 12345678910111213&lt;!-- 出错页面定义 --&gt; &lt;error-page&gt; &lt;exception-type&gt;java.lang.Throwable&lt;/exception-type&gt; &lt;location&gt;/500.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/500.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/404.jsp&lt;/location&gt; &lt;/error-page&gt;]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-SpringMVC实现RestFul服务]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F04%2F12%2FSpringMVC%E5%AD%A6%E4%B9%A0-7%2F</url>
    <content type="text"><![CDATA[​ Restful 风格的 API 是一种软件架构风格， 设计风格而不是标准， 只是提供了一组设计原则和约束条件。 它主要用于客户端和服务器交互类的软件。 基于这个风格设计的软件可以更简洁， 更有层次， 更易于实现缓存等机制。​ 在 Restful 风格中， 用户请求的 url 使用同一个 url 而用请求方式： get， post，delete， put…等方式对请求的处理方法进行区分， 这样可以在前后台分离式的开发中使得前端开发人员不会对请求的资源地址产生混淆和大量的检查方法名的麻烦， 形成一个统一的接口。 在 Restful 风格中， 现有规定如下：​ GET（ SELECT） ： 从服务器查询， 可以在服务器通过请求的参数区分查询的方式。​ POST（ CREATE） ： 在服务器端新建一个资源， 调用 insert 操作。​ PUT（ UPDATE） ： 在服务器端更新资源， 调用 update 操作。​ PATCH（ UPDATE） ： 在服务器端更新资源（ 客户端提供改变的属性） 。 (目前jdk7 未实现， tomcat7 不支持)。​ DELETE（ DELETE） ： 从服务器端删除资源， 调用 delete 语句。 Spring Mvc 中对 rest 的支持案例：​ 如何在 java 构造没有扩展名的 RESTful url,如 /forms/1 SpringMvc Restful 风格 url 配置实现​ springmvc 的 resturl是通过@RequestMapping 及@PathVariable annotation提供的,通过如@RequestMapping(value=”/blog /{id}”,method=RequestMethod.DELETE)即可处理/blog/1 的 delete 请求. GET请求配置1234567891011121314151617/** * restful--&gt;get 请求 执行查询操作 * @param id * @return */ @RequestMapping(value="queryAccountById02/&#123;id&#125;",method= RequestMethod.GET,produces= MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseBody public MessageModel queryAccountById(@PathVariable Integer id)&#123; MessageModel messageModel=new MessageModel(); if(null==id)&#123; messageModel.setCode(300); messageModel.setMsg("参数非法!"); return messageModel; &#125; messageModel.setResult(accountService.queryById(id)); return messageModel; &#125; POST请求配置12345678910111213141516171819202122/* restful--&gt;post 请求执行添加操作 * @param id * @param aname * @return */@RequestMapping(value = "saveAccount", method = RequestMethod.POST, produces = MediaType.APPLICATION_JSON_UTF8_VALUE)@ResponseBodypublic MessageModel queryAccountById04(@RequestBody Account account) &#123; MessageModel messageModel = new MessageModel(); try &#123; accountService.saveOrUpdateAccount(account); &#125; catch (ParamsException e) &#123; e.printStackTrace(); messageModel.setCode(e.getErrorCode()); messageModel.setMsg(e.getErrorMsg()); &#125; catch (Exception e) &#123; e.printStackTrace(); messageModel.setCode(300); messageModel.setMsg("操作失败!"); &#125; return messageModel;&#125; Put请求配置12345678910111213141516171819202122/* restful--&gt;put 请求执行更新操作 * @param id * @param account * @return */@RequestMapping(value = "update/&#123;id&#125;", method = RequestMethod.PUT, produces = MediaType.APPLICATION_JSON_UTF8_VALUE)@ResponseBodypublic MessageModel queryAccountById04(@PathVariable Integer id, @RequestBody Account account) &#123; MessageModel messageModel = new MessageModel(); try &#123; accountService.saveOrUpdateAccount(account); &#125; catch (ParamsException e) &#123; e.printStackTrace(); messageModel.setCode(e.getErrorCode()); messageModel.setMsg(e.getErrorMsg()); &#125; catch (Exception e) &#123; e.printStackTrace(); messageModel.setCode(300); messageModel.setMsg("操作失败!"); &#125; return messageModel;&#125; Delete请求配置12345678910111213141516171819202122/* restful--&gt;delete 请求 执行删除操作 * @param id * @return */@RequestMapping(value = "deleteAccountById/&#123;id&#125;", method = RequestMethod .DELETE, produces = MediaType.APPLICATION_JSON_UTF8_VALUE)@ResponseBodypublic MessageModel queryAccountById05(@PathVariable Integer id) &#123; MessageModel messageModel = new MessageModel(); try &#123; accountService.deleteAccountById(id); &#125; catch (ParamsException e) &#123; e.printStackTrace(); messageModel.setCode(e.getErrorCode()); messageModel.setMsg(e.getErrorMsg()); &#125; catch (Exception e) &#123; e.printStackTrace(); messageModel.setCode(300); messageModel.setMsg("操作失败!"); &#125; return messageModel;&#125;]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-文件上传-SSM整合]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F04%2F11%2FSpringMVC%E5%AD%A6%E4%B9%A0-6%2F</url>
    <content type="text"><![CDATA[步骤添加依赖12345&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; 配置servlet-context.xml123456789&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="maxUploadSize"&gt; &lt;value&gt;104857600&lt;/value&gt; &lt;/property&gt; &lt;property name="maxInMemorySize"&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 实现代码1234567891011121314151617181920212223242526@Controllerpublic class FileController &#123; @RequestMapping("file") public String fileUp(HttpServletRequest request, Model model)&#123; MultipartHttpServletRequest multRequest = (MultipartHttpServletRequest) request; MultipartFile file = multRequest.getFile("file"); if (null!=file &amp;&amp; !file.isEmpty())&#123; String path = request.getSession().getServletContext().getRealPath("upload"); String fileName = file.getOriginalFilename(); try &#123; file.transferTo(new File(path,fileName)); model.addAttribute("msg","上传成功"); &#125; catch (IOException e) &#123; e.printStackTrace(); model.addAttribute("msg","上传失败"); &#125; &#125; return "success"; &#125; @RequestMapping("fileUp") public String file()&#123; return "file"; &#125;&#125; 前台页面代码1234567891011&lt;html&gt;&lt;head&gt; &lt;title&gt;文件上传&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="file" method="post" enctype="multipart/form-data"&gt; &lt;input type="file" name="file"&gt; &lt;input type="submit"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 123456789&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;结果&lt;/title&gt;&lt;/head&gt;&lt;body&gt;操作：$&#123;msg&#125;&lt;/body&gt;&lt;/html&gt; 测试选择一个文件 提交 此时上传的文件已经在webapp/upload目录下 关于SSM整合 整合完成的项目我已经放在GitHub上 https://github.com/dlh1234okok/SSM]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-拦截器]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F04%2F11%2FSpringMVC%E5%AD%A6%E4%B9%A0-5%2F</url>
    <content type="text"><![CDATA[​ SpringMVC 中的 Interceptor 拦截器也是相当重要和相当有用的，它的主要作用是拦截用户的请求并进行相应的处理。比如通过它来进行权限验证，或者是来判断用户是否登陆等操作。 对于 springmvc 拦截器的定义方式有两种方式 实现接口： org.springframework.web.servlet.HandlerInterceptor 继承适配器 org.springframework.web.servlet.handler.HandlerInterceptorAdapter 实现接口1234567891011121314151617181920212223public class MyInterceptor implements HandlerInterceptor &#123; // 请求方法执行前执行 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("method before..."); // 请求地址 System.out.println(handler); // true代表放行，false拦截 return true; &#125; // 请求方法执行后执行 @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("method after..."); &#125; // 视图生成后执行 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("view after..."); &#125;&#125; 继承HandlerInterceptorAdapter123456789101112public class MyInterceptor2 extends HandlerInterceptorAdapter &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("before preHandle..."); return true; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("after completion"); &#125;&#125; 拦截器的配置全局拦截123&lt;mvc:interceptors&gt; &lt;bean class="com.dlh.interceptor.MyInterceptor"/&gt;&lt;/mvc:interceptors&gt; 部分拦截（拦截指定请求）123456&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/user/*"/&gt; &lt;bean class="com.dlh.interceptor.MyInterceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 简单的登录拦截拦截器类代码123456789101112131415161718public class LoginInterceptor extends HandlerInterceptorAdapter &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String uri = request.getRequestURI(); if (uri.indexOf("login") != -1) &#123; return true; &#125; else &#123; // 判断Session是否存在（是否已登录） User user = (User) request.getSession().getAttribute("user"); if (null != user) &#123; return true; &#125; else &#123; response.sendRedirect(request.getContextPath() + "/login.jsp"); return false; &#125; &#125; &#125;&#125; 配置文件配置123456&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/*/*"/&gt; &lt;bean class="com.dlh.interceptor.LoginInterceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 还有一种方式： 1234567&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/*/*"/&gt; &lt;mvc:exclude-mapping path="/user/login"/&gt; &lt;bean class="com.dlh.interceptor.LoginInterceptor2"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 在这里已经放行了登录地址，所以拦截器代码不需要再获取请求地址判断。 登录代码12345678910111213@RequestMapping("login")public String login(User user, Model model, HttpSession session)&#123; final String USERNAME="zs"; final String USERPWD="123"; System.out.println(user.getUserName()+"+"+user.getUserPwd()); if (USERNAME.equals(user.getUserName()) &amp;&amp; USERPWD.equals(user.getUserPwd()))&#123; model.addAttribute("msg","登陆成功"); session.setAttribute("user",user); &#125;else&#123; model.addAttribute("msg","帐号或密码错误"); &#125; return "index";&#125; 效果初次重启了服务器，Session不存在，输入简易查询的路径 1http://localhost:8080/springmvc01/user/user01 被拦截重定向到登录界面了 当我们登录后再次进行查询 简易的登录拦截器就完成了。]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-requst,response和JSON格式]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F04%2F11%2FSpringMVC%E5%AD%A6%E4%B9%A0-4%2F</url>
    <content type="text"><![CDATA[JSON数据返回@ResponseBody​ 该注解用于将 Controller 的方法返回的对象，通过适当的 HttpMessageConverter转换为指定格式后，写入到 Response 对象的 body 数据区。​ 返回的数据不是 html 标签的页面，而是其他某种格式的数据时（如 json、xml 等）使用（通常用于 ajax 请求） @RequestBody​ 该注解用于读取 Request 请求的 body 部分数据，使用系统默认配置的HttpMessageConverter 进行解析，然后把相应的数据绑定到要返回的对象上 ,再把HttpMessageConverter 返回的对象数据绑定到 controller 中方法的参数上 步骤： 1、添加json依赖jar包 12345678910111213141516&lt;!-- 添加 json 依赖 jar 包 --&gt;&lt;dependency&gt;&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&lt;artifactId&gt;jackson-core&lt;/artifactId&gt;&lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;&lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 2、修改servlet-context.xml 添加json转换器配置 123456789&lt;!-- json 支持 --&gt;&lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping"&gt;&lt;/bean&gt;&lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter"&gt; &lt;property name="messageConverters"&gt; &lt;list&gt; &lt;bean class="org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 在方法上定义@ResponseBody 123456789@RequestMapping("view01")@ResponseBodypublic User queryUser(Integer id)&#123; User user = new User(); user.setId(id); user.setUserName("zs"); user.setUserPwd("123"); return user;&#125; 查看结果： 获取request和response对象123456789@RequestMapping("user01")public String user01(HttpServletRequest request, HttpServletResponse response, HttpSession session)&#123; request.getParameter("request"); response.addCookie(new Cookie("cookie","a")); session.getAttribute("user"); return "hello";&#125;]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-请求转发和重定向]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F04%2F11%2FSpringMVC%E5%AD%A6%E4%B9%A0-3%2F</url>
    <content type="text"><![CDATA[区别1、请求转发是在服务端完成的，重定向是在客户端完成的 2、请求转发是一次请求，重定向是两次请求 3、请求转发地址栏不会发生变化，重定向地址栏会发生变化 4、请求转发速度快，重定向速度慢 5、请求转发只能在同一台服务器下完成，重定向能在不同服务器完成 请求转发转发到view页面 12345@RequestMapping("index08")public String index08()&#123; System.out.println("index08..."); return "hello";&#125; 转发到方法上 12345@RequestMapping("index07")public String index07()&#123; System.out.println("index07..."); return "forward:/index08";&#125; 重定向直接返回redirect+页面 12345678/** * 重定向1 * @return */@RequestMapping("index04")public String index04()&#123; return "redirect:v1.jsp";&#125; 返回ModelAndView对象 12345public ModelAndView index06()&#123; ModelAndView mv = new ModelAndView(); mv.setViewName("redirect:v1.jsp"); return mv;&#125; 重定向传递参数1234@RequestMapping("index04")public String index04()&#123; return "redirect:v1.jsp?a=1&amp;b=哈哈";&#125; 用这种方法传递中文参数会出现乱码。 解决乱码 12345678910/** * 重定向中文乱码问题 * @return */@RequestMapping("index05")public String index05(RedirectAttributes redirect)&#123; redirect.addAttribute("a",1); redirect.addAttribute("b","哈哈哈"); return "redirect:v1.jsp";&#125; 结果： 重定向方法二传递参数 12345678@RequestMapping("index06")public ModelAndView index06(RedirectAttributes attributes)&#123; ModelAndView mv = new ModelAndView(); attributes.addAttribute("a","哈哈哈"); attributes.addAttribute("b","aaa"); mv.setViewName("redirect:v1.jsp"); return mv;&#125; 结果： 也成功传递了参数并解决了中文乱码问题 重定向到controller1234@RequestMapping("index004")public String index004()&#123; return "redirect:/view/view01？id=1";&#125; view01： 1234567891011121314@Controller@RequestMapping("view")public class ViewController &#123; @RequestMapping("view01") @ResponseBody public User queryUser(Integer id)&#123; User user = new User(); user.setId(id); user.setUserName("zs"); user.setUserPwd("123"); return user; &#125;&#125; 结果： ​ 我们在重定向时传递了一个id为1的参数，重定向到view01方法上获取到了。 方法二： 1234567@RequestMapping("index006")public ModelAndView index006(RedirectAttributes attributes)&#123; ModelAndView mv = new ModelAndView(); attributes.addAttribute("id",2); mv.setViewName("redirect:/view/view01"); return mv;&#125; 结果：]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-参数绑定和Session]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F04%2F11%2FSpringMVC%E5%AD%A6%E4%B9%A0-2%2F</url>
    <content type="text"><![CDATA[参数绑定​ SpringMVC是处于控制层的框架，主要处理前台页面的请求和响应，在前台发起请求后，我们需要获取传过来的参数。参数绑定是请求参数到处理器功能处理方法的方法参数上的绑定，对于参数绑定SpringMVC处理的非常灵活。 简单数据类型值必须存在，不传可以通过默认值代替 1234567@RequestMapping("index") public void data1(@RequestParam(defaultValue="10",name="age")int age, @RequestParam(defaultValue="1",name="flag")boolean flag, @RequestParam(defaultValue="100",name="s")double s) &#123; System.err.println("age:"+age+":flag:"+flag+":s:"+s); &#125; 包装类型值可以为空 123456789/** * defaultValue：默认值 * name：指定前台传参的别名 */ @RequestMapping("hello13") public String hello06(@RequestParam(defaultValue = "1",name = "page") Integer pageNum, Integer pageSize)&#123; System.out.println(pageNum+"=="+pageSize); return "hello"; &#125; 数组类型12345678/** * 数组类型 */@RequestMapping("hello07")public String hello07(Integer[] ids)&#123; for(Integer id:ids) System.out.println(id); return "hello";&#125; 前台传递参数名相同时即为数组类型，如： 1http://localhost:8080/springmvc01/hello07?ids=1&amp;ids=2&amp;ids=3 PO类型12345@RequestMapping("hello08")public String hello08(User user)&#123; System.out.println(user); return "hello";&#125; 前台传参方式如： 1http://localhost/springmvc01/hello08?userName=zs&amp;userPwd=123 List类型此时实体类需要定义List属性 1private List&lt;Phone&gt; phones; 不能直接写在controller的方法中： 12345@RequestMapping("hello09")public String hello09(User user)&#123; System.out.println(user); return "hello";&#125; 前台传参方式（必须为post方式）： 12list:&lt;input type="text" name="phones[0].num"/&gt; &lt;input type="text" name="phones[1].num"/&gt; Set类型​ 因为Set集合无序的特点，绑定Set数据时，必须先在Set对象中add添加响应数量的模型对象。 12345private Set&lt;Phone&gt; phones = new HashSet&lt;&gt;();public User() &#123; phones.add(new Phone()); phones.add(new Phone());&#125; controller方法和前台传参方式和list一样。Set集合的优点在这里是不可重复。 Map类型在实体类中定义Map属性 1private Map&lt;String,Phone&gt; map = new HashMap&lt;&gt;(); controller方法： 123456789@RequestMapping("hello11")public String hello11(User user)&#123; Set&lt;Map.Entry&lt;String, Phone&gt;&gt; entrySet = user.getMap().entrySet(); for (Map.Entry&lt;String,Phone&gt; entry:entrySet)&#123; System.out.println(entry.getKey()); System.out.println(entry.getValue()); &#125; return "hello";&#125; 前台传参方式： 123map:&lt;input type="text" name="map['a'].num"/&gt; &lt;input type="text" name="map['b'].num"/&gt; &lt;input type="text" name="map['c'].num"/&gt; 自定义复合类型添加实体的引用 1private Phone phone; controller方法： 12345@RequestMapping("hello12")public String hello12(User2 user)&#123; System.out.println(user); return "hello";&#125; 前台传参方式： 1复合类型：&lt;input type="text" name="phone.num"/&gt; 获取Session级别存储的方式123456789101112131415161718192021222324252627282930313233343536/** * Session01 * @param session * @param userName * @return */@RequestMapping("index01")public String index01(HttpSession session,String userName)&#123; session.setAttribute("userName1",userName); return "index";&#125;/** * Session02 * @return * 这里前台取参的方式为$&#123;sessionScop.userName2&#125; */ @RequestMapping("index02")public ModelAndView index02(String userName)&#123; ModelAndView mv = new ModelAndView(); mv.addObject("userName2",userName); mv.setViewName("index"); return mv;&#125;/** * Session03 * @param request * @param userName * @return */@RequestMapping("index03")public String index03(HttpServletRequest request,String userName)&#123; request.getSession().setAttribute("userName3",userName); return "index";&#125;]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-简介和环境搭建]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F04%2F11%2FSpringMVC%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[什么叫MVC​ 模型-视图-控制器（MVC） 是一个众所周知的以设计界面应用程序为基础的设计思想。 它主要通过分离模型、 视图及控制器在应用程序中的角色将业务逻辑从界面中解耦。 通常， 模型负责封装应用程序数据在视图层展示。 视图仅仅只是展示这些数据， 不包含任何业务逻辑。 控制器负责接收来自用户的请求，并调用后台服务（service 或者 dao） 来处理业务逻辑。 处理后， 后台业务层可能会返回了一些数据在视图层展示。 控制器收集这些数据及准备模型在视图层展示。 MVC 模式的核心思想是将业务逻辑从界面中分离出来， 允许它们单独改变而不会相互影响。 SpringMVC是什么​ Spring MVC 是 Spring 家族中的一个 web 成员, 它是一种基于 Java 的实现了 Web MVC 设计思想的请求驱动类型的轻量级 Web 框架， 即使用了 MVC 架构模式的思想， 将 web 层进行职责解耦， 基于请求驱动指的就是使用请求-响应模型， 框架的目的就是帮助我们简化开发， Spring MVC 也是要简化我们日常Web 开发的。​ Spring MVC 是服务到工作者思想的实现。 前端控制器是DispatcherServlet； 应用控制器拆为处理器映射器(Handler Mapping)进行处理器管理和视图解析器(View Resolver)进行视图管理； 支持本地化/国际化（Locale） 解析及文件上传等； 提供了非常灵活的数据验证、 格式化和数据绑定机制； 提供了强大的约定大于配置（惯例优先原则） 的契约式编程支持。 环境搭建开发环境​ IDEA+JDK1.8+Maven+Jetty 添加依赖12345678910111213141516171819&lt;!-- spring web --&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-web&lt;/artifactId&gt;&lt;version&gt;4.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- spring mvc --&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;&lt;version&gt;4.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- web servlet --&gt;&lt;dependency&gt;&lt;groupId&gt;javax.servlet&lt;/groupId&gt;&lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;&lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt; jetty插件 12345678910111213141516171819202122&lt;plugins&gt;&lt;!-- 编译环境插件 --&gt;&lt;plugin&gt;&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&lt;version&gt;2.3.2&lt;/version&gt;&lt;configuration&gt;&lt;source&gt;1.7&lt;/source&gt;&lt;target&gt;1.7&lt;/target&gt;&lt;encoding&gt;UTF-8&lt;/encoding&gt;&lt;/configuration&gt;&lt;/plugin&gt;&lt;plugin&gt;&lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;&lt;artifactId&gt;maven-jetty-plugin&lt;/artifactId&gt;&lt;version&gt;6.1.25&lt;/version&gt;&lt;configuration&gt;&lt;scanIntervalSeconds&gt;10&lt;/scanIntervalSeconds&gt;&lt;contextPath&gt;/springmvc01&lt;/contextPath&gt;&lt;/configuration&gt;&lt;/plugin&gt;&lt;/plugins&gt; 配置web.xml（前端控制器配置）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app id="WebApp_ID" version="3.0" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"&gt; &lt;!-- 表示容器启动时 加载上下文配置 这里指定spring 相关配置 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 启用spring容器环境上下文监听 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 编码过滤 utf-8 --&gt; &lt;filter&gt; &lt;description&gt;char encoding filter&lt;/description&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- servlet请求分发器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:servlet-context.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 表示启动容器时初始化该Servlet --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMvc&lt;/servlet-name&gt; &lt;!-- 这是拦截请求, /代表拦截所有请求,拦截所有请求 --&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 配置servlet-context.xml1234567891011121314151617181920212223242526272829&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation=" http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;!-- 扫描com.dlh.controller 下包 --&gt; &lt;context:component-scan base-package="com.dlh.controller"/&gt; &lt;!-- mvc 请求映射 处理器与适配器配置--&gt; &lt;mvc:annotation-driven/&gt; &lt;!--配置视图解析器 默认的视图解析器- --&gt; &lt;bean id="defaultViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView"/&gt; &lt;property name="contentType" value="text/html"/&gt; &lt;property name="prefix" value="/WEB-INF/jsp/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt;&lt;/beans&gt; 至此，环境配置基本完成了，我们来小试一波 测试添加视图页面（jsp页面）​ 因为我们在servlet-context.xml中配置的视图解析器，配置的是WEB-INF下的JSP目录和后缀.jsp，所以SpringMVC在解析视图的时候，只会解析改目录下的jsp文件，所以添加视图页面的时候需要新建一个jsp目录。 创建Controller类123456789@Controller // 定义为controller类@RequestMapping("hello") // 将url和类绑定public class HelloController &#123; @RequestMapping("index") // 将url和方法绑定 （配置映射关系） public String hello() &#123; return "hello_springmvc"; &#125;&#125; 启动和访问1、启动jetty 2、访问 本机ip:端口号/jetty的访问地址/类访问路径/方法访问路径]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybatis-mybatis Dao层、Service层封装]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F15%2FMybatis%E5%AD%A6%E4%B9%A0-8%2F</url>
    <content type="text"><![CDATA[Dao层 BaseMapper定义与实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.dlh.base;import org.springframework.dao.DataAccessException;import java.util.List;import java.util.Map;public interface BaseMapper&lt;T&gt; &#123; /** * 添加记录不返回主键 * * @param entity * @return * @throws DataAccessException */ public int insert(T entity) throws DataAccessException; /** * * * @return * @throws DataAccessException */ public int insertBatch(List&lt;T&gt; entities) throws DataAccessException; /** * 查询总记录数 * @param map * @return */ @SuppressWarnings("rawtypes") public int queryCountByParams(Map map) throws DataAccessException; /** * 查询记录 通过 id * @param id * @return */ public T queryById(Integer id) throws DataAccessException; /** * 分页查询记录 * @return */ public List&lt;T&gt; queryForPage(BaseQuery baseQuery) throws DataAccessException; /** * 查询记录不带分页情况 * @param map * @return */ @SuppressWarnings("rawtypes") public List&lt;T&gt; queryByParams(Map map) throws DataAccessException; /** * 更新记录 * @param entity * @return */ public int update(T entity) throws DataAccessException; /** * 批量更新 * @param map * @return * @throws DataAccessException */ public int updateBatch(Map map) throws DataAccessException; /** * 删除记录 * @param id * @return */ public int delete(Integer id) throws DataAccessException; /** * 批量删除 * @param ids * @return */ public int deleteBatch(int[] ids) throws DataAccessException;&#125; Service层 BaseService层定义与实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134package com.dlh.base;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import org.springframework.beans.factory.annotation.Autowired;import java.util.List;import java.util.Map;public abstract class BaseService&lt;T&gt; &#123; @Autowired public BaseMapper&lt;T&gt; baseMapper; /** * 添加记录 * * @param entity * @return * @throws Exception */ public int insert(T entity) throws Exception &#123; int result = baseMapper.insert(entity); return result; &#125; /** * 批量添加记录 * * @param entities * @return * @throws Exception */ public int insertBatch(List&lt;T&gt; entities) throws Exception &#123; return baseMapper.insertBatch(entities); &#125; /** * 根据参数统计记录数 * * @param map * @return * @throws Exception */ @SuppressWarnings("rawtypes") public int queryCountByParams(Map map) throws Exception &#123; return baseMapper.queryCountByParams(map); &#125; /** * 查询记录通过 id * * @param id * @return * @throws Exception */ public T queryById(Integer id) throws Exception &#123; AssertUtil.isNull(id, "记录 id 非空!"); return baseMapper.queryById(id); &#125; /** * 分页查询 * * @param baseQuery * @return * @throws Exception */ public PageInfo&lt;T&gt; queryForPage(BaseQuery baseQuery) throws Exception &#123; PageHelper.startPage(baseQuery.getPageNum(), baseQuery.getPageSize()); List&lt;T&gt; list = baseMapper.queryForPage(baseQuery); PageInfo&lt;T&gt; pageInfo = new PageInfo&lt;T&gt;(list); return pageInfo; &#125; /** * * * * @param map * @return * @throws Exception */ @SuppressWarnings("rawtypes") public List&lt;T&gt; queryByParams(Map map) throws Exception &#123; return baseMapper.queryByParams(map); &#125; /** * 查询记录 * * @param entity * @return * @throws Exception */ public int update(T entity) throws Exception &#123; return baseMapper.update(entity); &#125; /** * 批量更新 * * @param map * @return * @throws Exception */ @SuppressWarnings("rawtypes") public int updateBatch(Map map) throws Exception &#123; return baseMapper.updateBatch(map); &#125; /** * 删除记录 * * @param id * @return * @throws Exception */ public int delete(Integer id) throws Exception &#123;// 判断 空 AssertUtil.isNull(id, "记录 id 非空！"); AssertUtil.isNull(queryById(id), "待删除的记录不存在!"); return baseMapper.delete(id); &#125; /** * 批量删除 * * @param ids * @return */ public int deleteBatch(int[] ids) throws Exception &#123; AssertUtil.isNull(ids.length == 0, "请至少选择一项记录!"); return baseMapper.deleteBatch(ids); &#125;&#125; BaseQuery类封装12345678910111213141516171819202122232425262728package com.dlh.base;public class BaseQuery &#123; /** * 分页页码 */ private int pageNum = 1; /** * 每页记录数 */ private int pageSize = 10; public int getPageNum() &#123; return pageNum; &#125; public void setPageNum(int pageNum) &#123; this.pageNum = pageNum; &#125; public int getPageSize() &#123; return pageSize; &#125; public void setPageSize(int pageSize) &#123; this.pageSize = pageSize; &#125;&#125; 参数异常处理1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.dlh.base;public class AssertUtil &#123; /** * 表达式结果真时判断 * * @param msg */ public static void isTrue(Boolean expression, String msg) &#123; if (expression) &#123; throw new ParamException(msg); &#125; &#125; public static void isTure(Boolean expression) &#123; if (expression) &#123; throw new ParamException("false"); &#125; &#125; /** * 参数为空时 * * @param object * @param msg */ public static void isNull(Object object, String msg) &#123; if (object == null) &#123; throw new ParamException(msg); &#125; &#125; /** * 参数不空时 * * @param object * @param msg */ public static void notNull(Object object, String msg) &#123; if (object != null) &#123; throw new ParamException(msg); &#125; &#125;&#125; 异常类定义123456789101112131415161718192021222324252627282930313233343536373839404142package com.dlh.base;/** * 参数异常类 * * @author Administrator */public class ParamException extends RuntimeException &#123; /** * * * / * private static final long serialVersionUID = -5962296753554846774L; * /** * 错误状态码 */ private int errorCode; public ParamException() &#123; &#125; /** * 错误消息 * * @param msg */ public ParamException(String msg) &#123; super(msg); &#125; public ParamException(int errorCode, String msg) &#123; super(msg); this.errorCode = errorCode; &#125; public int getErrorCode() &#123; return errorCode; &#125; public void setErrorCode(int errorCode) &#123; this.errorCode = errorCode; &#125;&#125; 使用1、Dao层接口继承BaseMapper 12@Repositorypublic interface UserDao extends BaseMapper&lt;User&gt; &#123;&#125; 2、Service层继承BaseService 12@Servicepublic class UserService extends BaseService&lt;User&gt; &#123;&#125; 3、不需要写任何代码，直接单元测试（映射sql文件中的sql已经自动生成） 1234@Testpublic void test01() throws Exception &#123; System.out.println(userService.queryById(6));;&#125;]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybatis-mybatis代码自动生成插件]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F14%2FMybatis%E5%AD%A6%E4%B9%A0-7%2F</url>
    <content type="text"><![CDATA[借助Maven插件实现mybatis基本crud代码生成 配置pom.xml123456789101112&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; 配置generatorConfig.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;!--数据库驱动--&gt; &lt;!--数据库驱动jar包路径--&gt; &lt;classPathEntry location="G:\Java\repository\mysql\mysql-connector-java\5.1.39\mysql-connector-java-5.1.39.jar"/&gt; &lt;context id="DB2Tables" targetRuntime="MyBatis3"&gt; &lt;commentGenerator&gt; &lt;property name="suppressDate" value="true"/&gt; &lt;property name="suppressAllComments" value="true"/&gt; &lt;/commentGenerator&gt; &lt;!--数据库链接地址账号密码--&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://127.0.0.1:3306/mybatis" userId="root" password="123456"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;property name="forceBigDecimals" value="false"/&gt; &lt;/javaTypeResolver&gt; &lt;!--生成 Model 类存放位置--&gt; &lt;javaModelGenerator targetPackage="com.dlh.po" targetProject="G:\idea\Workspaces\spring_mybatis\src\main\java" &gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;property name="trimStrings" value="true"/&gt; &lt;/javaModelGenerator&gt; &lt;!--生成映射文件存放位置--&gt; &lt;sqlMapGenerator targetPackage="com.dlh.mapper" targetProject="G:\idea\Workspaces\spring_mybatis\src\main\java" &gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;/sqlMapGenerator&gt; &lt;!--生成 Dao 类存放位置--&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="com.dlh.dao" targetProject="G:\idea\Workspaces\spring_mybatis\src\main\java" &gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;/javaClientGenerator&gt; &lt;!--tableName：数据库中的表名 domainObjectName:要生成的实体类类名--&gt; &lt;table tableName="account" domainObjectName="Account" enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false"&gt;&lt;/table&gt; &lt;table tableName="card" domainObjectName="Card" enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 执行配置 ​ 执行成功后，会自动生成对应的实体类，mybatis映射文件，映射接口类，其中基本sql也已经自动生成了。]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybatis-分页插件]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F12%2FMybatis%E5%AD%A6%E4%B9%A0-6%2F</url>
    <content type="text"><![CDATA[添加依赖12345&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;4.1.0&lt;/version&gt; &lt;/dependency&gt; 修改mybatis配置文件12345678910111213141516171819202122232425262728293031&lt;plugins&gt; &lt;!-- com.github.pagehelper 为 PageHelper 类所在包名 --&gt; &lt;plugin interceptor="com.github.pagehelper.PageHelper"&gt; &lt;property name="dialect" value="mysql"/&gt; &lt;!-- 该参数默认为 false --&gt; &lt;!-- 设置为 true 时，会将 RowBounds 第一个参数 offset 当成 pageNum 页码使 用 --&gt; &lt;!-- 和 startPage 中的 pageNum 效果一样 --&gt; &lt;property name="offsetAsPageNum" value="true"/&gt; &lt;!-- 该参数默认为 false --&gt; &lt;!-- 设置为 true 时，使用 RowBounds 分页会进行 count 查询 --&gt; &lt;property name="rowBoundsWithCount" value="true"/&gt; &lt;!-- 设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出 全部的结果 --&gt; &lt;!-- （相当于没有执行分页查询，但是返回结果仍然是 Page 类型） --&gt; &lt;property name="pageSizeZero" value="true"/&gt; &lt;!-- 3.3.0 版本可用 - 分页参数合理化，默认 false 禁用 --&gt; &lt;!-- 启用合理化时，如果 pageNum&lt;1 会查询第一页，如果 pageNum&gt;pages 会 查询最后一页 --&gt; &lt;!-- 禁用合理化时，如果 pageNum&lt;1 或 pageNum&gt;pages 会返回空数据 --&gt; &lt;property name="reasonable" value="true"/&gt; &lt;!-- 3.5.0 版本可用 - 为了支持 startPage(Object params)方法 --&gt; &lt;!-- 增加了一个`params`参数来配置参数映射，用于从 Map 或 ServletRequest 中取值 --&gt; &lt;!-- 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable,不配置映 射的用默认值 --&gt; &lt;property name="params" value="pageNum=start;pageSize=limit;pageSizeZero=zero;reasonable=heli;count=countsql"/&gt; &lt;/plugin&gt; &lt;/plugins&gt; 添加对应接口查询分页方法12345678910111213/** * @param pageNum 页号 * @param pageSize 每页显示的数量 * @param userName 参数 * @return */ public PageInfo&lt;User&gt; queryUsersByParams(Integer pageNum,Integer pageSize,String userName)&#123; // 设置分页页号和每页显示数量 PageHelper.startPage(pageNum,pageSize); List&lt;User&gt; users = userDao.queryUsersByParams(userName); PageInfo&lt;User&gt; pageInfo = new PageInfo&lt;&gt;(users); return pageInfo; &#125; 单元测试1234567@Test public void test02()&#123; PageInfo&lt;User&gt; pageInfo = userService.queryUsersByParams(1,3,null); System.out.println(pageInfo.getPages()+"=="+pageInfo.getTotal()); List&lt;User&gt; users = pageInfo.getList(); for(User user:users) System.out.println(user); &#125;]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybatis-整合spring]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F12%2FMybatis%E5%AD%A6%E4%B9%A0-5%2F</url>
    <content type="text"><![CDATA[添加依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;!-- spring 核心 jar --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring 测试 jar --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring jdbc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring 事物 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- aspectj 切面编程的 jar --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.9&lt;/version&gt; &lt;/dependency&gt; &lt;!-- c3p0 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加 mybatis 与 Spring 整合的核心包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql 驱动包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 日志打印相关的 jar --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt; &lt;/dependency&gt; 添加配置文件log4j123456# Global logging configurationlog4j.rootLogger=DEBUG, stdout# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%n db12345jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/mybatis?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8jdbc.username=rootjdbc.password=123456 mybatis123456789&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!-- po 包扫描 --&gt; &lt;typeAliases&gt; &lt;package name="com.dlh.po"/&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; spring12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/aophttp://www.springframework.org/schema/aop/spring-aop.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx-3.0.xsd"&gt; &lt;!-- 扫描 com.dlh 及其所有子包下类 --&gt; &lt;context:component-scan base-package="com.dlh" /&gt; &lt;!-- 加载 properties 配置文件 --&gt; &lt;context:property-placeholder location="classpath:db.properties" /&gt; &lt;aop:aspectj-autoproxy /&gt;&lt;!-- aop --&gt; &lt;!-- 配置数据源 --&gt; &lt;!-- 配置 c3p0 数据源 --&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;property name="driverClass" value="$&#123;jdbc.driver&#125;"&gt;&lt;/property&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url&#125;"&gt;&lt;/property&gt; &lt;property name="user" value="$&#123;jdbc.username&#125;"&gt;&lt;/property&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 设置事物增强 --&gt; &lt;tx:advice id="txAdvice" transaction-manager="txManager"&gt; &lt;tx:attributes&gt; &lt;tx:method name="get*" read-only="true" /&gt; &lt;tx:method name="find*" read-only="true" /&gt; &lt;tx:method name="query*" read-only="true" /&gt; &lt;tx:method name="load*" read-only="true" /&gt; &lt;tx:method name="add*" propagation="REQUIRED" /&gt; &lt;tx:method name="insert*" propagation="REQUIRED" /&gt; &lt;tx:method name="update*" propagation="REQUIRED"/&gt; &lt;tx:method name="delete*" propagation="REQUIRED" /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- aop 切面配置 --&gt; &lt;aop:config&gt; &lt;aop:pointcut id="servicePointcut" expression="execution(*com.dlh.service..*.*(..))" /&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="servicePointcut"/&gt; &lt;/aop:config&gt; &lt;!-- 配置 sqlSessionFactory--&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;property name="configLocation" value="classpath:mybatis.xml" /&gt; &lt;!-- 自动扫描 com/dlh/crm/mapper 目录下的所有 SQL 映射的 xml 文 件, 省掉 mybatis.xml 里的手工配置 value="classpath:com/dlh/crm/mapper/*.xml"指的是 classpath(类路径) 下 com.dlh.crm.mapper 包中的所有 xml 文件 UserMapper.xml 位于 com.dlh.mapper 包下，这样 UserMapper.xml 就可 以被自动扫描 --&gt; &lt;property name="mapperLocations" value="classpath:com/dlh/mapper/*.xml" /&gt; &lt;/bean&gt; &lt;!-- 配置扫描器 --&gt; &lt;bean id="mapperScanner" class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 扫描 com.dlh.dao 这个包以及它的子包下的所有映射接口类 --&gt; &lt;property name="basePackage" value="com.dlh.dao" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory" /&gt; &lt;/bean&gt;&lt;/beans&gt; mybatis映射sql文件1234567&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.dlh.dao.UserMapper"&gt;&lt;/mapper&gt; 目录结构 单元测试12345678910@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = "classpath:spring.xml")public class Test01 &#123; @Resource private UserService userService; @Test public void test01()&#123; System.out.println(userService.queryUserById(6)); &#125;&#125;]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybatis-缓存]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F11%2FMybatis%E5%AD%A6%E4%B9%A0-4%2F</url>
    <content type="text"><![CDATA[简介​ 缓存在数据库查询中就是将查询出来的数据存到内存或者磁盘中，以便下次再进行同样查询操作的时候可以直接读取。相比于到数据库中重新查询，从内存或磁盘中读取数据更加快速。 ​ 正如大多数持久层框架一样，mybatis同样提供了一级缓存和二级缓存 ​ 1、一级缓存：基于PerpetualCache的HashMap本地缓存，其存储作用域为Session，当Session flush或close之后，该Session中的所有Cache就将清空。 ​ 2、二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache 的 HashMap 存储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache； ​ 对于缓存数据更新机制，当某一个作用域(一级缓存 Session/二级缓存Namespaces)的进行了 C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear。 ​ 如果二级缓存开启，首先从二级缓存查询数据，如果二级缓存有则从二级缓存中获取数据，如果没有则到一级缓存中查询，如果有就从一级缓存中获取，如果一级缓存中没有，再查询数据库。 一级缓存​ mybatis默认开启一级缓存，当连续进行一个sql查询的时候，第二次查询就是从缓存中读取。 1234567@Test public void test05()&#123; Integer total1 = userMapper.queryUserCount(); System.out.println(total1); Integer total2 = userMapper.queryUserCount(); System.out.println(total2); &#125; 我们发现只执行了一条sql，当在两次查询中间刷新缓存后，结果是： 二级缓存mybatis提供了二级缓存，但需要手动开启。 ​ 1、在mybatis配置文件中全局开启二级缓存（位置在properties标签下面） ​ 2、在需要的Mapper.xml映射文件中加入二级缓存 至此已经开启了二级缓存，映射语句文件中所有的select语句将会被缓存 测试结果： ​ 发现也只执行了一遍sql查询，“Cache Hit Ratio”缓存命中率，说明第二次查询是从缓存中读取。 补充说明： ​ 1、映射语句文件中所有的insert、update、delete语句都会刷新缓存。 ​ 2、缓存会使用Least Recently Used（LRU，最近最少使用）算法来回收 ​ 3、缓存会根据指定时间间隔来刷新 ​ 4、缓存会存储1024个对象 使用场景：​ 1、 对查询频率高， 变化频率低的数据建议使用二级缓存。​ 2、 对于访问多的查询请求且用户对查询结果实时性要求不高， 此时可采用mybatis 二级缓存技术降低数据库访问量， 提高访问速度， 业务场景比如： 耗时较高的统计分析 sql、 电话账单查询 sql 等 Cache标签常用属性： 12345&lt;cache eviction="FIFO" &lt;!--回收策略为先进先出--&gt;flushInterval="60000" &lt;!--自动刷新时间60s--&gt;size="512" &lt;!--最多缓存512个引用对象--&gt;readOnly="true"/&gt; &lt;!--只读--&gt; 分布式缓存Ehcache1、引入依赖 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache-core&lt;/artifactId&gt; &lt;version&gt;2.4.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt; &lt;/dependency&gt; 2、缓存接口配置 1&lt;cache type="org.mybatis.caches.ehcache.EhcacheCache"/&gt; 3、添加配置文件（可以不设置，默认） 12345678910111213141516171819202122232425262728293031323334&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../bin/ehcache.xsd"&gt; &lt;!-- name：Cache 的唯一标识 maxElementsInMemory：内存中最大缓存对象数 maxElementsOnDisk：磁盘中最大缓存对象数，若是 0 表示无穷大 eternal：Element 是否永远不过期，如果为 true，则缓存的数据始终有效，如果为 false 那么还要根据 timeToIdleSeconds，timeToLiveSeconds 判断 overflowToDisk：配置此属性，当内存中 Element 数量达到 maxElementsInMemory 时， Ehcache 将会 Element 写到磁盘中 timeToIdleSeconds：设置 Element 在失效前的允许闲置时间。仅当 element 不是永久有效 时使用，可选属性，默认值是 0，也就是可闲置时间无穷大 timeToLiveSeconds：设置 Element 在失效前允许存活时间。最大时间介于创建时间和失效 时间之间。仅当 element 不是永久有效时使用，默认是 0.，也就是 element 存活时间无穷 大 di skPersistent：是否缓存虚拟机重启期数据 diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是 120 秒 diskSpoolBufferSizeMB：这个参数设置 DiskStore（磁盘缓存）的缓存区大小。默认是 30MB。每个 Cache 都应该有自己的一个缓冲区上海尚学智能科技有限公司 memoryStoreEvictionPolicy：当达到 maxElementsInMemory 限制时，Ehcache 将会根据 指定的策略去清理内存。默认策略是 LRU（最近最少使用）。你可以设置为 FIFO（先进先 出）或是 LFU（较少使用） --&gt; &lt;defaultCache overflowToDisk="true" eternal="false"/&gt; &lt;diskStore path="D:/cache" /&gt; &lt;!-- &lt;cache name="sxtcache" overflowToDisk="true" eternal="false" timeToIdleSeconds="300" timeToLiveSeconds="600" maxElementsInMemory="1000" maxElementsOnDisk="10" diskPersistent="true" diskExpiryThreadIntervalSeconds="300" diskSpoolBufferSizeMB="100" memoryStoreEvictionPolicy="LRU" /&gt; --&gt;&lt;/ehcache&gt;]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybatis-映射关系处理]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F10%2FMybatis%E5%AD%A6%E4%B9%A0-3%2F</url>
    <content type="text"><![CDATA[简介​ 数据库大类分为关系型数据库和非关系型数据库，关系型数据库有Mysql、Oracle、Sql Server等，非关系型数据库有MongoDB、Redis等。 ​ 关系型数据库中的映射关系主要有： ​ 一对一：比如一个人对应一个身份证号码 ​ 一对多（多对一）：父亲对孩子，一个父亲可以多个孩子，而一个孩子只会有一个父亲 ​ 多对多：一个学生可以选择多门课程，而一门课程可以给多个学生选择 ​ 处理映射关系如何处理这些关系映射？ ​ 一对一：在一个数据表中添加另一个表的主键作为外键 ​ 一对多：建立一个中间表 ​ 多对多：拆分成两个一对多 在mybatis环境中实现 ​ 因为我们实体类中的字段最好是固定不变的，所以当需要用到另外一张表的字段时新建一个类来对应，我们把它们放到DTO层，专门用来装这些组合的不完整的数据实体。 1、一对一 新建一个实体类 1234567891011121314151617181920212223public class UserCardDto &#123; private User user; private Card card; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; public Card getCard() &#123; return card; &#125; public void setCard(Card card) &#123; this.card = card; &#125; @Override public String toString() &#123; return "UserCardDto&#123;" + "user=" + user + ", card=" + card + '&#125;'; &#125;&#125; 在mapper.xml中编写sql 123456789101112131415161718192021222324&lt;!--一对一--&gt; &lt;resultMap id="user_card_map" type="userCardDto"&gt; &lt;!--property：实体类中成员变量名--&gt; &lt;!--变量类型（别名）--&gt; &lt;association property="user" javaType="user"&gt; &lt;id column="userId" property="userId"/&gt; &lt;result column="userName" property="userName"/&gt; &lt;result column="userPwd" property="userPwd"/&gt; &lt;result column="nickName" property="userNick"/&gt; &lt;result column="card_id" property="cardId"/&gt; &lt;/association&gt; &lt;association property="card" javaType="card"&gt; &lt;id column="id" property="id"/&gt; &lt;result column="card_num" property="cardNum"/&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id="queryCardUserById" parameterType="int" resultMap="user_card_map"&gt; select u.userName,u.nickName,c.card_num from user u left join card c on u.card_id=c.id where u.userId=#&#123;userId&#125; &lt;/select&gt; 2、一对多 12345678910111213141516171819202122232425262728293031public class UserCardAccountDto implements Serializable &#123; private User user; private Card card; private List&lt;Account&gt; accounts; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; public Card getCard() &#123; return card; &#125; public void setCard(Card card) &#123; this.card = card; &#125; public List&lt;Account&gt; getAccounts() &#123; return accounts; &#125; public void setAccounts(List&lt;Account&gt; accounts) &#123; this.accounts = accounts; &#125; @Override public String toString() &#123; return "UserCardAccountDto&#123;" + "user=" + user + ", card=" + card + ", accounts=" + accounts + '&#125;'; &#125;&#125; 123456789101112131415161718192021222324&lt;resultMap id="user_card_acc_map" extends="user_card_map" type="userCardAccountDto"&gt; &lt;!--property:字段名--&gt;&lt;!--ofType:集合中元素的类型--&gt; &lt;collection property="accounts" ofType="account"&gt; &lt;id column="id" property="id"/&gt; &lt;result column="aname" property="aname"/&gt; &lt;result column="type" property="type"/&gt; &lt;result column="money" property="money"/&gt; &lt;result column="userId" property="userId"/&gt; &lt;result column="create_time" property="create_time"/&gt; &lt;result column="update_time" property="update_time"/&gt; &lt;result column="remark" property="remark"/&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id="queryUserCardAccountById" parameterType="int" resultMap="user_card_acc_map"&gt; select u.userId,u.userName,u.userPwd,u.userNick,u.card_id, c.id,c.card_num, a.id,a.aname,a.type,a.money,a.remark,a.create_time,a.update_time from user u left join card c on u.card_id=c.id left join account a on u.userId=a.userId where u.userId=#&#123;userId&#125; &lt;/select&gt; 查询出来的结果天然去重]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybatis-CRUD操作..]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F09%2FMybatis%E5%AD%A6%E4%B9%A0-2%2F</url>
    <content type="text"><![CDATA[增删改查​ 需要进行增删改查操作时，需要在映射文件中配置不同的标签，有常用参数parameterType，resultType等。除了查询操作时需要配置返回结果类型（resultType）标签，其他三种操作都不需要添加。 ​ 参数类型（parameterType）有：基本数据类型,字符串,map,java bean,list等 ​ 返回结果类型（resultType）有：基本数据类型,字符串,map,java bean,list等 查询操作（select）123&lt;select id="queryMapById" parameterType="int" resultType="map"&gt; select * from user where userId=#&#123;userId&#125;&lt;/select&gt; 添加操作（insert）（1）添加不返回主键 1234&lt;!--添加不返回主键--&gt; &lt;insert id="addUser" parameterType="user"&gt; insert into user (userName, userPwd, userNick) values (#&#123;userName&#125;,#&#123;userPwd&#125;,#&#123;userNick&#125;) &lt;/insert&gt; （2）添加返回主键（这里使用的是mysql） 1234567&lt;!--添加返回主键1--&gt; &lt;insert id="addUserHasKey" parameterType="user"&gt; &lt;selectKey keyProperty="userId" order="AFTER" resultType="int"&gt; select LAST_INSERT_ID() as id &lt;/selectKey&gt; insert into user (userName, userPwd, userNick) values (#&#123;userName&#125;,#&#123;userPwd&#125;,#&#123;userNick&#125;) &lt;/insert&gt; 1234&lt;!--添加返回主键2 推荐--&gt; &lt;insert id="addUserHasKey2" parameterType="user" useGeneratedKeys="true" keyProperty="userId"&gt; insert into user (userName, userPwd, userNick) values (#&#123;userName&#125;,#&#123;userPwd&#125;,#&#123;userNick&#125;) &lt;/insert&gt; ​ useGeneratedKeys:使用自动生成key ​ keyProperty:数据库中主键的名字 ​ 注意：mapper接口返回的依然是受影响的行数，但是主键已经赋值到实体类对象的id中了 （3）批量添加 1234567&lt;!--批量添加--&gt; &lt;insert id="addUserBatch" parameterType="list"&gt; insert into user (userName, userPwd, userNick) values &lt;foreach collection="list" item="item" separator=","&gt; (#&#123;item.userName&#125;,#&#123;item.userPwd&#125;,#&#123;item.userNick&#125;) &lt;/foreach&gt; &lt;/insert&gt; 删除操作（delete）123456789101112&lt;!--删除--&gt; &lt;delete id="deleteUser" parameterType="int"&gt; delete from user where userId=#&#123;userId&#125; &lt;/delete&gt; &lt;!--批量删除--&gt; &lt;delete id="deleteUserBatch" parameterType="list"&gt; delete from user where userId in( &lt;foreach collection="list" item="item" separator=","&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/delete&gt; 更新操作（update）123456789101112&lt;!--更新--&gt; &lt;update id="updateUser" parameterType="user"&gt; update user set userPwd=#&#123;userPwd&#125; where userId=#&#123;userId&#125; &lt;/update&gt; &lt;!--批量更新--&gt; &lt;update id="updateUserBatch" parameterType="int"&gt; update user set userPwd="8888" where userId in ( &lt;foreach collection="array" item="item" separator=","&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/update&gt; 设置事务自动提交在增删改操作中，默认不会自动进行事务提交，需要进行设置才会自动提交 1、在创建session时设置 1SqlSession sqlSession = sessionFactory.openSession(true); 2、commit方法 12SqlSession sqlSession = sessionFactory.openSession();sqlSession.commit(); 使用sql片段​ 发现在编写sql时，有很多重复的语句或者语段，为了复用这些语句，可以编写sql语句段 1234&lt;!--sql片段--&gt; &lt;sql id="base"&gt; user (userName, userPwd, userNick) &lt;/sql&gt; 然后可以在需要使用这段语句的地方使用“include”引用，如： 1234&lt;!--添加返回主键2--&gt; &lt;insert id="addUserHasKey2" parameterType="user" useGeneratedKeys="true" keyProperty="userId"&gt; insert into &lt;include refid="base"/&gt; values (#&#123;userName&#125;,#&#123;userPwd&#125;,#&#123;userNick&#125;) &lt;/insert&gt; #{}和${}的区别12select * from user where name = #&#123;name&#125;; select * from user where name = '$&#123;name&#125;'; #{}在动态解析时，会解析成一个参数占位符?，所以解析之后的语句是： 1select * from user where name = ?; ${}在动态解析时，会将我们填充的参数当做字符串的形式填充到语句中，结果是： 1select * from user where name = "zhangsan"; #{}能够很大程度防止sql注入，而${}不能；${}方式一般用于插入一个不改变的字符串，比如order by ${type}，或是在传入表名时。一般我们尽量使用#{}的方式。 resultMap​ 当数据库中字段名和对应java bean中的变量名不同时，总是需要在sql语句中使用as取别名来将查询出来的字段名转换为和java bean中的相同。此时使用resultMap可以将数据库中查询出来的结果自动映射成java bean。 123456&lt;resultMap id="resMap" type="user"&gt; &lt;id column="userId" property="userId"/&gt; &lt;!--主键--&gt; &lt;result column="userName" property="userName"/&gt; &lt;result column="userPwd" property="userPwd"/&gt; &lt;result column="userNick" property="userNick"/&gt; &lt;/resultMap&gt; ​ type：java bean的别名 ​ column：数据库中的字段名 ​ property：java bean中的变量名 因为我在数据库中的字段名和java中的变量名取的是相同的，所以写的也一样，这里只做一个演示 将resultType替换resultMap，值和id对应 mapper接口代理​ 遵循mybatis开发规范，mybatis框架可以自动生成mapper接口对象 ​ 1、mapper.xml中namespace等于接口类全限定名 ​ 2、mapper.java接口中方法名必须与mapper.xml中statement id一致 ​ 3、接口中输入参数类型必须与parameterType参数类型一致 ​ 4、接口中方法的返回值类型必须与映射文件中对应返回值类型一致 ​ 非集成环境：接口名与映射文件名称一致，映射文件与接口处于同一个包中 此时可以通过getMapper()方法传入接口的class对象返回接口的对象，所以测试代码可以这么写： 12345678@Testpublic void test01() throws IOException &#123; InputStream is = Resources.getResourceAsStream("mybatis.xml"); SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(is); SqlSession sqlSession = sessionFactory.openSession(); UserMapper userMapper = sqlSession.getMapper(UserMapper.class); System.out.println(userMapper.queryMapById(1));&#125; 动态sqlmybatis的强大特性就是它的动态sql，动态sql顾名思义就是随着传入的参数动态产生不同的sql。 使用动态sql时需要在接口方法参数中设置@param指定参数才能将参数传入if等条件中： 1public List&lt;User&gt; queryUsersByName(@Param("userName") String userName); if条件判断123456&lt;select id="queryUsersByName" parameterType="string" resultType="user"&gt; select * from user where 1=1 &lt;if test="null!=userName and ''!=userName"&gt; and userName like concat('%',#&#123;userName&#125;,'%') &lt;/if&gt; &lt;/select&gt; ​ 当使用动态sql时，为了防止sql语句结构不当，所以加上where 1=1。在段代码中只有当if中的条件成立时，才会拼接上其中的代码。 choose when otherwise​ 这个类似于java中的switch-case-default 123456789101112&lt;select id="queryUserByNick" parameterType="string" resultType="user"&gt; select userId &lt;choose&gt; &lt;when test="null!=userNick and ''!=userNick"&gt; ,userName,userNick &lt;/when&gt; &lt;otherwise&gt; ,userPwd &lt;/otherwise&gt; &lt;/choose&gt; from user where 1=1 &lt;/select&gt; Ognl表达式​ 我们在进行if或者choose-when-outherwise进行判断的时候经常要写判断条件如 1&lt;if test="null!=userName and ''!=userName"&gt;&lt;/if&gt; ​ 此时我们可以用Ognl访问工具类来简化这里的编写，表达式格式为：@class@method(args)，上面这条判断使用之后的格式是： 1&lt;if test="@Ognl@isNotEmpty(userName)"&gt;&lt;/if&gt; trim where set标签​ 在我们使用动态sql的时候，sql中总有些连接词不能正常拼接，比如下面的代码： 12345678910&lt;select id="queryUserByNameOrNick" parameterType="user" resultType="user"&gt; select * from user where &lt;if test="@Ognl@isNotEmpty(userName)"&gt; userName like concat('%',#&#123;userName&#125;,'%') &lt;/if&gt; &lt;if test="@Ognl@isNotEmpty(userNick)"&gt; and userNick like concat('%',#&#123;userNick&#125;,'%') &lt;/if&gt; &lt;/select&gt; ​ 这段sql中当第一个if不满足而第二个if满足时，sql拼接where条件后面就会多一个and，此时查询就会报异常，为了避免这种问题，可以使用where标签将条件内容包含起来，这个标签相当于一个where，而且在里面的动态sql会自动去除多余的and。 使用where标签后： 1234567891011&lt;select id="queryUserByNameAndNick" parameterType="user" resultType="user"&gt; select * from user &lt;where&gt; &lt;if test="@Ognl@isNotEmpty(userName)"&gt; userName like concat('%',#&#123;userName&#125;,'%') &lt;/if&gt; &lt;if test="@Ognl@isNotEmpty(userNick)"&gt; and userNick like concat('%',#&#123;userNick&#125;,'%') &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; ​ ​ set标签和where类似，set标签是在做更新操作的时候（update tbName set id=? where xxx）使用，同时更新多个字段，总会出现多余的“，”，使用set标签即可去除它们。 ​ trim标签既有where标签的作用又有set标签的作用： 1234567891011&lt;select id="queryUserByNameAndNick" parameterType="user" resultType="user"&gt; select * from user &lt;trim prefix="where" prefixOverrides="and|or"&gt; &lt;if test="@Ognl@isNotEmpty(userName)"&gt; userName like concat('%',#&#123;userName&#125;,'%') &lt;/if&gt; &lt;if test="@Ognl@isNotEmpty(userNick)"&gt; and userNick like concat('%',#&#123;userNick&#125;,'%') &lt;/if&gt; &lt;/trim&gt; &lt;/select&gt; forEach标签类似于JSTL的c:foreach标签，对一个集合进行遍历，通常在in或者插入多条数据时使用，如： 1234567&lt;!--批量添加--&gt; &lt;insert id="addUserBatch" parameterType="list"&gt; insert into user (userName, userPwd, userNick) values &lt;foreach collection="list" item="item" separator=","&gt; (#&#123;item.userName&#125;,#&#123;item.userPwd&#125;,#&#123;item.userNick&#125;) &lt;/foreach&gt; &lt;/insert&gt; 注解形式动态sql不常用，需要新建一个类来写sql语句 1、在接口方法上加上注解，如： 12@SelectProvider(method = "queryUserCount",type = UserProvider.class)public Integer queryUserCount(); ​ type指定sql类的class，method指定sql方法名 2、编写sql 123456789public class UserProvider &#123; public String queryUserCount()&#123; String total= new SQL()&#123;&#123; SELECT("count(*)"); FROM("user"); &#125;&#125;.toString(); return total; &#125;&#125; 这里的方法的返回值和接口方法的返回值不对应]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybatis-搭建和简单查询]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F09%2FMybatis%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[简介​ mybatis框架是一个基于java的持久层框架。持久层就是将数据存到持久化设备上（如数据库、硬盘等），它对于jdbc和持久层的操作做了简化，将sql和代码分离。 ​ mybatis不是一个完全的orm（对象关系映射）框架，和hibernate（对象关系映射框架）相比，它还需要自己编写sql语句，但是在某些业务逻辑多变的场景下，它可以由自己编写sql语句就显得更加灵活。 环境搭建maven项目 导入依赖​ mybatis核心依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; ​ mysql驱动 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; ​ log4j依赖（可以输出操作过程，更容易在出错时找到问题） 12345&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; 添加mybatis配置文件12345678910111213141516171819202122232425262728&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!-- 注册属性文件 --&gt; &lt;properties resource="jdbc.properties"/&gt; &lt;typeAliases&gt; &lt;!--配置实体类别名：包扫描 默认别名是类名--&gt; &lt;package name="com.dlh.po"/&gt; &lt;/typeAliases&gt; &lt;!-- 配置MyBatis运行环境 --&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="$&#123;driver&#125;"/&gt; &lt;property name="url" value="$&#123;url&#125;"/&gt; &lt;property name="username" value="$&#123;user&#125;"/&gt; &lt;property name="password" value="$&#123;password&#125;"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;!-- 在这里可以配置另一个环境 --&gt; &lt;/environments&gt; &lt;!-- 注册映射文件 --&gt; &lt;mappers&gt; &lt;package name="com.dlh.mapper"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; ​ 在配置时可以配置多个运行环境，默认运行标签指定的默认环境（上面为development环境），在需要切换环境时，可以在创建session工厂时指定，如： 1sqlSessionFactory = new SqlSessionFactoryBuilder().build(is,"test"); 配置映射文件（sql代码所在）​ 配置映射文件的方式有三种： 12345678&lt;mappers&gt; &lt;!--包扫描--&gt; &lt;package name="com.dlh.mapper"/&gt; &lt;!--配置xml--&gt; &lt;mapper resource="com.dlh.mapper.UserMapper"/&gt; &lt;!--配置接口--&gt; &lt;mapper class="com.dlh.mapper.UserMapper"/&gt; &lt;/mappers&gt; ​ 一个实体类对应一个映射文件，所以当业务复杂有多个实体类时，包扫描的配置方式较为方便，而配置xml和配置接口都需要配置多个mapper标签。 创建一个xml文件作为映射文件，在java目录（因为不在resources目录下不会自动读取配置文件，所以需要指定java目录下读取配置文件） 1234567891011121314&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.tld&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; xml映射文件 123456789101112&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.dlh.mapper.UserMapper"&gt; &lt;!--数字--&gt; &lt;select id="queryUserByName" parameterType="string" resultType="user"&gt; select * from user where userName like concat('%',#&#123;userName&#125;,'%') &lt;!--concat:拼接字符串--&gt; &lt;/select&gt;&lt;/mapper&gt; namespace：指明命名空间，等于接口的全限定名，后面调用crud操作的时候需要 parameterType：指明输入参数类型（int,string,map,java bean,list..） resultType：指明输出数据类型（基本数据类型,string,map,java bean,list） ​ 在这里输出类型如果为List的话，只需要指明list中泛型的类型 ​ ·当输出类型为javabean类型时，需要写类所在的完整路径com.xxx.xxx.xx；为了书写方便，也可以指定它的别名，如上面一般。指定别名有三种方式： 123456&lt;typeAliases&gt; &lt;!--配置实体类别名：包扫描 默认别名是类名--&gt; &lt;package name="com.dlh.po"/&gt; &lt;!--typeAlias标签指定路径--&gt; &lt;typeAlias type="com.dlh.po.User" alias="user"/&gt; &lt;/typeAliases&gt; ​ 还可以把typeAlias中的alias标签以注解的方式写在javabean类的上面 ​ 和原生jdbc不同的是，原生jdbc的占位符’?’，在这里用#{传入参数的名字} ​ 基本配置就基本完成了，接下来就是调用了，从这里可以看出，mybatis环境中需要配置输入参数类型，输出参数类型和sql语句就可以完成数据库操作。 ​ 那我们知道数据库中一部分字段的类型和java中是不同的，比如数据库中的varchar，在java中是String，它是用什么转换的呢—-&gt;typeHandler类型处理器，在预处理语句中设置一个参数或者获取一个参数时，类型处理器都会将获取到的值以合适的方式转换为java类型 ​ 调用，实现一个查询其中主要过程 （1）读取资源文件 （2）创建sqlsession工厂 （3）由sqlsession工厂打开/创建session （4）通过session操作数据库 （5）处理结果 （6）关闭sqlsession 我在这里将映射文件对应了一个接口，实现了这个接口并且做了一些封装 12345678910111213141516171819202122232425262728public class UserMapperImpl implements UserMapper &#123; private SqlSessionFactory sqlSessionFactory; private static SqlSession sqlSession; public UserMapperImpl() &#123; &#125; public UserMapperImpl(SqlSessionFactory sqlSessionFactory) &#123; this.sqlSessionFactory = sqlSessionFactory; sqlSession = sqlSessionFactory.openSession(); &#125; @Override public List&lt;User&gt; queryUserByName(String userName) &#123; List&lt;User&gt; users = null; try &#123; users = sqlSession.selectList("com.dlh.mapper.UserMapper.queryUserByName", userName); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (sqlSession != null) &#123; sqlSession.close(); &#125; &#125; return users; &#125;&#125; 单元测试代码 1234567891011121314151617public class Test01 &#123; private SqlSessionFactory sqlSessionFactory; private static UserMapper userMapper; @Before public void before() throws IOException &#123; InputStream is = Resources.getResourceAsStream("mybatis.xml"); sqlSessionFactory = new SqlSessionFactoryBuilder().build(is); &#125; @Test public void test01() &#123; userMapper = new UserMapperImpl(sqlSessionFactory); List&lt;User&gt; users = userMapper.queryUserByName("z"); for (User user : users) System.out.println(user); &#125;&#125; 结果 因为使用了log4j日志采集，可以看到我们编写的sql还有查询到的总数量]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ajax轮询和长轮询]]></title>
    <url>%2Fdlh1234okok.github.io%2F2017%2F01%2F02%2FAjax%E8%BD%AE%E8%AF%A2%E5%92%8C%E9%95%BF%E8%BD%AE%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[​ 在需要实时信息更新的时候，可以使用轮询不断向服务器请求获取数据，但是频繁请求服务器，效率低而且十分耗费资源，一般推荐使用webSocket建立持久连接 ​ 因为以前没有听说过这个名词，现在了解后在这里做一个备份（这里只贴出代码） 12345678910111213// Ajax轮询 var get = &#123; url:"user", type:"post", dataType:"json", success:function (data) &#123; console.log("next"); &#125; &#125;; // Ajax定时访问服务端，不断建立连接获取数据 window.setInterval(function () &#123; $.ajax(get) &#125;,1000); 1234567891011121314// Ajax长轮询 var get = &#123; url:"user", type:"post", dataType:"json", success:function (data) &#123; $.ajax(get); // 在Ajax的回调函数这里再次发送ajax请求 &#125;, error:function () &#123; $.ajax(get); // 当请求时间过长，再次调用ajax长轮询 &#125; &#125;; $.ajax(get); 在一次请求完成返回之后立刻再次发送请求，当没有数据就会被挂在服务器，但只要有数据就会返回。]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[无意识递归]]></title>
    <url>%2Fdlh1234okok.github.io%2F2016%2F11%2F12%2F%E6%97%A0%E6%84%8F%E8%AF%86%E9%80%92%E5%BD%92%2F</url>
    <content type="text"><![CDATA[​ 在java中，所有类如果没有显式的继承一个类，那么它将隐式继承Object类。在开发中，我们常常重写toString方法，但是使用不当将造成无意识递归，让我们来看看下面的栗子（来自Thinking in Java） 12345678910111213141516171819202122public class InfiniteRecursion &#123; @Override public String toString() &#123; // this代表当前类对象 return "InfiniteRecursion address:"+ this + "\n"; &#125; public static void main(String[] args)&#123; List&lt;InfiniteRecursion&gt; list = new ArrayList&lt;&gt;(); // 存入10个InfiniteRecursion对象 for (int i = 0; i &lt; 10 ; i++) &#123; list.add(new InfiniteRecursion()); &#125; // 遍历集合 for (InfiniteRecursion infiniteRecursion:list)&#123; // 在println方法中打印，将调用toString方法 System.out.println(infiniteRecursion); &#125; &#125;&#125; ​ 我们知道this代表当前对象，但是在这里将它返回时，”InfiniteRecursion address:”字符串发现后面的this不是一个String类型，它会尝试将this转换为String类型，然后就会调用this的toString方法，然而当前类重写了toString方法，将造成递归，且没有出口，抛出异常java.lang.StackOverflowError栈内存溢出。 解决： 我们只需要在重写的toString方法中调用父类Object的toString方法 12345678910111213141516171819public class InfiniteRecursion &#123; @Override public String toString() &#123; return "InfiniteRecursion address:"+ super.toString() + "\n"; &#125; public static void main(String[] args)&#123; List&lt;InfiniteRecursion&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10 ; i++) &#123; list.add(new InfiniteRecursion()); &#125; // 遍历集合 for (InfiniteRecursion infiniteRecursion:list)&#123; System.out.println(infiniteRecursion); &#125; &#125;&#125; Object中的toString方法为 123public String toString() &#123; return getClass().getName() + "@" + Integer.toHexString(hashCode());&#125; 返回的是该类的全限定名+@+十六进制的哈希码 所以打印出来该类对象的地址值为 com.mani.InfiniteRecursion@2f0e140b]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[面向对象-继承]]></title>
    <url>%2Fdlh1234okok.github.io%2F2016%2F11%2F03%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[1、继承的作用： 通过继承 将多个类中的相同的内容摘取出来 变成一个新的类 让其他类和当前新的类产生关系 达到代码复用性的目的，可以更好的维护类和类之间的关系 2、如何继承 Class A extend B A是B的子类(派生类) B是A的父类(超类/基类) 3、继承的注意事项： 继承在java中只支持单继承，一个子类只能有一个父类，但是一个父类可以有多个子类 子类继承父类，重写父类的方法，子类可以获得父类的部分功能。 子类不能从父类继承的：private修饰的方法、final修饰的方法、父类构造器 父类static修饰的方法子类可以继承但不能重写 4、子类创建对象时会导致父类加载，先调用父类的构造器 5、子类继承父类时不能继承父类的构造器，但是可以调用父类的构造器 如果没有默认的空构造，要调用父类的有参构造，就必须用关键字super显式地编写调用父类构造器的语句，并配备参数列表 因为会先调用父类的构造器，所以运行的结果是： 证明-4； 6、子类重写父类方法，默认情况下会调用子类重写的方法。子类对象调用父类原来的方法，可以通过super.调用 7、因为java只支持单继承，所以当A继承B不能满足需求时，较好的方法是B继承C，多层继承。 以上是一个多层继承简单的例子，学生继承人的特征，并有自己新的特征，坏学生继承学生，有相同的day方法，但有不同的表现。 多层继承较好地解决了前面继承无法满足的要求，但是继承链过长容易导致代码不易维护，后期功能拓展很麻烦。 8.当一个类没有显式地继承一个类时，默认会隐式地继承Object类 以上代码可以Person类的父类其实就是Object，在Person类中可以使用Object的资源和方法，如toString方法 9、继承的重写 子类重写父类要遵守以下规则： （1）方法名/形参列表相同 （2）子类的返回值类型/抛出异常 小于等于 父类 （3）子类的修饰符权限 大于等于 父类 检验重写：@Override注解 如果加上该注解没有出错就是重写了父类的方法，否则就没有重写]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
</search>
